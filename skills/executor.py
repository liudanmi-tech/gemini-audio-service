"""
æŠ€èƒ½æ‰§è¡Œå™¨
æ‰§è¡ŒæŠ€èƒ½ï¼ŒåŠ¨æ€ç»„è£… Prompt å¹¶ç”Ÿæˆç­–ç•¥
"""
import os
import json
import re
import time
import logging
from typing import Dict, List, Optional
import google.generativeai as genai

from .loader import load_knowledge_base
from schemas.strategy_schemas import parse_gemini_response, VisualData, StrategyItem, Call2Response

logger = logging.getLogger(__name__)

# ç­–ç•¥æ¨¡å‹åï¼Œå¯é€šè¿‡ç¯å¢ƒå˜é‡ GEMINI_FLASH_MODEL è¦†ç›–
GEMINI_FLASH_MODEL = os.getenv("GEMINI_FLASH_MODEL", "gemini-3-flash-preview")

# æƒ…ç»ªçŠ¶æ€ -> emoji æ˜ å°„ï¼ˆä¸ SKILL.md ä¸€è‡´ï¼‰
MOOD_EMOJI_MAP = {
    "é«˜å…´": "ğŸ˜Š",
    "ç„¦è™‘": "ğŸ˜°",
    "å¹³å¸¸å¿ƒ": "ğŸ˜",
    "äº¢å¥‹": "ğŸ¤©",
    "æ‚²ä¼¤": "ğŸ˜¢",
}


def execute_skill_scripts(skill_id: str, script_name: str, input_data: dict) -> dict:
    """
    æ‰§è¡ŒæŠ€èƒ½ scripts ç›®å½•ä¸‹çš„ä»£ç ï¼ˆé¢„å¤„ç†/åå¤„ç†ï¼‰
    
    æ³¨æ„ï¼šä¸ºäº†å®‰å…¨ï¼Œè¿™ä¸ªåŠŸèƒ½æš‚æ—¶ä¸å®ç°ï¼Œæˆ–è€…éœ€è¦ä¸¥æ ¼çš„æ²™ç®±ç¯å¢ƒ
    
    Args:
        skill_id: æŠ€èƒ½ ID
        script_name: è„šæœ¬åç§°ï¼ˆå¦‚ "preprocess.py"ï¼‰
        input_data: è¾“å…¥æ•°æ®
        
    Returns:
        dict: å¤„ç†åçš„æ•°æ®
    """
    # TODO: å®ç°è„šæœ¬æ‰§è¡ŒåŠŸèƒ½ï¼ˆéœ€è¦å®‰å…¨æ²™ç®±ï¼‰
    logger.warning(f"è„šæœ¬æ‰§è¡ŒåŠŸèƒ½æš‚æœªå®ç°: {skill_id}/{script_name}")
    return input_data


def _extract_emotion_counts(user_text: str) -> dict:
    """ä»ç”¨æˆ·è¯æœ¯ä¸­æå–å¹æ°”ã€å“ˆå“ˆå“ˆæ¬¡æ•°å’Œå­—æ•°ï¼ˆè§„åˆ™ç»Ÿè®¡ï¼‰"""
    sigh_pattern = re.compile(r'å”‰|å“|å”‰å£°å¹æ°”|å”‰å‘€|å“å‘¦|å“å“Ÿ', re.IGNORECASE)
    haha_pattern = re.compile(r'å“ˆå“ˆ+|å‘µå‘µ+|å˜¿å“ˆ|å˜»å“ˆ', re.IGNORECASE)
    sigh_count = len(sigh_pattern.findall(user_text))
    haha_count = len(haha_pattern.findall(user_text))
    char_count = len(user_text.replace(" ", "").replace("\n", ""))
    return {"sigh_count": sigh_count, "haha_count": haha_count, "char_count": char_count}


async def _execute_emotion_skill(
    skill: Dict,
    transcript: List[Dict],
    context: Dict,
    model=None
) -> Dict:
    """æ‰§è¡Œæƒ…ç»ªè¯†åˆ«æŠ€èƒ½ï¼šæå–ç”¨æˆ·è¯æœ¯ï¼Œè§„åˆ™ç»Ÿè®¡+LLMåˆ¤æ–­çŠ¶æ€"""
    if model is None:
        model = genai.GenerativeModel(GEMINI_FLASH_MODEL)
    skill_id = skill.get("skill_id", "emotion_recognition")
    skill_name = skill.get("name", "æƒ…ç»ªè¯†åˆ«")
    prompt_template = skill.get("prompt_template", "")
    start_time = time.time()
    
    try:
        # 1. æå–ç”¨æˆ·è‡ªå·±çš„è¯æœ¯ï¼ˆis_me=Trueï¼‰
        user_lines = []
        for item in transcript:
            if item.get("is_me") is True:
                text = item.get("text", item.get("content", ""))
                if text:
                    user_lines.append(text)
        user_text = "\n".join(user_lines) if user_lines else ""
        
        # 2. è§„åˆ™ç»Ÿè®¡
        counts = _extract_emotion_counts(user_text)
        sigh_count = counts["sigh_count"]
        haha_count = counts["haha_count"]
        char_count = counts["char_count"]
        
        # 3. LLM åˆ¤æ–­ mood_stateï¼ˆè‹¥ç”¨æˆ·æ— è¯åˆ™é»˜è®¤å¹³å¸¸å¿ƒï¼‰
        mood_state = "å¹³å¸¸å¿ƒ"
        mood_emoji = "ğŸ˜"
        if user_text.strip():
            prompt = prompt_template.replace("{transcript_json}", json.dumps(user_lines, ensure_ascii=False, indent=2))
            prompt = prompt.replace("{session_id}", context.get("session_id", ""))
            prompt = prompt.replace("{user_id}", context.get("user_id", ""))
            prompt = prompt.replace("{memory_context}", context.get("memory_context", ""))
            response = model.generate_content(prompt)
            try:
                data = parse_gemini_response(response.text)
                if isinstance(data, dict):
                    raw_state = data.get("mood_state", "å¹³å¸¸å¿ƒ")
                    mood_state = raw_state if raw_state in MOOD_EMOJI_MAP else "å¹³å¸¸å¿ƒ"
                    mood_emoji = data.get("mood_emoji", MOOD_EMOJI_MAP.get(mood_state, "ğŸ˜"))
            except Exception as e:
                logger.warning(f"æƒ…ç»ª LLM è§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤: {e}")
        
        execution_time_ms = int((time.time() - start_time) * 1000)
        emotion_insight = {
            "sigh_count": sigh_count,
            "haha_count": haha_count,
            "mood_state": mood_state,
            "mood_emoji": mood_emoji,
            "char_count": char_count,
        }
        logger.info(f"æƒ…ç»ªè¯†åˆ«å®Œæˆ: sigh={sigh_count} haha={haha_count} mood={mood_state} chars={char_count}")
        return {
            "skill_id": skill_id,
            "name": skill_name,
            "result": None,
            "emotion_insight": emotion_insight,
            "execution_time_ms": execution_time_ms,
            "success": True,
            "priority": skill.get("priority", 50),
            "confidence": skill.get("confidence", 0.9),
        }
    except Exception as e:
        execution_time_ms = int((time.time() - start_time) * 1000) if 'start_time' in locals() else 0
        logger.error(f"æƒ…ç»ªè¯†åˆ«å¤±è´¥: {e}")
        return {
            "skill_id": skill_id,
            "name": skill_name,
            "result": None,
            "emotion_insight": None,
            "execution_time_ms": execution_time_ms,
            "success": False,
            "error_message": str(e),
            "priority": skill.get("priority", 50),
            "confidence": skill.get("confidence", 0.9),
        }


async def _execute_depression_skill(
    skill: Dict,
    transcript: List[Dict],
    context: Dict,
    model=None
) -> Dict:
    """æ‰§è¡Œé˜²æŠ‘éƒç›‘æ§æŠ€èƒ½ï¼šè§£æ LLM è¿”å›çš„ JSONï¼Œè¾“å‡º mental_health_insight"""
    if model is None:
        model = genai.GenerativeModel(GEMINI_FLASH_MODEL)
    skill_id = skill.get("skill_id", "depression_prevention")
    skill_name = skill.get("name", "é˜²æŠ‘éƒç›‘æ§")
    prompt_template = skill.get("prompt_template", "")
    start_time = time.time()

    try:
        # 1. æå–ç”¨æˆ·è‡ªå·±çš„è¯æœ¯ï¼ˆis_me=Trueï¼‰
        user_lines = []
        for item in transcript:
            if item.get("is_me") is True:
                text = item.get("text", item.get("content", ""))
                if text:
                    user_lines.append(text)
        user_text = "\n".join(user_lines) if user_lines else ""

        if not user_text.strip():
            logger.info(f"é˜²æŠ‘éƒç›‘æ§è·³è¿‡: ç”¨æˆ·æ— è¯æœ¯")
            return {
                "skill_id": skill_id,
                "name": skill_name,
                "result": None,
                "mental_health_insight": None,
                "execution_time_ms": int((time.time() - start_time) * 1000),
                "success": False,
                "error_message": "ç”¨æˆ·æ— è¯æœ¯",
                "priority": skill.get("priority", 45),
                "confidence": skill.get("confidence", 0.9),
            }

        # 2. ç»„è£… prompt å¹¶è°ƒç”¨ LLM
        prompt = prompt_template.replace("{transcript_json}", json.dumps(user_lines, ensure_ascii=False, indent=2))
        prompt = prompt.replace("{session_id}", context.get("session_id", ""))
        prompt = prompt.replace("{user_id}", context.get("user_id", ""))
        prompt = prompt.replace("{memory_context}", context.get("memory_context", ""))
        response = model.generate_content(prompt)

        # 3. è§£æ JSON å“åº”
        data = parse_gemini_response(response.text)
        if not isinstance(data, dict):
            raise ValueError("LLM æœªè¿”å›æœ‰æ•ˆ JSON å¯¹è±¡")

        # 4. æ„å»º mental_health_insight ç»“æ„
        triad = data.get("cognitive_triad", {}) or {}
        mental_health_insight = {
            "defense_energy_pct": data.get("defense_energy_pct", 50),
            "dominant_defense": data.get("dominant_defense", ""),
            "status_assessment": data.get("status_assessment", ""),
            "cognitive_triad": {
                "self": triad.get("self", {"status": "green", "reason": ""}),
                "world": triad.get("world", {"status": "green", "reason": ""}),
                "future": triad.get("future", {"status": "green", "reason": ""}),
            },
            "insight": data.get("insight", ""),
            "strategy": data.get("strategy", ""),
            "crisis_alert": data.get("crisis_alert", False),
        }

        execution_time_ms = int((time.time() - start_time) * 1000)
        logger.info(f"é˜²æŠ‘éƒç›‘æ§å®Œæˆ: crisis_alert={mental_health_insight['crisis_alert']} energy={mental_health_insight['defense_energy_pct']}%")
        return {
            "skill_id": skill_id,
            "name": skill_name,
            "result": None,
            "mental_health_insight": mental_health_insight,
            "execution_time_ms": execution_time_ms,
            "success": True,
            "priority": skill.get("priority", 45),
            "confidence": skill.get("confidence", 0.9),
        }
    except Exception as e:
        execution_time_ms = int((time.time() - start_time) * 1000) if 'start_time' in locals() else 0
        logger.error(f"é˜²æŠ‘éƒç›‘æ§å¤±è´¥: {e}")
        return {
            "skill_id": skill_id,
            "name": skill_name,
            "result": None,
            "mental_health_insight": None,
            "execution_time_ms": execution_time_ms,
            "success": False,
            "error_message": str(e),
            "priority": skill.get("priority", 45),
            "confidence": skill.get("confidence", 0.9),
        }


async def execute_skill(
    skill: Dict,
    transcript: List[Dict],
    context: Dict,
    model=None
) -> Dict:
    """
    æ‰§è¡Œå•ä¸ªæŠ€èƒ½

    Args:
        skill: æŠ€èƒ½ä¿¡æ¯ï¼ˆåŒ…å« prompt_templateï¼‰
        transcript: å¯¹è¯è½¬å½•åˆ—è¡¨
        context: ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆåŒ…å« session_id, user_id ç­‰ï¼‰
        model: Gemini æ¨¡å‹å®ä¾‹ï¼ˆå¦‚æœä¸º Noneï¼Œåˆ™ä½¿ç”¨é»˜è®¤æ¨¡å‹ï¼‰
        
    Returns:
        dict: ç­–ç•¥åˆ†æç»“æœï¼ˆCall2Response æ ¼å¼ï¼‰æˆ– emotion_insightï¼ˆæƒ…ç»ªæŠ€èƒ½ï¼‰
    """
    skill_id = skill.get("skill_id", "unknown")
    if skill_id == "emotion_recognition":
        return await _execute_emotion_skill(skill, transcript, context, model)
    if skill_id == "depression_prevention":
        return await _execute_depression_skill(skill, transcript, context, model)
    
    if model is None:
        model = genai.GenerativeModel(GEMINI_FLASH_MODEL)
    
    prompt_template = skill.get("prompt_template", "")
    
    if not prompt_template:
        raise ValueError(f"æŠ€èƒ½ {skill_id} ç¼ºå°‘ prompt_template")
    
    try:
        skill_name = skill.get("name", skill_id)
        logger.info(f"========== å¼€å§‹æ‰§è¡ŒæŠ€èƒ½: {skill_id} (åç§°: {skill_name}) ==========")
        start_time = time.time()
        
        # 1. é¢„å¤„ç†ï¼ˆå¯é€‰ï¼‰
        # TODO: å¦‚æœå­˜åœ¨ scripts/preprocess.pyï¼Œæ‰§è¡Œé¢„å¤„ç†
        processed_transcript = transcript
        
        # 2. Prompt ç»„è£…
        transcript_json = json.dumps(processed_transcript, ensure_ascii=False, indent=2)
        
        # æ›¿æ¢å˜é‡
        prompt = prompt_template.replace("{transcript_json}", transcript_json)
        prompt = prompt.replace("{session_id}", context.get("session_id", ""))
        prompt = prompt.replace("{user_id}", context.get("user_id", ""))
        # v0.6 è®°å¿†ï¼šæ³¨å…¥ memory_contextï¼Œè‹¥æ— åˆ™å¡«ç©ºï¼ˆå‘åå…¼å®¹ï¼‰
        memory_context = context.get("memory_context", "")
        has_memory = bool(memory_context and memory_context.strip())
        if has_memory:
            logger.info(f"[è®°å¿†] æŠ€èƒ½ {skill_id} æ³¨å…¥ memory_context: len={len(memory_context)} preview={memory_context[:150]}...")
        elif "{memory_context}" in prompt_template:
            logger.info(f"[è®°å¿†] æŠ€èƒ½ {skill_id} memory_context ä¸ºç©ºï¼Œå ä½ç¬¦å°†å¡«ç©º")
        prompt = prompt.replace("{memory_context}", memory_context)
        
        # 3. çŸ¥è¯†åº“æ³¨å…¥ï¼ˆå¯é€‰ï¼‰
        knowledge_base = skill.get("knowledge_base")
        if knowledge_base:
            # åœ¨ Prompt æœ«å°¾æ·»åŠ çŸ¥è¯†åº“å†…å®¹
            prompt += f"\n\n## çŸ¥è¯†åº“å‚è€ƒ\n{knowledge_base}"
        
        logger.info(f"Prompt é•¿åº¦: {len(prompt)} å­—ç¬¦")
        logger.debug(f"Prompt å†…å®¹: {prompt[:500]}...")
        
        # 4. è°ƒç”¨ Gemini ç”Ÿæˆç­–ç•¥
        logger.info(f"è°ƒç”¨æ¨¡å‹: {GEMINI_FLASH_MODEL}")
        response = model.generate_content(prompt)
        
        logger.info(f"Gemini å“åº”é•¿åº¦: {len(response.text)} å­—ç¬¦")
        logger.debug(f"Gemini å“åº”å†…å®¹: {response.text[:1000]}...")
        
        # 5. è§£æå“åº”
        try:
            analysis_data = parse_gemini_response(response.text)
        except Exception as e:
            logger.error(f"è§£æ Gemini å“åº”å¤±è´¥: {e}")
            logger.error(f"å“åº”å†…å®¹: {response.text}")
            raise Exception(f"è§£æç­–ç•¥åˆ†æç»“æœå¤±è´¥: {str(e)}")
        
        # 6. éªŒè¯è§£æç»“æœ
        if not isinstance(analysis_data, dict):
            logger.error(f"è§£æç»“æœä¸æ˜¯å­—å…¸ç±»å‹: {type(analysis_data)}, å†…å®¹: {analysis_data}")
            raise Exception("ç­–ç•¥åˆ†æç»“æœæ ¼å¼é”™è¯¯")
        
        if "visual" not in analysis_data:
            logger.error(f"ç¼ºå°‘ 'visual' å­—æ®µï¼Œå¯ç”¨å­—æ®µ: {list(analysis_data.keys())}")
            raise Exception("ç­–ç•¥åˆ†æç»“æœç¼ºå°‘ 'visual' å­—æ®µ")
        
        if "strategies" not in analysis_data:
            logger.error(f"ç¼ºå°‘ 'strategies' å­—æ®µï¼Œå¯ç”¨å­—æ®µ: {list(analysis_data.keys())}")
            raise Exception("ç­–ç•¥åˆ†æç»“æœç¼ºå°‘ 'strategies' å­—æ®µ")
        
        # 7. å¤„ç† visual æ•°æ®
        visual_raw = analysis_data.get("visual")
        
        # å‘åå…¼å®¹ï¼šå¦‚æœè¿”å›çš„æ˜¯å•ä¸ªå¯¹è±¡ï¼Œè½¬æ¢ä¸ºæ•°ç»„
        if isinstance(visual_raw, dict):
            logger.warning("æ”¶åˆ°å•ä¸ª visual å¯¹è±¡ï¼Œè½¬æ¢ä¸ºæ•°ç»„æ ¼å¼ä»¥ä¿æŒå…¼å®¹")
            visual_raw = [visual_raw]
        elif not isinstance(visual_raw, list):
            logger.error(f"visual å­—æ®µæ ¼å¼é”™è¯¯ï¼ŒæœŸæœ›æ•°ç»„æˆ–å¯¹è±¡ï¼Œå®é™…ç±»å‹: {type(visual_raw)}")
            raise Exception("visual å­—æ®µå¿…é¡»æ˜¯æ•°ç»„æˆ–å¯¹è±¡")
        
        # éªŒè¯ visual æ•°ç»„ä¸ä¸ºç©º
        if len(visual_raw) == 0:
            logger.warning("visual æ•°ç»„ä¸ºç©ºï¼Œåˆ›å»ºé»˜è®¤ visual")
            if transcript:
                first_item = transcript[0]
                visual_raw = [{
                    "transcript_index": 0,
                    "speaker": first_item.get("speaker", "Speaker_0"),
                    "image_prompt": "å®«å´éªå‰åœåŠ›åŠ¨ç”»é£æ ¼ï¼Œæ¸©æš–è‡ªç„¶è‰²è°ƒã€‚å·¦ä¾§ä¸ºç”¨æˆ·ï¼Œå³ä¾§ä¸ºå¯¹æ–¹ã€‚",
                    "emotion": "æœªçŸ¥",
                    "subtext": "",
                    "context": "å¯¹è¯å¼€å§‹",
                    "my_inner": "",
                    "other_inner": ""
                }]
            else:
                raise Exception("visual æ•°ç»„ä¸ºç©ºä¸”æ— æ³•åˆ›å»ºé»˜è®¤å€¼")
        
        # éªŒè¯å…³é”®æ—¶åˆ»æ•°é‡ï¼ˆ2-5 ä¸ªï¼‰
        if len(visual_raw) > 5:
            logger.warning(f"å…³é”®æ—¶åˆ»æ•°é‡è¿‡å¤š ({len(visual_raw)} ä¸ª)ï¼Œåªä¿ç•™å‰ 5 ä¸ª")
            visual_raw = visual_raw[:5]
        elif len(visual_raw) < 3:
            logger.warning(f"å…³é”®æ—¶åˆ»æ•°é‡è¾ƒå°‘ ({len(visual_raw)} ä¸ª)ï¼Œå°†å°è¯•ä»ç­–ç•¥è¡¥è¶³è‡³è‡³å°‘ 3 ä¸ª")
        
        # æ„å»º VisualData åˆ—è¡¨
        visual_list = []
        transcript_length = len(transcript)
        
        try:
            for idx, v in enumerate(visual_raw):
                # éªŒè¯ transcript_index
                transcript_index = v.get("transcript_index", idx)
                if transcript_index < 0 or transcript_index >= transcript_length:
                    logger.warning(f"transcript_index {transcript_index} è¶…å‡ºèŒƒå›´ (0-{transcript_length-1})ï¼Œä½¿ç”¨ç´¢å¼• {idx}")
                    transcript_index = min(idx, transcript_length - 1) if transcript_length > 0 else 0
                
                # è·å–å¯¹åº”çš„ transcript é¡¹ä»¥è·å– speaker
                speaker = v.get("speaker", "")
                if not speaker and transcript_length > 0:
                    speaker = transcript[transcript_index].get("speaker", "Speaker_0")
                
                visual_data = VisualData(
                    transcript_index=transcript_index,
                    speaker=speaker,
                    image_prompt=v.get("image_prompt", ""),
                    emotion=v.get("emotion", ""),
                    subtext=v.get("subtext", ""),
                    context=v.get("context", ""),
                    my_inner=v.get("my_inner", ""),
                    other_inner=v.get("other_inner", "")
                )
                visual_list.append(visual_data)
        except Exception as e:
            logger.error(f"æ„å»º VisualData åˆ—è¡¨å¤±è´¥: {e}")
            logger.error(f"visual æ•°æ®: {visual_raw}")
            raise Exception(f"æ„å»ºè§†è§‰æ•°æ®å¤±è´¥: {str(e)}")
        
        # æ„å»ºç­–ç•¥åˆ—è¡¨ï¼ˆéœ€åœ¨è¡¥è¶³ visual å‰å®Œæˆï¼Œå› è¡¥è¶³é€»è¾‘ä¾èµ– strategiesï¼‰
        strategies_list = []
        try:
            for s in analysis_data.get("strategies", []):
                strategies_list.append(StrategyItem(
                    id=s.get("id", ""),
                    label=s.get("label", ""),
                    emoji=s.get("emoji", ""),
                    title=s.get("title", ""),
                    content=s.get("content", "")
                ))
        except Exception as e:
            logger.error(f"æ„å»ºç­–ç•¥åˆ—è¡¨å¤±è´¥: {e}")
            logger.error(f"strategies æ•°æ®: {analysis_data.get('strategies')}")
            raise Exception(f"æ„å»ºç­–ç•¥åˆ—è¡¨å¤±è´¥: {str(e)}")
        
        # 7b. å…œåº•ï¼šä¸è¶³ 3 ä¸ª visual æ—¶ï¼Œä» strategies è¡¥è¶³ï¼ˆæ¨èç­–ç•¥ç±»å›¾ç‰‡ï¼‰
        if len(visual_list) < 3 and strategies_list:
            strategies_to_use = [s for s in strategies_list if s.id and s.id != "s0"]
            if not strategies_to_use:
                strategies_to_use = strategies_list[:3]
            last_ti = visual_list[-1].transcript_index if visual_list else 0
            last_speaker = visual_list[-1].speaker if visual_list else "Speaker_0"
            idx = 0
            while len(visual_list) < 3 and strategies_to_use:
                s = strategies_to_use[idx % len(strategies_to_use)]
                idx += 1
                content_preview = (s.content or "").replace("\n", " ").strip()
                if len(content_preview) > 80:
                    content_preview = content_preview[:80] + "â€¦"
                image_prompt = f"å®«å´éªå‰åœåŠ›åŠ¨ç”»é£æ ¼ï¼Œæ¸©æš–è‡ªç„¶è‰²è°ƒã€‚ç”»é¢è¡¨ç°æ¨èç­–ç•¥ã€Œ{s.title or s.label}ã€ï¼š{content_preview or 'è¯¥ç­–ç•¥çš„æ ¸å¿ƒå»ºè®®'}ã€‚å·¦ä¾§ä¸ºç”¨æˆ·é‡‡çº³è¯¥ç­–ç•¥æ—¶çš„è‡ªä¿¡å§¿æ€ï¼Œå³ä¾§ä¸ºå¯¹æ–¹ååº”ã€‚"
                visual_list.append(VisualData(
                    transcript_index=last_ti,
                    speaker=last_speaker,
                    image_prompt=image_prompt,
                    emotion="ç­–ç•¥å»ºè®®",
                    subtext="",
                    context=f"æ¨èç­–ç•¥: {s.title}",
                    my_inner="",
                    other_inner=""
                ))
                logger.info(f"è¡¥è¶³ visual: ç­–ç•¥ã€Œ{s.title}ã€-> ç¬¬ {len(visual_list)} å¼ ")
        
        # 8. åå¤„ç†ï¼ˆå¯é€‰ï¼‰
        # TODO: å¦‚æœå­˜åœ¨ scripts/postprocess.pyï¼Œæ‰§è¡Œåå¤„ç†
        
        execution_time_ms = int((time.time() - start_time) * 1000)
        
        logger.info(f"æŠ€èƒ½æ‰§è¡ŒæˆåŠŸ: {skill_id}")
        logger.info(f"  - æ‰§è¡Œè€—æ—¶: {execution_time_ms}ms")
        logger.info(f"  - å…³é”®æ—¶åˆ»æ•°é‡: {len(visual_list)}")
        logger.info(f"  - ç­–ç•¥æ•°é‡: {len(strategies_list)}")
        
        # è¿”å›ç»“æœ
        return {
            "skill_id": skill_id,
            "result": Call2Response(
                visual=visual_list,
                strategies=strategies_list
            ),
            "execution_time_ms": execution_time_ms,
            "success": True
        }
        
    except Exception as e:
        execution_time_ms = int((time.time() - start_time) * 1000) if 'start_time' in locals() else 0
        logger.error(f"æŠ€èƒ½æ‰§è¡Œå¤±è´¥: {skill_id}, é”™è¯¯: {e}")
        return {
            "skill_id": skill_id,
            "result": None,
            "execution_time_ms": execution_time_ms,
            "success": False,
            "error_message": str(e)
        }
