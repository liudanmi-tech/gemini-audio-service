"""
FastAPI éŸ³é¢‘åˆ†æå¾®æœåŠ¡
é€šè¿‡ Google Gemini API åˆ†æä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶
"""

import os
import json
import time
import tempfile
import traceback
import logging
import uuid
import asyncio
from contextlib import asynccontextmanager
from io import BytesIO
from typing import List, Optional, Any, Tuple
from pathlib import Path
from datetime import datetime

import google.generativeai as genai
from google import genai as genai_new  # æ–°çš„ SDK ç”¨äºå›¾ç‰‡ç”Ÿæˆ
from google.genai import types as genai_types
from fastapi import FastAPI, UploadFile, File, HTTPException, Query, Depends, Request
from fastapi.responses import JSONResponse, Response
from pydantic import BaseModel
from dotenv import load_dotenv
import base64

# é…ç½®æ—¥å¿—
# ä½¿ç”¨ç”¨æˆ·ç›®å½•ä¸‹çš„æ—¥å¿—æ–‡ä»¶ï¼Œé¿å…æƒé™é—®é¢˜
log_file_path = os.path.expanduser('~/gemini-audio-service.log')
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler(log_file_path)
    ]
)
logger = logging.getLogger(__name__)

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸï¼šå¯åŠ¨æ—¶åˆå§‹åŒ–æ•°æ®åº“ä¸æŠ€èƒ½ï¼Œå…³é—­æ—¶é‡Šæ”¾è¿æ¥ï¼ˆæ›¿ä»£å·²å¼ƒç”¨çš„ on_eventï¼‰"""
    # === startup ===
    use_proxy = os.getenv("PROXY_FORCE_LOCALHOST", "").lower() == "true" or bool(os.getenv("PROXY_URL"))
    proxy_url = os.getenv("PROXY_URL", "http://127.0.0.1/secret-channel")
    if use_proxy and proxy_url:
        try:
            from urllib.parse import urlparse
            parsed = urlparse(proxy_url)
            host = parsed.hostname or "127.0.0.1"
            port = parsed.port or (80 if parsed.scheme == "http" else 443)
            sock = __import__("socket").socket(__import__("socket").AF_INET, __import__("socket").SOCK_STREAM)
            sock.settimeout(3)
            sock.connect((host, port))
            sock.close()
            logger.info(f"âœ… ä»£ç†å¯è¾¾: {host}:{port}")
        except (OSError, Exception) as e:
            err = str(e).lower()
            if "refused" in err or "111" in err:
                logger.warning(
                    "âš ï¸ ä»£ç†è¿æ¥è¢«æ‹’ç» (Connection refused)ã€‚å½•éŸ³åˆ†æä¸Šä¼ ä¼šå¤±è´¥ã€‚"
                    " è¯·åœ¨æœåŠ¡å™¨ä¸Šå¯åŠ¨ Nginxï¼ˆæˆ–ä»£ç†ï¼‰ï¼Œå¹¶ç¡®ä¿ç›‘å¬ %s:%sï¼Œä¸” /secret-channel å·²é…ç½®è½¬å‘åˆ° Geminiã€‚",
                    host, port
                )
            else:
                logger.warning(f"âš ï¸ ä»£ç†æ£€æµ‹å¤±è´¥: {e}")
    try:
        logger.info("æ­£åœ¨åˆå§‹åŒ–æ•°æ®åº“...")
        await init_db()
        logger.info("âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
        try:
            from database.connection import engine
            from sqlalchemy import text
            async with engine.connect() as conn:
                await conn.execute(text("SELECT 1"))
            logger.info("âœ… æ•°æ®åº“è¿æ¥æ± å·²é¢„çƒ­")
        except Exception as e:
            logger.warning(f"è¿æ¥æ± é¢„çƒ­è·³è¿‡: {e}")
        try:
            logger.info("æ­£åœ¨åˆå§‹åŒ–æŠ€èƒ½...")
            from database.connection import AsyncSessionLocal
            async with AsyncSessionLocal() as db:
                try:
                    registered_skills = await initialize_skills(db)
                    logger.info(f"âœ… æŠ€èƒ½åˆå§‹åŒ–å®Œæˆï¼Œå…±æ³¨å†Œ {len(registered_skills)} ä¸ªæŠ€èƒ½")
                    for skill in registered_skills:
                        logger.info(f"  - {skill['skill_id']}: {skill['name']}")
                except Exception as e:
                    logger.error(f"âŒ æŠ€èƒ½åˆå§‹åŒ–å¤±è´¥: {e}")
                    logger.error(traceback.format_exc())
                    await db.rollback()
        except Exception as e:
            logger.error(f"âŒ æŠ€èƒ½åˆå§‹åŒ–å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
        logger.error(traceback.format_exc())
    yield
    # === shutdown ===
    try:
        await close_db()
        logger.info("âœ… æ•°æ®åº“è¿æ¥å·²å…³é—­")
    except Exception as e:
        logger.error(f"å…³é—­æ•°æ®åº“è¿æ¥æ—¶å‡ºé”™: {e}")


# åˆå§‹åŒ– FastAPI åº”ç”¨
app = FastAPI(title="éŸ³é¢‘åˆ†ææœåŠ¡", description="é€šè¿‡ Gemini API åˆ†æéŸ³é¢‘æ–‡ä»¶", lifespan=lifespan)


@app.middleware("http")
async def log_requests(request: Request, call_next):
    """è¯·æ±‚/å“åº”æ—¥å¿—ï¼šä¾¿äºæ’æŸ¥ 502 ä¸åˆ—è¡¨æ¥å£é—®é¢˜"""
    start = time.time()
    is_extract = "extract-segment" in request.url.path
    if is_extract:
        logger.info(f"[Request] ===== extract-segment æ”¶åˆ°è¯·æ±‚ ===== {request.method} {request.url.path}")
    else:
        logger.info(f"[Request] {request.method} {request.url.path}")
    try:
        response = await call_next(request)
        duration = time.time() - start
        status = response.status_code
        if is_extract:
            logger.info(f"[Response] ===== extract-segment è¿”å› ===== path={request.url.path} status={status} duration={duration:.3f}s")
        else:
            logger.info(f"[Response] {request.url.path} status={status} duration={duration:.3f}s")
        if status >= 500:
            logger.error(f"[Response] 5xx path={request.url.path} status={status} duration={duration:.3f}s")
        return response
    except Exception as e:
        duration = time.time() - start
        logger.error(f"[Response] Exception path={request.url.path} error={type(e).__name__}: {e} duration={duration:.3f}s")
        logger.error(traceback.format_exc())
        if is_extract:
            logger.error(f"[Response] ===== extract-segment å‘ç”Ÿæœªæ•è·å¼‚å¸¸ ===== è¯¦è§ä¸Šæ–¹å †æ ˆ")
        raise


# æ³¨å†Œè®¤è¯è·¯ç”±
from api.auth import router as auth_router
app.include_router(auth_router)

# æ³¨å†ŒæŠ€èƒ½ç®¡ç†è·¯ç”±
from api.skills import router as skills_router
app.include_router(skills_router)

# æ³¨å†Œæ¡£æ¡ˆç®¡ç†è·¯ç”±
from api.profiles import router as profiles_router
app.include_router(profiles_router)

# æ³¨å†ŒéŸ³é¢‘ç‰‡æ®µè·¯ç”±
from api.audio_segments import router as audio_segments_router
app.include_router(audio_segments_router)

# å¯¼å…¥æ•°æ®åº“ç›¸å…³
from database.connection import get_db, init_db, close_db
from database.models import User, Session, AnalysisResult, StrategyAnalysis, Skill, SkillExecution, Profile
from auth.jwt_handler import get_current_user_id, get_current_user
from sqlalchemy import select, func
from sqlalchemy.ext.asyncio import AsyncSession

# å¯¼å…¥æŠ€èƒ½æ¨¡å—
from skills.router import classify_scene, match_skills
from skills.registry import get_skill, initialize_skills
from skills.executor import execute_skill

# é…ç½® Gemini API
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
PROXY_URL_RAW = os.getenv("PROXY_URL", "http://47.79.254.213/secret-channel")
USE_PROXY = os.getenv("USE_PROXY", "true").lower() == "true"
# å½“åº”ç”¨ä¸ä»£ç†åœ¨åŒä¸€å°æœºæ—¶è®¾ä¸º trueï¼Œå¯é¿å… Connection refusedï¼ˆè¯·æ±‚èµ° 127.0.0.1ï¼‰
PROXY_FORCE_LOCALHOST = os.getenv("PROXY_FORCE_LOCALHOST", "true").lower() == "true"

if PROXY_FORCE_LOCALHOST and USE_PROXY and PROXY_URL_RAW:
    from urllib.parse import urlparse, urlunparse
    _p = urlparse(PROXY_URL_RAW)
    PROXY_URL = urlunparse((_p.scheme, "127.0.0.1" + (f":{_p.port}" if _p.port else ""), _p.path or "", _p.params, _p.query, _p.fragment))
    logger.info(f"PROXY_FORCE_LOCALHOST å·²å¯ç”¨ï¼Œä»£ç†è¯·æ±‚ä½¿ç”¨: {PROXY_URL}")
else:
    PROXY_URL = PROXY_URL_RAW

if not GEMINI_API_KEY:
    raise ValueError("è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® GEMINI_API_KEY")

# ç­–ç•¥/åœºæ™¯æ¨¡å‹åï¼Œå¯é€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–ï¼ˆé»˜è®¤ gemini-3-flash-previewï¼‰
GEMINI_FLASH_MODEL = os.getenv("GEMINI_FLASH_MODEL", "gemini-3-flash-preview")

# é…ç½® Gemini å®¢æˆ·ç«¯ï¼Œä½¿ç”¨åå‘ä»£ç†æœåŠ¡å™¨
logger.info(f"API Key: {GEMINI_API_KEY[:10]}... (å·²éšè—)")
if USE_PROXY and PROXY_URL:
    logger.info(f"åå‘ä»£ç†æ¨¡å¼: å¯ç”¨ï¼Œä»£ç†æœåŠ¡å™¨: {PROXY_URL}")
    
    # å¯¹äºåå‘ä»£ç†ï¼Œéœ€è¦ä¿®æ”¹ API çš„ base URL
    # google-generativeai SDK ä½¿ç”¨ googleapiclient å’Œ httplib2
    try:
        from urllib.parse import urlparse, urlunparse, urljoin
        import googleapiclient.http
        import httplib2
        
        parsed = urlparse(PROXY_URL)
        logger.info(f"ä»£ç†æœåŠ¡å™¨ä¸»æœº: {parsed.hostname}, ç«¯å£: {parsed.port or 80}")
        
        # ä¿å­˜åŸå§‹çš„ execute æ–¹æ³•
        original_execute = googleapiclient.http.HttpRequest.execute
        
        def patched_execute(self, http=None, num_retries=0):
            """ä¿®æ”¹è¯·æ±‚ URLï¼Œå°† Google API çš„ URL æ›¿æ¢ä¸ºä»£ç†æœåŠ¡å™¨ URL"""
            if http is None:
                http = self.http
            
            # è·å–åŸå§‹ URI
            original_uri = self.uri
            
            # å¦‚æœ URI åŒ…å« generativelanguage.googleapis.comï¼Œæ›¿æ¢ä¸ºä»£ç†æœåŠ¡å™¨
            if 'generativelanguage.googleapis.com' in original_uri:
                # æå–è·¯å¾„éƒ¨åˆ†
                from urllib.parse import urlparse, urlunparse
                parsed_uri = urlparse(original_uri)
                
                # æ„å»ºæ–°çš„ URLï¼šä½¿ç”¨ä»£ç†æœåŠ¡å™¨ + /secret-channel + åŸå§‹è·¯å¾„
                # ä¾‹å¦‚ï¼šhttps://generativelanguage.googleapis.com/v1beta/... 
                # -> http://47.79.254.213/secret-channel/v1beta/...
                new_path = f"/secret-channel{parsed_uri.path}"
                
                new_uri = urlunparse((
                    parsed.scheme,  # http
                    f"{parsed.hostname}:{parsed.port or 80}",  # ä»£ç†æœåŠ¡å™¨åœ°å€
                    new_path,  # æ·»åŠ  /secret-channel å‰ç¼€
                    parsed_uri.params,
                    parsed_uri.query,
                    parsed_uri.fragment
                ))
                
                logger.info(f"ä¿®æ”¹è¯·æ±‚ URL: {original_uri} -> {new_uri}")
                self.uri = new_uri
            
            # è°ƒç”¨åŸå§‹æ–¹æ³•
            return original_execute(self, http, num_retries)
        
        # æ›¿æ¢ execute æ–¹æ³•
        googleapiclient.http.HttpRequest.execute = patched_execute
        logger.info("å·² patch googleapiclient.http.HttpRequest.execute ä»¥ä½¿ç”¨åå‘ä»£ç†")
        
        # è®©æ–‡ä»¶æœåŠ¡çš„ discovery è¯·æ±‚ä¹Ÿèµ°ä»£ç†ï¼ˆå¦åˆ™ä¸Šä¼ æ—¶é¦–æ¬¡ discovery å¯èƒ½ç›´è¿ Googleï¼‰
        try:
            import google.generativeai.client as _genai_client
            _genai_client.GENAI_API_DISCOVERY_URL = urlunparse((
                parsed.scheme or "http",
                f"{parsed.hostname or '127.0.0.1'}:{parsed.port or 80}",
                "/secret-channel/$discovery/rest",
                "", "", ""
            ))
            logger.info(f"å·²è®¾ç½®æ–‡ä»¶æœåŠ¡ discovery URL: {_genai_client.GENAI_API_DISCOVERY_URL}")
        except Exception as pe:
            logger.warning(f"è®¾ç½®æ–‡ä»¶æœåŠ¡ discovery URL å¤±è´¥: {pe}")
        
    except Exception as e:
        logger.warning(f"é…ç½®åå‘ä»£ç†æ—¶å‡ºé”™: {e}")
        logger.error(traceback.format_exc())
        logger.info("å°†å°è¯•ä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®")
else:
    logger.info("ä»£ç†æ¨¡å¼: ç¦ç”¨ï¼Œç›´æ¥è¿æ¥ Gemini API")

# é…ç½® Gemini API
try:
    # å¦‚æœä½¿ç”¨åå‘ä»£ç†ï¼Œå°è¯•é€šè¿‡ client_options è®¾ç½®
    config_params = {
        'api_key': GEMINI_API_KEY,
        'transport': 'rest'
    }
    
    # å°è¯•è®¾ç½® client_optionsï¼ˆå¦‚æœ SDK æ”¯æŒï¼‰
    if USE_PROXY and PROXY_URL:
        try:
            # æŸäº›ç‰ˆæœ¬å¯èƒ½æ”¯æŒ client_options
            config_params['client_options'] = {
                'api_endpoint': PROXY_URL
            }
            logger.info(f"å°è¯•é€šè¿‡ client_options è®¾ç½® API endpoint: {PROXY_URL}")
        except TypeError:
            logger.info("SDK ä¸æ”¯æŒ client_optionsï¼Œå°†ä½¿ç”¨å…¶ä»–æ–¹æ³•")
    
    genai.configure(**config_params)
    logger.info("Gemini API é…ç½®å®Œæˆï¼ˆä½¿ç”¨ REST ä¼ è¾“æ¨¡å¼ï¼‰")
    
except Exception as e:
    logger.error(f"é…ç½® Gemini API æ—¶å‡ºé”™: {e}")
    raise

# é…ç½®é˜¿é‡Œäº‘ OSS
OSS_ACCESS_KEY_ID = os.getenv("OSS_ACCESS_KEY_ID")
OSS_ACCESS_KEY_SECRET = os.getenv("OSS_ACCESS_KEY_SECRET")
OSS_ENDPOINT = os.getenv("OSS_ENDPOINT")
OSS_BUCKET_NAME = os.getenv("OSS_BUCKET_NAME")
OSS_CDN_DOMAIN = os.getenv("OSS_CDN_DOMAIN")  # å¯é€‰ï¼Œå¦‚æœä½¿ç”¨ CDN
USE_OSS = os.getenv("USE_OSS", "true").lower() == "true"  # æ˜¯å¦å¯ç”¨ OSS

# åˆå§‹åŒ– OSS å®¢æˆ·ç«¯
oss_bucket = None
if USE_OSS:
    if not all([OSS_ACCESS_KEY_ID, OSS_ACCESS_KEY_SECRET, OSS_ENDPOINT, OSS_BUCKET_NAME]):
        logger.warning("âš ï¸ OSS é…ç½®ä¸å®Œæ•´ï¼Œå°†ç¦ç”¨ OSS åŠŸèƒ½")
        logger.warning("éœ€è¦é…ç½®: OSS_ACCESS_KEY_ID, OSS_ACCESS_KEY_SECRET, OSS_ENDPOINT, OSS_BUCKET_NAME")
        USE_OSS = False
    else:
        try:
            import oss2
            auth = oss2.Auth(OSS_ACCESS_KEY_ID, OSS_ACCESS_KEY_SECRET)
            oss_bucket = oss2.Bucket(auth, OSS_ENDPOINT, OSS_BUCKET_NAME)
            logger.info(f"âœ… OSS é…ç½®æˆåŠŸ")
            logger.info(f"OSS Endpoint: {OSS_ENDPOINT}")
            logger.info(f"OSS Bucket: {OSS_BUCKET_NAME}")
            if OSS_CDN_DOMAIN:
                logger.info(f"OSS CDN Domain: {OSS_CDN_DOMAIN}")
        except ImportError:
            logger.error("âŒ æœªå®‰è£… oss2 åº“ï¼Œè¯·è¿è¡Œ: pip install oss2")
            USE_OSS = False
        except Exception as e:
            logger.error(f"âŒ OSS åˆå§‹åŒ–å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            USE_OSS = False
else:
    logger.info("OSS åŠŸèƒ½å·²ç¦ç”¨ï¼ˆUSE_OSS=falseï¼‰")

# å®šä¹‰è¿”å›æ•°æ®æ¨¡å‹
class DialogueItem(BaseModel):
    """å•ä¸ªå¯¹è¯é¡¹çš„æ•°æ®æ¨¡å‹"""
    speaker: str  # è¯´è¯äººæ ‡è¯†ï¼ˆå¦‚ï¼šè¯´è¯äºº1ã€è¯´è¯äººAç­‰ï¼‰
    content: str  # è¯´è¯å†…å®¹
    tone: str  # è¯´è¯è¯­æ°”ï¼ˆå¦‚ï¼šå¹³é™ã€æ„¤æ€’ã€è½»æ¾ã€ç„¦è™‘ç­‰ï¼‰
    timestamp: Optional[str] = None  # æ—¶é—´æˆ³ï¼ˆæ ¼å¼ï¼š"MM:SS"ï¼‰
    is_me: Optional[bool] = False  # æ˜¯å¦æ˜¯æˆ‘è¯´çš„ï¼ˆSpeaker_1ä¸ºtrueï¼‰

class AudioAnalysisResponse(BaseModel):
    """éŸ³é¢‘åˆ†æç»“æœçš„æ•°æ®æ¨¡å‹"""
    speaker_count: int  # è¯´è¯äººæ•°
    dialogues: List[DialogueItem]  # æ‰€æœ‰å¯¹è¯åˆ—è¡¨ï¼ŒæŒ‰æ—¶é—´é¡ºåº
    risks: List[str]  # é£é™©ç‚¹åˆ—è¡¨

# Call #1 æ•°æ®æ¨¡å‹ï¼ˆæ–°çš„åˆ†ææ ¼å¼ï¼‰
class TranscriptItem(BaseModel):
    """è½¬å½•é¡¹æ•°æ®æ¨¡å‹"""
    speaker: str  # è¯´è¯äººæ ‡è¯†
    text: str  # å¯¹è¯å†…å®¹
    timestamp: Optional[str] = None  # æ—¶é—´æˆ³ï¼ˆæ ¼å¼ï¼š"MM:SS"ï¼‰
    is_me: bool  # æ˜¯å¦æ˜¯æˆ‘è¯´çš„

class Call1Response(BaseModel):
    """Call #1 åˆ†æå“åº”"""
    mood_score: int  # æƒ…ç»ªåˆ†æ•° (0-100)
    stats: dict  # ç»Ÿè®¡ä¿¡æ¯ï¼ŒåŒ…å« sigh å’Œ laugh
    summary: str  # å¯¹è¯æ€»ç»“
    transcript: List[TranscriptItem]  # è½¬å½•åˆ—è¡¨

# Call #2 æ•°æ®æ¨¡å‹ï¼ˆç­–ç•¥åˆ†æï¼‰- ä» schemas å¯¼å…¥ï¼Œé¿å…ä¸ skills å¾ªç¯ä¾èµ–
from schemas.strategy_schemas import StrategyItem, VisualData, Call2Response, parse_gemini_response


def wait_for_file_active(file: Any, max_wait_time=300) -> Any:
    """
    ç­‰å¾…æ–‡ä»¶çŠ¶æ€å˜ä¸º ACTIVE
    
    Args:
        file: Gemini æ–‡ä»¶å¯¹è±¡
        max_wait_time: æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ 5 åˆ†é’Ÿ
        
    Returns:
        çŠ¶æ€ä¸º ACTIVE çš„æ–‡ä»¶å¯¹è±¡
    """
    start_time = time.time()
    logger.info(f"[wait_for_file_active] ç­‰å¾…æ–‡ä»¶å¤„ç†ï¼Œå½“å‰çŠ¶æ€: {file.state}")
    
    while file.state.name == "PROCESSING":
        elapsed = time.time() - start_time
        if elapsed > max_wait_time:
            raise Exception(f"æ–‡ä»¶å¤„ç†è¶…æ—¶ï¼ˆè¶…è¿‡ {max_wait_time} ç§’ï¼‰ï¼Œå½“å‰çŠ¶æ€: {file.state}")
        
        time.sleep(2)
        try:
            file = genai.get_file(file.name)
            logger.info(f"[wait_for_file_active] æ–‡ä»¶çŠ¶æ€: {file.state} (å·²ç­‰å¾… {int(elapsed)} ç§’)")
        except Exception as e:
            logger.warning(f"[wait_for_file_active] è·å–æ–‡ä»¶çŠ¶æ€æ—¶å‡ºé”™: {e}")
            time.sleep(2)
            continue
    
    if file.state.name != "ACTIVE":
        raise Exception(f"æ–‡ä»¶å¤„ç†å¤±è´¥ï¼ŒçŠ¶æ€: {file.state}")
    
    return file


def upload_image_to_oss(image_bytes: bytes, user_id: str, session_id: str, image_index: int,
                        content_type: str = "image/png") -> Optional[str]:
    """
    ä¸Šä¼ å›¾ç‰‡åˆ°é˜¿é‡Œäº‘ OSS
    
    Args:
        image_bytes: å›¾ç‰‡çš„å­—èŠ‚æ•°æ®
        user_id: ç”¨æˆ· ID
        session_id: ä¼šè¯ ID
        image_index: å›¾ç‰‡ç´¢å¼•
        content_type: MIME ç±»å‹ï¼Œé»˜è®¤ image/png
        
    Returns:
        OSS URLï¼Œå¦‚æœå¤±è´¥è¿”å› None
    """
    if not USE_OSS or oss_bucket is None:
        logger.warning("OSS æœªå¯ç”¨æˆ–æœªåˆå§‹åŒ–ï¼Œæ— æ³•ä¸Šä¼ å›¾ç‰‡")
        return None
    
    try:
        # ç»Ÿä¸€ä½¿ç”¨ .png åç¼€ä¾¿äº API æ‹‰å–
        oss_key = f"images/{user_id}/{session_id}/{image_index}.png"
        
        logger.info(f"ä¸Šä¼ å›¾ç‰‡åˆ° OSS: {oss_key} type={content_type}")
        logger.info(f"å›¾ç‰‡å¤§å°: {len(image_bytes)} å­—èŠ‚")
        
        start_time = time.time()
        headers = {'Content-Type': content_type}
        oss_bucket.put_object(oss_key, image_bytes, headers=headers)
        upload_time = time.time() - start_time
        
        logger.info(f"âœ… å›¾ç‰‡ä¸Šä¼ æˆåŠŸï¼Œè€—æ—¶: {upload_time:.2f} ç§’")
        
        # æ„å»ºå›¾ç‰‡ URL
        if OSS_CDN_DOMAIN:
            # ä½¿ç”¨ CDN åŸŸå
            image_url = f"https://{OSS_CDN_DOMAIN}/{oss_key}"
        else:
            # ä½¿ç”¨ OSS ç›´æ¥è®¿é—® URL
            # æ ¼å¼: https://{bucket}.{endpoint}/{key}
            if OSS_ENDPOINT.startswith('http://'):
                endpoint = OSS_ENDPOINT.replace('http://', 'https://')
            elif OSS_ENDPOINT.startswith('https://'):
                endpoint = OSS_ENDPOINT
            else:
                endpoint = f"https://{OSS_BUCKET_NAME}.{OSS_ENDPOINT}"
            image_url = f"{endpoint}/{oss_key}"
        
        logger.info(f"âœ… å›¾ç‰‡ URL: {image_url}")
        return image_url
        
    except Exception as e:
        logger.error(f"âŒ ä¸Šä¼ å›¾ç‰‡åˆ° OSS å¤±è´¥: {e}")
        logger.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
        logger.error(f"å®Œæ•´é”™è¯¯å †æ ˆ:")
        logger.error(traceback.format_exc())
        return None


# åŸéŸ³é¢‘æ˜¯å¦ä¸Šä¼ é˜¿é‡Œäº‘ OSSï¼ˆé»˜è®¤ falseï¼šä»…æœ¬åœ°ï¼Œç›´æ¥èµ° Geminiï¼‰
USE_OSS_FOR_ORIGINAL_AUDIO = os.getenv("USE_OSS_FOR_ORIGINAL_AUDIO", "false").lower() == "true"


def persist_original_audio(
    session_id: str,
    temp_file_path: str,
    file_filename: str,
    user_id: str,
) -> Tuple[Optional[str], Optional[str]]:
    """
    å°†åŸéŸ³é¢‘æŒä¹…åŒ–åˆ°æœ¬åœ°ï¼ˆæˆ– OSSï¼Œéœ€æ˜¾å¼å¯ç”¨ï¼‰ï¼Œä¾›åç»­å‰ªåˆ‡ä¸å£°çº¹ä½¿ç”¨ã€‚
    é»˜è®¤ä¸ä¸Šä¼ é˜¿é‡Œäº‘ï¼Œç›´æ¥èµ° Gemini åˆ†æã€‚
    Returns:
        (audio_url, audio_path): OSS æ—¶ url æœ‰å€¼ï¼›ä»…æœ¬åœ°æ—¶ path æœ‰å€¼ã€‚
    """
    audio_url: Optional[str] = None
    audio_path: Optional[str] = None
    file_ext = Path(file_filename).suffix.lower() if file_filename else ".m4a"
    if not file_ext.startswith("."):
        file_ext = "." + file_ext

    if USE_OSS_FOR_ORIGINAL_AUDIO and USE_OSS and oss_bucket is not None:
        try:
            oss_key = f"sessions/{user_id}/{session_id}/original{file_ext}"
            with open(temp_file_path, "rb") as f:
                content = f.read()
            headers = {"Content-Type": "audio/mp4" if file_ext == ".m4a" else "application/octet-stream"}
            oss_bucket.put_object(oss_key, content, headers=headers)
            if OSS_CDN_DOMAIN:
                audio_url = f"https://{OSS_CDN_DOMAIN}/{oss_key}"
            else:
                if OSS_ENDPOINT.startswith("http://"):
                    endpoint = OSS_ENDPOINT.replace("http://", "https://")
                elif OSS_ENDPOINT.startswith("https://"):
                    endpoint = OSS_ENDPOINT
                else:
                    endpoint = f"https://{OSS_BUCKET_NAME}.{OSS_ENDPOINT}"
                audio_url = f"{endpoint}/{oss_key}"
            logger.info(f"[åˆ†æ-{session_id}] åŸéŸ³é¢‘å·²ä¸Šä¼  OSS: {audio_url[:80]}...")
        except Exception as e:
            logger.warning(f"åŸéŸ³é¢‘ä¸Šä¼  OSS å¤±è´¥ï¼Œå°†ä½¿ç”¨æœ¬åœ°è·¯å¾„: {e}")
            audio_url = None

    if not audio_url:
        # æœ¬åœ°å­˜å‚¨ï¼ˆé»˜è®¤è·¯å¾„ï¼Œä¾›å‰ªåˆ‡ä¸å£°çº¹ä½¿ç”¨ï¼‰
        storage_dir = os.getenv("AUDIO_STORAGE_DIR", "data/audio/sessions")
        os.makedirs(storage_dir, exist_ok=True)
        local_name = f"{session_id}{file_ext}"
        dest_path = os.path.join(storage_dir, local_name)
        try:
            import shutil
            shutil.copy2(temp_file_path, dest_path)
            audio_path = dest_path
            logger.info(f"[åˆ†æ-{session_id}] åŸéŸ³é¢‘å·²ä¿å­˜åˆ°æœ¬åœ°: {audio_path}")
        except Exception as e:
            logger.warning(f"åŸéŸ³é¢‘ä¿å­˜æœ¬åœ°å¤±è´¥: {e}")

    return (audio_url, audio_path)


def _fetch_image_bytes(url: str, timeout: float = 10.0) -> Optional[Tuple[bytes, str]]:
    """
    ä» URL ä¸‹è½½å›¾ç‰‡ï¼Œè¿”å› (bytes, mime_type) æˆ– Noneã€‚
    æ”¯æŒ http/httpsï¼Œç”¨äºè·å–æ¡£æ¡ˆç…§ç‰‡ä½œä¸ºå›¾ç‰‡ç”Ÿæˆå‚è€ƒã€‚
    æ³¨æ„ï¼š/api/v1/images/ éœ€ JWTï¼ŒæœåŠ¡ç«¯å†…éƒ¨è¯·ç”¨ _fetch_profile_image_from_ossã€‚
    """
    if not url or not isinstance(url, str) or not url.strip():
        return None
    url = url.strip()
    if not url.startswith(("http://", "https://")):
        return None
    try:
        from urllib.request import Request, urlopen
        req = Request(url, headers={"User-Agent": "gemini-audio-service/1.0"})
        with urlopen(req, timeout=timeout) as resp:
            data = resp.read()
            ctype = resp.headers.get("Content-Type", "").split(";")[0].strip().lower()
            if "png" in ctype:
                mime = "image/png"
            elif "webp" in ctype:
                mime = "image/webp"
            else:
                mime = "image/jpeg"
            if len(data) > 7 * 1024 * 1024:  # 7MB limit for Gemini inline
                logger.warning(f"[æ¡£æ¡ˆç…§ç‰‡] å›¾ç‰‡è¿‡å¤§ ({len(data)} bytes)ï¼Œè·³è¿‡")
                return None
            return (data, mime)
    except Exception as e:
        logger.warning(f"[æ¡£æ¡ˆç…§ç‰‡] ä¸‹è½½å¤±è´¥ url={url[:80]}...: {e}")
        return None


def _fetch_profile_image_from_oss(user_id: str, profile_id: str) -> Optional[Tuple[bytes, str]]:
    """
    ä» OSS ç›´æ¥è¯»å–æ¡£æ¡ˆç…§ç‰‡ï¼Œç”¨äºå›¾ç‰‡ç”Ÿæˆå‚è€ƒï¼ˆé¿å… API éœ€ JWT çš„é—®é¢˜ï¼‰ã€‚
    è·¯å¾„: images/{user_id}/profile_{profile_id}/0.png
    """
    if not USE_OSS or oss_bucket is None:
        return None
    try:
        oss_key = f"images/{user_id}/profile_{profile_id}/0.png"
        obj = oss_bucket.get_object(oss_key)
        data = obj.read()
        if len(data) > 7 * 1024 * 1024:
            logger.warning(f"[æ¡£æ¡ˆç…§ç‰‡] OSS å›¾ç‰‡è¿‡å¤§ ({len(data)} bytes)ï¼Œè·³è¿‡")
            return None
        if len(data) >= 2 and data[0:2] == b"\xff\xd8":
            mime = "image/jpeg"
        elif len(data) >= 4 and data[0:4] == b"\x89PNG":
            mime = "image/png"
        else:
            mime = "image/jpeg"
        return (data, mime)
    except Exception as e:
        logger.debug(f"[æ¡£æ¡ˆç…§ç‰‡] OSS è¯»å–å¤±è´¥ profile_id={profile_id}: {e}")
        return None


async def _get_profile_reference_images(session_id: str, user_id: str, db: AsyncSession) -> List[Tuple[bytes, str]]:
    """
    æ ¹æ® speaker_mapping è·å–å·¦å³äººç‰©ï¼ˆç”¨æˆ·/å¯¹æ–¹ï¼‰çš„æ¡£æ¡ˆç…§ç‰‡ï¼Œç”¨äºå›¾ç‰‡ç”Ÿæˆå‚è€ƒã€‚
    ä¼˜å…ˆä» OSS ç›´æ¥è¯»å–ï¼ˆè·¯å¾„ images/{user_id}/profile_{id}/0.pngï¼‰ï¼Œé¿å… API éœ€ JWTã€‚
    è¿”å› [(left_bytes, mime), (right_bytes, mime), ...]ï¼Œé¡ºåºä¸ºå·¦ä¾§ï¼ˆç”¨æˆ·ï¼‰ã€å³ä¾§ï¼ˆå¯¹æ–¹ï¼‰ã€‚
    """
    result = []
    try:
        ar_q = await db.execute(
            select(AnalysisResult).where(AnalysisResult.session_id == uuid.UUID(session_id))
        )
        ar = ar_q.scalar_one_or_none()
        if not ar or not isinstance(getattr(ar, "speaker_mapping", None), dict):
            logger.info(f"[æ¡£æ¡ˆç…§ç‰‡] session_id={session_id} æ—  speaker_mappingï¼Œæ— æ³•è·å–å‚è€ƒå›¾")
            return result
        speaker_mapping = ar.speaker_mapping
        profile_ids = [str(pid) for pid in speaker_mapping.values()]
        if not profile_ids:
            logger.info(f"[æ¡£æ¡ˆç…§ç‰‡] session_id={session_id} speaker_mapping ä¸ºç©º")
            return result
        logger.info(f"[æ¡£æ¡ˆç…§ç‰‡] speaker_mapping={speaker_mapping} profile_ids={profile_ids}")
        
        prof_q = await db.execute(
            select(Profile).where(
                Profile.user_id == uuid.UUID(user_id),
                Profile.id.in_([uuid.UUID(pid) for pid in profile_ids])
            )
        )
        profiles = {str(p.id): p for p in prof_q.scalars().all()}
        left_pid, right_pid = None, None
        for sp, pid in speaker_mapping.items():
            pid_str = str(pid)
            if pid_str not in profiles:
                continue
            rel = getattr(profiles[pid_str], "relationship_type", "") or ""
            if rel == "è‡ªå·±":
                left_pid = pid_str
            else:
                right_pid = pid_str
        if not left_pid and profile_ids:
            left_pid = next((p for p in profile_ids if p in profiles), None)
        if not right_pid and len(profiles) >= 2 and left_pid:
            right_pid = next((p for p in profile_ids if p in profiles and p != left_pid), None)
        
        for pid in [left_pid, right_pid]:
            if not pid:
                continue
            p = profiles.get(pid)
            if not p:
                continue
            photo_url = getattr(p, "photo_url", None)
            fetched = None
            # ä¼˜å…ˆä» OSS ç›´æ¥è¯»å–ï¼ˆä¸ä¾èµ– JWTï¼Œä¸”æ¡£æ¡ˆä¸Šä¼ å OSS å¿…æœ‰æ–‡ä»¶ï¼‰
            if USE_OSS and oss_bucket:
                fetched = _fetch_profile_image_from_oss(user_id, pid)
            if not fetched and photo_url and photo_url.startswith(("http://", "https://")):
                # è‹¥ä¸ºç›´è¿ OSS CDN ç­‰å…¬å¼€ URLï¼Œå¯å°è¯• HTTP æ‹‰å–ï¼ˆ/api/v1/images éœ€ JWT ä¼šå¤±è´¥ï¼‰
                if "/api/v1/images/" not in photo_url:
                    fetched = _fetch_image_bytes(photo_url)
            if fetched:
                result.append(fetched)
                logger.info(f"[æ¡£æ¡ˆç…§ç‰‡] å·²åŠ è½½å‚è€ƒå›¾: profile_id={pid} name={getattr(p,'name','')} rel={getattr(p,'relationship_type','')}")
            else:
                logger.warning(f"[æ¡£æ¡ˆç…§ç‰‡] æ— æ³•åŠ è½½ profile_id={pid} photo_url={bool(photo_url)} OSS={USE_OSS and oss_bucket is not None}")
    except Exception as e:
        logger.warning(f"[æ¡£æ¡ˆç…§ç‰‡] è·å–å‚è€ƒå›¾å¤±è´¥: {e}", exc_info=True)
    return result


def generate_image_from_prompt(
    image_prompt: str,
    user_id: str,
    session_id: str,
    image_index: int,
    reference_images: Optional[List[Tuple[bytes, str]]] = None,
    max_retries: int = 3,
) -> Optional[str]:
    """
    ä½¿ç”¨ Gemini Nano Banana ç”Ÿæˆå›¾ç‰‡å¹¶ä¸Šä¼ åˆ° OSSã€‚
    æ”¯æŒå¤šæ¨¡æ€è¾“å…¥ï¼šå¯ä¼ å…¥æ¡£æ¡ˆç…§ç‰‡ä½œä¸ºå‚è€ƒå›¾ï¼Œæå‡äººç‰©ä¸€è‡´æ€§ã€‚
    
    Args:
        image_prompt: å›¾ç‰‡ç”Ÿæˆæç¤ºè¯
        user_id: ç”¨æˆ· ID
        session_id: ä¼šè¯ ID
        image_index: å›¾ç‰‡ç´¢å¼•
        reference_images: å¯é€‰ï¼Œå‚è€ƒå›¾åˆ—è¡¨ [(bytes, mime_type), ...]ï¼Œæœ€å¤š2å¼ ï¼ˆå·¦=ç”¨æˆ·ï¼Œå³=å¯¹æ–¹ï¼‰
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        
    Returns:
        å›¾ç‰‡ URL æˆ– Base64ï¼Œå¤±è´¥è¿”å› None
    """
    from google.genai.errors import ClientError
    
    client = genai_new.Client(api_key=GEMINI_API_KEY)
    
    config = genai_types.GenerateContentConfig(
        image_config=genai_types.ImageConfig(aspect_ratio="4:3")
    )
    
    # æ„å»º contentsï¼šå‚è€ƒå›¾ + æ–‡æœ¬ prompt
    style_prefix = "å®«å´éªå‰åœåŠ›åŠ¨ç”»é£æ ¼ï¼Œæ¸©æš–è‡ªç„¶è‰²è°ƒï¼ŒæŸ”å’Œç¬”è§¦ã€‚"
    if reference_images and len(reference_images) >= 1:
        ref_desc = "ç¬¬ä¸€å¼ å›¾ä¸ºå·¦ä¾§äººç‰©ï¼ˆç”¨æˆ·ï¼‰çš„å‚è€ƒç…§ç‰‡"
        if len(reference_images) >= 2:
            ref_desc += "ï¼Œç¬¬äºŒå¼ å›¾ä¸ºå³ä¾§äººç‰©ï¼ˆå¯¹æ–¹ï¼‰çš„å‚è€ƒç…§ç‰‡"
        ref_desc += "ã€‚è¯·ä¿æŒäººç‰©é¢éƒ¨ä¸æ°”è´¨ä¸å‚è€ƒå›¾ä¸€è‡´ã€‚\n\n"
        full_prompt = style_prefix + ref_desc + image_prompt
    else:
        full_prompt = style_prefix + image_prompt
    
    contents_list = []
    if reference_images:
        for img_bytes, mime_type in reference_images[:2]:  # æœ€å¤š2å¼ 
            contents_list.append(genai_types.Part.from_bytes(data=img_bytes, mime_type=mime_type))
        logger.info(f"[å›¾ç‰‡ç”Ÿæˆ] ä½¿ç”¨ {len(contents_list)} å¼ æ¡£æ¡ˆç…§ç‰‡ä½œä¸ºå‚è€ƒå›¾")
    contents_list.append(full_prompt)
    
    for attempt in range(max_retries):
        try:
            if attempt > 0:
                logger.info(f"========== é‡è¯•ç”Ÿæˆå›¾ç‰‡ (ç¬¬ {attempt + 1}/{max_retries} æ¬¡) ==========")
            else:
                logger.info(f"========== å¼€å§‹ç”Ÿæˆå›¾ç‰‡ ==========")
            
            logger.info(f"æç¤ºè¯é•¿åº¦: {len(full_prompt)} å­—ç¬¦ (å«å‚è€ƒå›¾è¯´æ˜)")
            logger.debug(f"æç¤ºè¯å†…å®¹: {full_prompt[:200]}...")
            logger.info(f"è°ƒç”¨æ¨¡å‹: gemini-2.5-flash-image å‚è€ƒå›¾æ•°={len(reference_images) if reference_images else 0}")
            
            start_time = time.time()
            response = client.models.generate_content(
                model="gemini-2.5-flash-image",
                contents=contents_list,
                config=config
            )
            generate_time = time.time() - start_time
            
            logger.info(f"âœ… å›¾ç‰‡ç”ŸæˆæˆåŠŸï¼Œè€—æ—¶: {generate_time:.2f} ç§’")
            
            # æå–å›¾ç‰‡æ•°æ®
            image_bytes = None
            for part in response.parts:
                if part.inline_data is not None:
                    # å›¾ç‰‡æ•°æ®å·²ç»æ˜¯ bytes
                    image_bytes = part.inline_data.data
                    logger.info(f"âœ… å›¾ç‰‡æ•°æ®æå–æˆåŠŸï¼Œå¤§å°: {len(image_bytes)} å­—èŠ‚")
                    break
            
            if image_bytes is None:
                logger.warning("âš ï¸ å“åº”ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ•°æ®")
                return None
            
            # å°è¯•ä¸Šä¼ åˆ° OSS
            if USE_OSS and oss_bucket is not None:
                logger.info(f"å°è¯•ä¸Šä¼ å›¾ç‰‡åˆ° OSS...")
                image_url = upload_image_to_oss(image_bytes, user_id, session_id, image_index)
                if image_url:
                    logger.info(f"âœ… å›¾ç‰‡å·²ä¸Šä¼ åˆ° OSSï¼ŒURL: {image_url}")
                    return image_url
                else:
                    logger.warning("âš ï¸ OSS ä¸Šä¼ å¤±è´¥ï¼Œé™çº§åˆ° Base64")
            
            # å¦‚æœ OSS æœªå¯ç”¨æˆ–ä¸Šä¼ å¤±è´¥ï¼Œé™çº§åˆ° Base64
            logger.info("ä½¿ç”¨ Base64 ç¼–ç è¿”å›å›¾ç‰‡")
            image_base64 = base64.b64encode(image_bytes).decode('utf-8')
            logger.info(f"âœ… å›¾ç‰‡ Base64 ç¼–ç å®Œæˆï¼Œå¤§å°: {len(image_base64)} å­—ç¬¦")
            return image_base64
            
        except ClientError as e:
            error_code = getattr(e, 'status_code', None)
            error_message = str(e)
            
            # å¤„ç† 429 é…é¢è¶…é™é”™è¯¯
            if error_code == 429 or '429' in error_message or 'RESOURCE_EXHAUSTED' in error_message:
                # å°è¯•ä»é”™è¯¯ä¿¡æ¯ä¸­æå–é‡è¯•å»¶è¿Ÿ
                retry_delay = 15  # é»˜è®¤å»¶è¿Ÿ 15 ç§’
                if 'retry in' in error_message.lower() or 'retryDelay' in error_message:
                    import re
                    delay_match = re.search(r'retry in ([\d.]+)s', error_message, re.IGNORECASE)
                    if delay_match:
                        retry_delay = max(15, int(float(delay_match.group(1))) + 2)  # è‡³å°‘ç­‰å¾… 15 ç§’ï¼Œå¤šåŠ  2 ç§’ç¼“å†²
                
                logger.warning(f"âš ï¸ é…é¢è¶…é™ (429)ï¼Œç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
                logger.warning(f"é”™è¯¯è¯¦æƒ…: {error_message[:500]}")
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯å…è´¹å±‚é…é¢ä¸º 0 çš„é—®é¢˜
                if 'limit: 0' in error_message or 'free_tier' in error_message.lower():
                    logger.error("âŒ æ£€æµ‹åˆ°å…è´¹å±‚é…é¢é™åˆ¶ (limit: 0)")
                    logger.error("ğŸ’¡ å»ºè®®æ£€æŸ¥:")
                    logger.error("   1. ç¡®è®¤ API Key æ˜¯å¦å…³è”åˆ°ä»˜è´¹é¡¹ç›®")
                    logger.error("   2. åœ¨ Google Cloud Console æ£€æŸ¥é…é¢è®¾ç½®")
                    logger.error("   3. ç¡®è®¤å·²å¯ç”¨å›¾ç‰‡ç”Ÿæˆ API çš„ä»˜è´¹é…é¢")
                    logger.error("   4. å¯èƒ½éœ€è¦ç­‰å¾…å‡ åˆ†é’Ÿè®©é…é¢åˆ·æ–°")
                
                if attempt < max_retries - 1:
                    logger.info(f"ç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
                    time.sleep(retry_delay)
                    continue
                else:
                    logger.error(f"âŒ é‡è¯• {max_retries} æ¬¡åä»ç„¶å¤±è´¥ï¼Œæ”¾å¼ƒç”Ÿæˆå›¾ç‰‡")
                    logger.error(f"æœ€ç»ˆé”™è¯¯: {error_message[:500]}")
                    return None
            else:
                # å…¶ä»–ç±»å‹çš„ ClientError
                logger.error(f"âŒ ç”Ÿæˆå›¾ç‰‡å¤±è´¥ (ClientError): {error_code} - {error_message[:500]}")
                if attempt < max_retries - 1:
                    wait_time = (attempt + 1) * 5  # æŒ‡æ•°é€€é¿ï¼š5ç§’ã€10ç§’ã€15ç§’
                    logger.info(f"ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                    continue
                else:
                    logger.error(traceback.format_exc())
                    return None
                    
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆå›¾ç‰‡å¤±è´¥: {e}")
            logger.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
            if attempt < max_retries - 1:
                wait_time = (attempt + 1) * 5  # æŒ‡æ•°é€€é¿
                logger.info(f"ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                time.sleep(wait_time)
                continue
            else:
                logger.error(f"å®Œæ•´é”™è¯¯å †æ ˆ:")
                logger.error(traceback.format_exc())
                return None
    
    return None


# å¤§æ–‡ä»¶åˆ†ç‰‡é˜ˆå€¼ï¼šè¶…è¿‡æ­¤å¤§å°æ—¶åˆ‡åˆ†ä¸ºå¤šä¸ª â‰¤18MB ç‰‡æ®µåˆ†åˆ«ä¸Šä¼  Gemini
CHUNK_SIZE_MB = 18.0


def _upload_single_file_to_gemini(
    path: str,
    display_name: str,
    _sid: str,
    no_proxy: bool,
    use_resumable: bool,
    upload_timeout: int,
    max_retries: int = 3,
):
    """ä¸Šä¼ å•ä¸ªæ–‡ä»¶åˆ° Geminiï¼Œå¸¦é‡è¯•ã€‚è¿”å› uploaded_file å¯¹è±¡ã€‚"""
    import concurrent.futures
    retry_count = 0
    current_resumable = use_resumable
    while retry_count < max_retries:
        try:
            logger.info(f"[åˆ†æ-{_sid}-step3] å°è¯•ä¸Šä¼ ï¼ˆç¬¬ {retry_count + 1}/{max_retries} æ¬¡ï¼Œresumable={current_resumable}ï¼Œè¶…æ—¶={upload_timeout}sï¼‰...")
            start_upload = time.time()
            with concurrent.futures.ThreadPoolExecutor(max_workers=1) as ex:
                fut = ex.submit(
                    genai.upload_file,
                    path=path,
                    display_name=display_name,
                    resumable=current_resumable,
                )
                try:
                    uploaded_file = fut.result(timeout=upload_timeout)
                except concurrent.futures.TimeoutError:
                    raise Exception(f"Gemini æ–‡ä»¶ä¸Šä¼ è¶…æ—¶ï¼ˆ{upload_timeout}ç§’ï¼‰")
            logger.info(f"[åˆ†æ-{_sid}-step4] âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼name={uploaded_file.name} è€—æ—¶={time.time()-start_upload:.2f}s")
            return uploaded_file
        except Exception as e:
            retry_count += 1
            error_msg = str(e)
            logger.error(f"[åˆ†æ-{_sid}-step3] âŒ ä¸Šä¼ å¤±è´¥ï¼ˆç¬¬ {retry_count}/{max_retries}ï¼‰{error_msg}")
            if ("string indices must be integers" in error_msg or "not 'str'" in error_msg) and current_resumable:
                current_resumable = False
                retry_count -= 1
            if retry_count >= max_retries:
                raise Exception(f"ä¸Šä¼ æ–‡ä»¶å¤±è´¥ï¼ˆå·²é‡è¯• {max_retries} æ¬¡ï¼‰: {error_msg}")
            time.sleep(5)


async def analyze_audio_from_path(temp_file_path: str, file_filename: str, session_id: Optional[str] = None) -> Tuple[AudioAnalysisResponse, Optional[Call1Response]]:
    """
    ä»æ–‡ä»¶è·¯å¾„åˆ†æéŸ³é¢‘æ–‡ä»¶ï¼ˆå†…éƒ¨å‡½æ•°ï¼‰
    è‹¥æ–‡ä»¶ > 18MBï¼Œè‡ªåŠ¨åˆ‡åˆ†ä¸ºå¤šä¸ª â‰¤18MB ç‰‡æ®µï¼Œåˆ†åˆ«ä¸Šä¼  Gemini ååˆå¹¶åˆ†æã€‚
    
    Args:
        temp_file_path: ä¸´æ—¶æ–‡ä»¶è·¯å¾„
        file_filename: æ–‡ä»¶å
        
    Returns:
        å…ƒç»„ï¼š(AudioAnalysisResponse, Optional[Call1Response])
    """
    uploaded_file = None
    uploaded_files_list: List[Any] = []
    chunk_paths_to_clean: List[str] = []
    _sid = session_id or "?"
    
    try:
        logger.info(f"[åˆ†æ-{_sid}-step1] ========== æ–‡ä»¶ä¸Šä¼ å¤„ç†å¼€å§‹ ==========")
        logger.info(f"[åˆ†æ-{_sid}-step1] æ–‡ä»¶å·²ä¿å­˜åˆ°ä¸´æ—¶è·¯å¾„: {temp_file_path}")
        
        file_size = os.path.getsize(temp_file_path)
        file_size_mb = file_size / 1024 / 1024
        logger.info(f"[åˆ†æ-{_sid}-step2] æ–‡ä»¶å: {file_filename} å¤§å°: {file_size} å­—èŠ‚ ({file_size_mb:.2f} MB)")
        
        no_proxy = os.getenv("GEMINI_FILE_UPLOAD_NO_PROXY", "").lower() == "true"
        use_resumable = False if no_proxy else True
        _genai_client = None
        _old_discovery_url = None
        if no_proxy:
            try:
                import google.generativeai.client as _genai_client
                _old_discovery_url = getattr(_genai_client, "GENAI_API_DISCOVERY_URL", None)
                _genai_client.GENAI_API_DISCOVERY_URL = "https://generativelanguage.googleapis.com/$discovery/rest"
                logger.info("æ–‡ä»¶ä¸Šä¼ å·²åˆ‡æ¢ä¸ºç›´è¿ Geminiï¼ˆGEMINI_FILE_UPLOAD_NO_PROXY=trueï¼‰")
            except Exception as e:
                logger.warning(f"åˆ‡æ¢ç›´è¿å¤±è´¥: {e}ï¼Œå°†ç»§ç»­ä½¿ç”¨ä»£ç†")
        
        upload_timeout = int(os.getenv("GEMINI_UPLOAD_TIMEOUT", "90"))
        
        try:
            if file_size > CHUNK_SIZE_MB * 1024 * 1024:
                # å¤§æ–‡ä»¶ï¼šåˆ‡åˆ†ä¸ºå¤šä¸ª â‰¤18MB ç‰‡æ®µï¼Œåˆ†åˆ«ä¸Šä¼ åä¸€èµ·ä¼ ç»™ Gemini
                from utils.audio_storage import split_audio_into_chunks
                logger.info(f"[åˆ†æ-{_sid}] å¤§æ–‡ä»¶ï¼ˆ{file_size_mb:.1f} MB > {CHUNK_SIZE_MB} MBï¼‰ï¼Œåˆ‡åˆ†åå¤šæ–‡ä»¶ä¸Šä¼ ")
                chunks = split_audio_into_chunks(
                    temp_file_path,
                    max_chunk_mb=CHUNK_SIZE_MB,
                    base_name=f"gemini_{_sid[:8]}",
                )
                chunk_paths_to_clean = [c[2] for c in chunks]
                for i, (start_sec, end_sec, chunk_path) in enumerate(chunks):
                    chunk_name = f"{file_filename}_ç‰‡æ®µ{i+1}"
                    uf = _upload_single_file_to_gemini(
                        chunk_path, chunk_name, _sid, no_proxy, use_resumable, upload_timeout
                    )
                    uf = wait_for_file_active(uf, max_wait_time=600)
                    uploaded_files_list.append(uf)
                # å¤šæ–‡ä»¶æ—¶ç”¨ç»Ÿä¸€å˜é‡ï¼Œåç»­ generate_content ç”¨ contents
                uploaded_file = uploaded_files_list[0] if uploaded_files_list else None
            else:
                # å°æ–‡ä»¶ï¼šå•æ–‡ä»¶ä¸Šä¼ 
                logger.info(f"[åˆ†æ-{_sid}-step2] ========== å¼€å§‹ä¸Šä¼ æ–‡ä»¶åˆ° Gemini ==========")
                uploaded_file = _upload_single_file_to_gemini(
                    temp_file_path, file_filename, _sid, no_proxy, use_resumable, upload_timeout
                )
                logger.info(f"[åˆ†æ-{_sid}-step5] ç­‰å¾…æ–‡ä»¶å¤„ç†å®Œæˆï¼Œå½“å‰çŠ¶æ€: {uploaded_file.state}")
                uploaded_file = wait_for_file_active(uploaded_file, max_wait_time=600)
        finally:
            if no_proxy and _genai_client is not None and _old_discovery_url is not None:
                try:
                    _genai_client.GENAI_API_DISCOVERY_URL = _old_discovery_url
                    logger.info("å·²æ¢å¤æ–‡ä»¶æœåŠ¡ discovery URL")
                except Exception:
                    pass
        
        logger.info(f"[åˆ†æ-{_sid}-step6] âœ… æ–‡ä»¶ ACTIVEï¼Œå³å°†è°ƒç”¨ generate_content")
        
        model_name = GEMINI_FLASH_MODEL
        model = genai.GenerativeModel(model_name)
        
        # å•æ–‡ä»¶ / å¤šæ–‡ä»¶ å…±ç”¨åŸºç¡€æç¤ºè¯
        prompt_base = """è§’è‰²: ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è¯­éŸ³åˆ†æä¸è¡Œä¸ºè§‚å¯Ÿä¸“å®¶ã€‚

ä»»åŠ¡: è¯·æ·±å…¥è§£æä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶ï¼Œå¹¶è¾“å‡ºä¸¥æ ¼æ ¼å¼åŒ–çš„ JSON æ•°æ®ã€‚

å‚æ•°å®šä¹‰:

1. **mood_score**: (Integer, 0-100) æ ¹æ®è¯­è°ƒæ³¢åŠ¨ã€è¯­é€Ÿå˜åŒ–åŠè¯­ä¹‰å†²çªç¨‹åº¦å¯¹å¯¹è¯æ°›å›´è¿›è¡Œå»ºæ¨¡è¯„åˆ†ã€‚åˆ†æ•°è¶Šé«˜è¡¨ç¤ºæ°›å›´è¶Šè½»æ¾æ„‰å¿«ã€‚

2. **sigh_count**: (Integer) è¯†åˆ«å¹¶ç»Ÿè®¡ Speaker_1 (ç”¨æˆ·) åœ¨éŸ³é¢‘ä¸­äº§ç”Ÿçš„é•¿å‘¼æ°”æˆ–å¹æ°”æ¬¡æ•°ï¼ˆé€šå¸¸ä»£è¡¨å‹åŠ›ã€ç–²æƒ«æˆ–æ— å¥ˆï¼‰ã€‚

3. **laugh_count**: (Integer) è¯†åˆ«å¹¶ç»Ÿè®¡å…¨åœºå‡ºç°çš„æ‰€æœ‰ç±»å‹ç¬‘å£°ï¼ˆåŒ…æ‹¬æ„‰å¿«çš„ã€å°´å°¬çš„æˆ–å˜²è®½çš„ç¬‘ï¼‰ã€‚

4. **summary**: (String) å¯¹å¯¹è¯å†…å®¹ã€æ ¸å¿ƒçŸ›ç›¾åŠæƒ…ç»ªè½¬æŠ˜ç‚¹è¿›è¡Œç²¾ç‚¼æ€»ç»“ï¼ˆ100-200å­—ï¼‰ã€‚

5. **transcript**: (Array) æŒ‰æ—¶é—´é¡ºåºåŒ…å«æ‰€æœ‰å¯¹è¯ï¼Œæ¯ä¸ªå¯¹è¯åŒ…å«ï¼š
   - speaker: è¯´è¯äººæ ‡è¯†ï¼ˆå¦‚ï¼šSpeaker_0, Speaker_1ï¼Œå…¶ä¸­Speaker_1ä¸ºç”¨æˆ·ï¼‰
   - text: å¯¹è¯å†…å®¹ï¼ˆå®Œæ•´åŸè¯ï¼‰
   - timestamp: æ—¶é—´æˆ³ï¼ˆæ ¼å¼ï¼š"MM:SS"ï¼Œå¦‚"00:01"ï¼‰
   - is_me: (Boolean) æ˜¯å¦ä¸ºç”¨æˆ·è¯´çš„ï¼ˆSpeaker_1ä¸ºtrueï¼Œå…¶ä»–ä¸ºfalseï¼‰

6. **risks**: (Array) å…³é”®é£é™©ç‚¹åˆ—è¡¨

è¯·åŠ¡å¿…ä»¥çº¯ JSON æ ¼å¼è¿”å›ï¼Œä¸è¦åŒ…å« Markdown æ ‡è®°ã€‚

è¿”å›æ ¼å¼å¿…é¡»ä¸¥æ ¼éµå¾ªä»¥ä¸‹ç»“æ„ï¼š
{
  "mood_score": 75,
  "sigh_count": 2,
  "laugh_count": 5,
  "summary": "å¯¹è¯æ°”æ°›æ•´ä½“ç¼“å’Œï¼Œä½†åœ¨å‘¨æœ«åŠ ç­çš„æˆªæ­¢æ—¥æœŸé—®é¢˜ä¸Šå­˜åœ¨æ˜æ˜¾çš„éšå½¢æ‹‰é”¯ï¼Œç”¨æˆ·è¯•å›¾é˜²å¾¡ä¸ªäººæ—¶é—´ã€‚",
  "transcript": [
    {
      "speaker": "Speaker_0",
      "text": "å…·ä½“è¯´è¯å†…å®¹",
      "timestamp": "00:01",
      "is_me": false
    },
    {
      "speaker": "Speaker_1",
      "text": "å…·ä½“è¯´è¯å†…å®¹",
      "timestamp": "00:05",
      "is_me": true
    }
  ],
  "risks": ["é£é™©ç‚¹1", "é£é™©ç‚¹2", ...]
}

æ³¨æ„ï¼štranscript æ•°ç»„å¿…é¡»åŒ…å«æ‰€æœ‰å¯¹è¯ï¼ŒæŒ‰æ—¶é—´é¡ºåºæ’åˆ—ï¼Œä¸è¦é—æ¼ä»»ä½•å¯¹è¯ã€‚"""
        
        if len(uploaded_files_list) > 1:
            # å¤šæ–‡ä»¶æ—¶é™„åŠ è¯´æ˜
            multi_instruction = f"""
é‡è¦ï¼šä½ æ”¶åˆ°çš„æ˜¯åŒä¸€æ®µå½•éŸ³æŒ‰æ—¶é—´é¡ºåºåˆ‡åˆ†çš„ {len(uploaded_files_list)} ä¸ªè¿ç»­ç‰‡æ®µï¼ˆç‰‡æ®µ1ã€2ã€...ã€{len(uploaded_files_list)}ï¼‰ã€‚
è¯·å°†å…¨éƒ¨ç‰‡æ®µä½œä¸ºæ•´ä½“åˆ†æï¼Œåˆå¹¶è¾“å‡ºä¸€ä¸ªå®Œæ•´çš„ JSONã€‚
transcript ä¸­çš„ timestamp å¿…é¡»ä½¿ç”¨ç›¸å¯¹äºæ•´æ®µå½•éŸ³å¼€å§‹çš„å…¨å±€æ—¶é—´ã€‚
ä¾‹å¦‚ï¼Œè‹¥ç‰‡æ®µ2å¯¹åº”åŸå½•éŸ³çš„ 20:00â€“40:00ï¼Œåˆ™ç‰‡æ®µ2ä¸­ã€Œ00:05ã€çš„å¯¹è¯åº”è®°ä¸ºã€Œ20:05ã€ã€‚"""
            prompt = prompt_base + multi_instruction
        else:
            prompt = prompt_base
        
        # è°ƒç”¨æ¨¡å‹è¿›è¡Œåˆ†æï¼ˆæ·»åŠ é‡è¯•æœºåˆ¶ï¼‰
        logger.info(f"========== å¼€å§‹è°ƒç”¨ Gemini æ¨¡å‹åˆ†æéŸ³é¢‘ ==========")
        logger.info(f"æ¨¡å‹: {model_name} æ–‡ä»¶æ•°: {len(uploaded_files_list) or 1}")
        max_retries = 3
        retry_count = 0
        response = None
        contents = (uploaded_files_list if uploaded_files_list else [uploaded_file]) + [prompt]
        
        while retry_count < max_retries:
            try:
                logger.info(f"[åˆ†æ-{_sid}-step7] è°ƒç”¨ generate_contentï¼ˆç¬¬ {retry_count + 1}/{max_retries} æ¬¡ï¼‰...")
                start_generate = time.time()
                response = model.generate_content(contents)
                generate_time = time.time() - start_generate
                logger.info(f"[åˆ†æ-{_sid}-step8] âœ… generate_content æˆåŠŸï¼Œè€—æ—¶: {generate_time:.2f}s å“åº”é•¿åº¦: {len(response.text)}")
                break
            except Exception as e:
                retry_count += 1
                error_msg = str(e)
                error_type = type(e).__name__
                logger.error(f"[åˆ†æ-{_sid}-step7] âŒ generate_content å¤±è´¥ï¼ˆç¬¬ {retry_count}/{max_retries}ï¼‰{error_type}: {error_msg}")
                logger.error(f"å®Œæ•´é”™è¯¯å †æ ˆ:")
                logger.error(traceback.format_exc())
                if retry_count >= max_retries:
                    raise Exception(f"è°ƒç”¨æ¨¡å‹å¤±è´¥ï¼ˆé‡è¯• {max_retries} æ¬¡ï¼‰: {error_msg}")
                logger.info(f"ç­‰å¾… 5 ç§’åé‡è¯•...")
                time.sleep(5)
        
        logger.info(f"Gemini å“åº”é•¿åº¦: {len(response.text)} å­—ç¬¦")
        logger.debug(f"Gemini å“åº”å†…å®¹: {response.text[:500]}...")  # åªè®°å½•å‰500å­—ç¬¦
        
        # è§£æå“åº”
        analysis_data = parse_gemini_response(response.text)
        
        # å°è¯•è§£ææ–°çš„Call1æ ¼å¼ï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨æ—§æ ¼å¼
        call1_result = None
        try:
            # è§£æè½¬å½•åˆ—è¡¨
            transcript_list = []
            if "transcript" in analysis_data:
                for item in analysis_data["transcript"]:
                    transcript_list.append(TranscriptItem(
                        speaker=item.get("speaker", "æœªçŸ¥"),
                        text=item.get("text", ""),
                        timestamp=item.get("timestamp"),
                        is_me=item.get("is_me", False)
                    ))
            
            # æ„å»ºCall1Response
            call1_result = Call1Response(
                mood_score=analysis_data.get("mood_score", 70),
                stats={
                    "sigh": analysis_data.get("sigh_count", 0),
                    "laugh": analysis_data.get("laugh_count", 0)
                },
                summary=analysis_data.get("summary", ""),
                transcript=transcript_list
            )
            
            # è½¬æ¢ä¸ºæ—§æ ¼å¼ä»¥ä¿æŒå…¼å®¹æ€§
            dialogues_list = []
            for item in transcript_list:
                dialogues_list.append(DialogueItem(
                    speaker=item.speaker,
                    content=item.text,
                    tone="æœªçŸ¥",  # æ–°æ ¼å¼ä¸åŒ…å«toneï¼Œä¿ç•™é»˜è®¤å€¼
                    timestamp=item.timestamp,
                    is_me=item.is_me
                ))
            
            speaker_count = len(set(item.speaker for item in transcript_list)) if transcript_list else 0
            
        except Exception as e:
            logger.warning(f"è§£ææ–°æ ¼å¼å¤±è´¥ï¼Œä½¿ç”¨æ—§æ ¼å¼: {e}")
            # å…¼å®¹æ—§æ ¼å¼
            dialogues_list = []
            if "dialogues" in analysis_data:
                for dialogue in analysis_data["dialogues"]:
                    dialogues_list.append(DialogueItem(
                        speaker=dialogue.get("speaker", "æœªçŸ¥"),
                        content=dialogue.get("content", ""),
                        tone=dialogue.get("tone", "æœªçŸ¥"),
                        timestamp=dialogue.get("timestamp"),
                        is_me=dialogue.get("is_me", False)
                    ))
            speaker_count = analysis_data.get("speaker_count", 0)
        
        # éªŒè¯å¹¶æ„å»ºè¿”å›æ•°æ®
        result = AudioAnalysisResponse(
            speaker_count=speaker_count,
            dialogues=dialogues_list,
            risks=analysis_data.get("risks", [])
        )
        
        # è¿”å›ç»“æœå’ŒCall1æ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        return result, call1_result
        
    except Exception as e:
        error_msg = str(e)
        error_type = type(e).__name__
        logger.error(f"[åˆ†æ-{_sid}] âŒ analyze_audio_from_path å¼‚å¸¸: {error_type}: {error_msg}")
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"éŸ³é¢‘åˆ†æå¤±è´¥: {error_msg}")
    
    finally:
        # åˆ é™¤ Gemini ä¸Šçš„æ–‡ä»¶
        to_delete = uploaded_files_list if uploaded_files_list else ([uploaded_file] if uploaded_file else [])
        for uf in to_delete:
            if uf:
                try:
                    genai.delete_file(uf.name)
                    logger.info(f"å·²åˆ é™¤ Gemini æ–‡ä»¶: {uf.name}")
                except Exception as e:
                    logger.error(f"åˆ é™¤ Gemini æ–‡ä»¶å¤±è´¥: {e}")
        # åˆ é™¤åˆ†ç‰‡ä¸´æ—¶æ–‡ä»¶
        for p in chunk_paths_to_clean:
            try:
                if os.path.exists(p):
                    os.unlink(p)
                    logger.info(f"å·²åˆ é™¤åˆ†ç‰‡ä¸´æ—¶æ–‡ä»¶: {p}")
            except Exception as e:
                logger.warning(f"åˆ é™¤åˆ†ç‰‡ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")


@app.post("/analyze-audio", response_model=AudioAnalysisResponse)
async def analyze_audio(file: UploadFile = File(...)):
    """
    åˆ†æä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶
    
    Args:
        file: ä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶ï¼ˆmp3/wav/m4aï¼‰
        
    Returns:
        ç»“æ„åŒ–çš„éŸ³é¢‘åˆ†æç»“æœ
    """
    # éªŒè¯æ–‡ä»¶ç±»å‹
    allowed_extensions = {'.mp3', '.wav', '.m4a'}
    file_ext = Path(file.filename).suffix.lower() if file.filename else '.m4a'
    
    if file_ext not in allowed_extensions:
        raise HTTPException(
            status_code=400,
            detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ã€‚ä»…æ”¯æŒ: {', '.join(allowed_extensions)}"
        )
    
    # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ä¿å­˜ä¸Šä¼ çš„éŸ³é¢‘
    temp_file_path = None
    
    try:
        # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
        with tempfile.NamedTemporaryFile(delete=False, suffix=file_ext) as temp_file:
            temp_file_path = temp_file.name
            content = await file.read()
            temp_file.write(content)
        
        # è°ƒç”¨å†…éƒ¨å‡½æ•°åˆ†æï¼ˆåªè¿”å›æ—§æ ¼å¼ä»¥ä¿æŒAPIå…¼å®¹æ€§ï¼‰
        result, _ = await analyze_audio_from_path(temp_file_path, file.filename or "audio.m4a")
        return result
        
    except Exception as e:
        error_msg = str(e)
        error_type = type(e).__name__
        logger.error(f"========== å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ ==========")
        logger.error(f"é”™è¯¯ç±»å‹: {error_type}")
        logger.error(f"é”™è¯¯ä¿¡æ¯: {error_msg}")
        logger.error(f"å®Œæ•´é”™è¯¯å †æ ˆ:")
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"éŸ³é¢‘åˆ†æå¤±è´¥: {error_msg}")
    
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if temp_file_path and os.path.exists(temp_file_path):
            try:
                os.unlink(temp_file_path)
                print(f"å·²åˆ é™¤ä¸´æ—¶æ–‡ä»¶: {temp_file_path}")
            except Exception as e:
                print(f"åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")


@app.get("/")
async def root():
    """æ ¹è·¯å¾„ï¼Œè¿”å›æœåŠ¡ä¿¡æ¯"""
    return {
        "service": "éŸ³é¢‘åˆ†ææœåŠ¡",
        "version": "1.0.0",
        "endpoint": "/analyze-audio"
    }


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    return {"message": "éŸ³é¢‘åˆ†ææœåŠ¡æ­£åœ¨è¿è¡Œ", "status": "ok"}


# ==================== ä»»åŠ¡ç®¡ç† API ====================

# å†…å­˜å­˜å‚¨ï¼ˆä¸´æ—¶ï¼Œåç»­æ”¹ä¸ºæ•°æ®åº“ï¼‰
tasks_storage: dict = {}
analysis_storage: dict = {}


class TaskItem(BaseModel):
    """ä»»åŠ¡é¡¹æ•°æ®æ¨¡å‹"""
    session_id: str
    title: str
    start_time: str
    end_time: Optional[str] = None
    duration: int
    tags: List[str] = []
    status: str
    emotion_score: Optional[int] = None
    speaker_count: Optional[int] = None
    summary: Optional[str] = None  # å¯¹è¯æ€»ç»“ï¼Œæ¥è‡ª AnalysisResult
    cover_image_url: Optional[str] = None  # ç­–ç•¥åˆ†æé¦–å›¾ URLï¼Œæ¥è‡ª StrategyAnalysis.visual_data[0]


class TaskListResponse(BaseModel):
    """ä»»åŠ¡åˆ—è¡¨å“åº”"""
    sessions: List[TaskItem]
    pagination: dict


class TaskDetailResponse(BaseModel):
    """ä»»åŠ¡è¯¦æƒ…å“åº”"""
    session_id: str
    title: str
    start_time: str
    end_time: Optional[str] = None
    duration: int
    tags: List[str] = []
    status: str
    error_message: Optional[str] = None  # åˆ†æå¤±è´¥æ—¶çš„é”™è¯¯ä¿¡æ¯
    emotion_score: Optional[int] = None
    speaker_count: Optional[int] = None
    dialogues: List[dict] = []
    risks: List[str] = []
    summary: Optional[str] = None  # å¯¹è¯æ€»ç»“
    speaker_mapping: Optional[dict] = None  # Speaker_0/1 -> profile_id
    speaker_names: Optional[dict] = None  # Speaker_0/1 -> æ¡£æ¡ˆåï¼ˆå…³ç³»ï¼‰ï¼Œå¦‚ å¼ ä¸‰ï¼ˆè‡ªå·±ï¼‰ï¼Œä¾¿äºå‰ç«¯å±•ç¤º
    conversation_summary: Optional[str] = None  # ã€Œè°å’Œè°å¯¹è¯ã€æ€»ç»“
    created_at: str
    updated_at: str


class UploadResponse(BaseModel):
    """ä¸Šä¼ å“åº”"""
    session_id: str
    audio_id: str
    title: str
    status: str
    estimated_duration: Optional[int] = None
    created_at: str


class APIResponse(BaseModel):
    """é€šç”¨ API å“åº”"""
    code: int
    message: str
    data: Optional[dict] = None
    timestamp: Optional[str] = None


def calculate_emotion_score(result: AudioAnalysisResponse) -> int:
    """è®¡ç®—æƒ…ç»ªåˆ†æ•°"""
    score = 70  # åŸºç¡€åˆ†æ•°
    
    for dialogue in result.dialogues:
        tone = dialogue.tone.lower()
        if tone in ["æ„¤æ€’", "ç„¦è™‘", "ç´§å¼ ", "angry", "anxious", "tense"]:
            score -= 20
        elif tone in ["è½»æ¾", "å¹³é™", "relaxed", "calm"]:
            score += 5
    
    score -= len(result.risks) * 10
    return max(0, min(100, score))


def generate_tags(result: AudioAnalysisResponse) -> List[str]:
    """ç”Ÿæˆæ ‡ç­¾"""
    tags = []
    
    for risk in result.risks:
        if "PUA" in risk or "pua" in risk.lower():
            tags.append("#PUAé¢„è­¦")
        if "é¢„ç®—" in risk or "budget" in risk.lower():
            tags.append("#é¢„ç®—")
        if "äº‰è®®" in risk or "dispute" in risk.lower():
            tags.append("#äº‰è®®")
    
    tones = [d.tone for d in result.dialogues]
    if any("æ„¤æ€’" in t or "angry" in t.lower() for t in tones):
        tags.append("#æ€¥èº")
    if any("ç”»é¥¼" in t or "promise" in t.lower() for t in tones):
        tags.append("#ç”»é¥¼")
    
    return tags if tags else ["#æ­£å¸¸"]


@app.post("/api/v1/audio/upload", response_model=APIResponse)
async def upload_audio_api(
    file: UploadFile = File(...),
    title: Optional[str] = None,
    user_id: str = Depends(get_current_user_id),
    db: AsyncSession = Depends(get_db)
):
    """ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶å¹¶å¼€å§‹åˆ†æï¼ˆéœ€è¦JWTè®¤è¯ï¼‰"""
    import asyncio
    from datetime import datetime
    
    t_enter = time.time()
    logger.info("========== [upload] è¿›å…¥ handler ==========")
    logger.info(f"æ–‡ä»¶å: {file.filename} Content-Type: {file.content_type} Title: {title} User: {user_id[:8]}...")
    
    try:
        session_id = str(uuid.uuid4())
        logger.info(f"ç”Ÿæˆ session_id: {session_id}")
        
        if not title:
            formatter = datetime.now().strftime("%H:%M")
            title = f"å½•éŸ³ {formatter}"
        
        start_time = datetime.now()
        
        # åˆ›å»ºæ•°æ®åº“Sessionè®°å½•
        db_session = Session(
            id=uuid.UUID(session_id),
            user_id=uuid.UUID(user_id),
            title=title,
            start_time=start_time,
            duration=0,
            status="analyzing",
            tags=[]
        )
        db.add(db_session)
        await db.commit()
        await db.refresh(db_session)
        t_after_db = time.time() - t_enter
        logger.info(f"[upload] æ•°æ®åº“Sessionå·²åˆ›å»º session_id={session_id} è€—æ—¶={t_after_db:.2f}s")
        
        # ä¿ç•™å†…å­˜å­˜å‚¨ç”¨äºå‘åå…¼å®¹ï¼ˆå¯é€‰ï¼‰
        task_data = {
            "session_id": session_id,
            "user_id": user_id,
            "title": title,
            "start_time": start_time.isoformat(),
            "end_time": None,
            "duration": 0,
            "tags": [],
            "status": "analyzing",
            "emotion_score": None,
            "speaker_count": None,
            "created_at": start_time.isoformat(),
            "updated_at": start_time.isoformat()
        }
        tasks_storage[session_id] = task_data
        logger.info(f"ä»»åŠ¡æ•°æ®å·²å­˜å‚¨: {session_id}")
        
        # è¯»å–æ–‡ä»¶å†…å®¹å¹¶ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶ï¼ˆå¿…é¡»åœ¨å¼‚æ­¥ä»»åŠ¡ä¹‹å‰è¯»å–ï¼Œå› ä¸º UploadFile åªèƒ½è¯»å–ä¸€æ¬¡ï¼‰
        # æ³¨æ„ï¼šä¸é™åˆ¶æ–‡ä»¶å¤§å°ï¼ŒGemini æ”¯æŒå¤§æ–‡ä»¶ï¼›Nginx éœ€é…ç½® client_max_body_size 100M ä»¥ä¸Š
        t_before_read = time.time()
        logger.info("[upload] å¼€å§‹è¯»å–æ–‡ä»¶å†…å®¹ï¼ˆawait file.readï¼Œå¤§æ–‡ä»¶æ—¶æ­¤æ­¥éª¤è¾ƒæ…¢ï¼‰...")
        file_content = await file.read()
        file_size = len(file_content)
        t_read_elapsed = time.time() - t_before_read
        logger.info(f"[upload] æ–‡ä»¶è¯»å–å®Œæˆ size={file_size} bytes ({file_size / 1024 / 1024:.2f} MB) è€—æ—¶={t_read_elapsed:.2f}s")
        
        file_filename = file.filename or "audio.m4a"
        file_ext = Path(file_filename).suffix.lower() if file_filename else '.m4a'
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ä¿å­˜æ–‡ä»¶å†…å®¹
        import tempfile
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=file_ext)
        temp_file.write(file_content)
        temp_file.close()
        temp_file_path = temp_file.name
        logger.info(f"[upload] ä¸´æ—¶æ–‡ä»¶å·²åˆ›å»º: {temp_file_path}")
        
        # å¼‚æ­¥åˆ†æï¼ˆä¼ é€’ä¸´æ—¶æ–‡ä»¶è·¯å¾„å’Œæ–‡ä»¶åï¼Œç¡®ä¿æ‰€æœ‰å‚æ•°éƒ½æ­£ç¡®ä¼ é€’ï¼‰
        # æ³¨æ„ï¼šä¸ä¼ é€’dbä¼šè¯ï¼Œåœ¨å¼‚æ­¥ä»»åŠ¡ä¸­åˆ›å»ºæ–°çš„ä¼šè¯
        logger.info(f"åˆ›å»ºå¼‚æ­¥åˆ†æä»»åŠ¡: session_id={session_id}, file_path={temp_file_path}, filename={file_filename}")
        asyncio.create_task(analyze_audio_async(session_id, temp_file_path, file_filename, task_data, user_id))
        
        # æ„å»ºå“åº”æ•°æ®
        response_data = {
            "session_id": session_id,
            "user_id": user_id,
            "audio_id": session_id,
            "title": title,
            "status": "analyzing",
            "estimated_duration": 300,
            "created_at": start_time.isoformat()
        }
        
        api_response = APIResponse(
            code=200,
            message="ä¸Šä¼ æˆåŠŸ",
            data=response_data,
            timestamp=datetime.now().isoformat()
        )
        
        t_total = time.time() - t_enter
        logger.info(f"[upload] ========== å‡†å¤‡è¿”å›å“åº” æ€»è€—æ—¶={t_total:.2f}s ==========")
        logger.info(f"[upload] å“åº”: code={api_response.code} session_id={session_id}")
        
        # ä½¿ç”¨ JSONResponse ç¡®ä¿æ­£ç¡®åºåˆ—åŒ–
        return JSONResponse(
            content=api_response.dict(),
            status_code=200,
            headers={"Content-Type": "application/json"}
        )
    except Exception as e:
        logger.error(f"========== ä¸Šä¼ éŸ³é¢‘å¤±è´¥ ==========")
        logger.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
        logger.error(f"é”™è¯¯ä¿¡æ¯: {str(e)}")
        logger.error(f"å®Œæ•´é”™è¯¯å †æ ˆ:")
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"ä¸Šä¼ å¤±è´¥: {str(e)}")


async def analyze_audio_async(session_id: str, temp_file_path: str, file_filename: str, task_data: dict, user_id: str):
    """å¼‚æ­¥åˆ†æéŸ³é¢‘æ–‡ä»¶ï¼ˆä¿å­˜åˆ°æ•°æ®åº“ï¼‰"""
    from datetime import datetime
    from database.connection import AsyncSessionLocal
    
    # åˆ›å»ºæ–°çš„æ•°æ®åº“ä¼šè¯ï¼ˆå› ä¸ºåŸä¼šè¯å¯èƒ½å·²å…³é—­ï¼‰
    async with AsyncSessionLocal() as db:
        try:
            logger.info(f"[åˆ†æ-{session_id}] ========== å¼€å§‹å¼‚æ­¥åˆ†æ ==========")
            logger.info(f"session_id: {session_id}")
            logger.info(f"user_id: {user_id}")
            logger.info(f"temp_file_path: {temp_file_path}")
            logger.info(f"file_filename: {file_filename}")
            logger.info(f"task_data keys: {list(task_data.keys()) if task_data else 'None'}")
            
            # éªŒè¯å‚æ•°
            if not task_data:
                raise ValueError("task_data å‚æ•°ä¸èƒ½ä¸ºç©º")
            if not session_id:
                raise ValueError("session_id å‚æ•°ä¸èƒ½ä¸ºç©º")
            if not temp_file_path:
                raise ValueError("temp_file_path å‚æ•°ä¸èƒ½ä¸ºç©º")
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(temp_file_path):
                raise FileNotFoundError(f"ä¸´æ—¶æ–‡ä»¶ä¸å­˜åœ¨: {temp_file_path}")
            
            logger.info(f"[åˆ†æ-{session_id}] step_async1: åˆ†æä»»åŠ¡å¼€å§‹ï¼Œæ–‡ä»¶å¤§å°: {os.path.getsize(temp_file_path)} å­—èŠ‚")
            # ç›´æ¥è¿›å…¥ Gemini åˆ†æé˜¶æ®µï¼ˆåŸéŸ³é¢‘ä¸ä¸Šä¼ é˜¿é‡Œäº‘ï¼Œä»…æœ¬åœ°å­˜å‚¨ï¼‰
            _uq = await db.execute(select(Session).where(Session.id == uuid.UUID(session_id)))
            _us = _uq.scalar_one_or_none()
            if _us:
                _us.analysis_stage = "gemini_analysis"
                await db.commit()
            
            # åŸéŸ³é¢‘æŒä¹…åŒ–åˆ°æœ¬åœ°ï¼ˆç§’çº§ï¼Œä¾›å‰ªåˆ‡ä¸å£°çº¹ä½¿ç”¨ï¼›é»˜è®¤ä¸ä¸Šä¼  OSSï¼‰
            audio_url, audio_path = await asyncio.to_thread(
                persist_original_audio, session_id, temp_file_path, file_filename or "audio.m4a", user_id
            )
            result_query = await db.execute(select(Session).where(Session.id == uuid.UUID(session_id)))
            db_session_audio = result_query.scalar_one_or_none()
            if db_session_audio:
                db_session_audio.audio_url = audio_url
                db_session_audio.audio_path = audio_path
                await db.commit()
                logger.info(f"[åˆ†æ-{session_id}] Session å·²æ›´æ–°åŸéŸ³é¢‘: audio_url={bool(audio_url)}, audio_path={bool(audio_path)}")
            
            logger.info(f"[åˆ†æ-{session_id}] step_async2: æœ¬åœ°å­˜å‚¨å®Œæˆï¼Œå³å°†è°ƒç”¨ Gemini")
            
            # åœ¨ executor ä¸­è¿è¡Œ Gemini åˆ†æï¼ˆé¿å…é˜»å¡äº‹ä»¶å¾ªç¯ï¼‰ï¼Œå¸¦ 6 åˆ†é’Ÿè¶…æ—¶
            logger.info(f"[åˆ†æ-{session_id}] step_async3: å³å°†è°ƒç”¨ analyze_audio_from_pathï¼ˆexecutorï¼‰")
            def _run_analysis():
                return asyncio.run(analyze_audio_from_path(temp_file_path, file_filename or "audio.m4a", session_id=session_id))
            try:
                result, call1_result = await asyncio.wait_for(
                    asyncio.get_event_loop().run_in_executor(None, _run_analysis),
                    timeout=360.0  # 6 åˆ†é’Ÿè¶…æ—¶ï¼Œé˜²æ­¢ Gemini ä¸Šä¼ å¡ä½å¯¼è‡´æ°¸ä¹… analyzing
                )
                logger.info(f"[åˆ†æ-{session_id}] step_async4: analyze_audio_from_path è¿”å›æˆåŠŸ")
            except asyncio.TimeoutError:
                logger.error(f"[åˆ†æ-{session_id}] step_async4: 6 åˆ†é’Ÿè¶…æ—¶ï¼Gemini åˆ†ææœªåœ¨é™æ—¶å†…å®Œæˆ")
                raise Exception("åˆ†æè¶…æ—¶ï¼ˆ6 åˆ†é’Ÿï¼‰ï¼Œå¯èƒ½å›  Gemini æ–‡ä»¶ä¸Šä¼ å¤±è´¥æˆ–ä»£ç†ä¸å¯è¾¾ï¼Œè¯·æ£€æŸ¥ç½‘ç»œ/ä»£ç†é…ç½®")
            
            # ä½¿ç”¨Call1ç»“æœæˆ–æ—§ç»“æœ
            if call1_result:
                emotion_score = call1_result.mood_score
                stats = call1_result.stats
                summary = call1_result.summary
                transcript = [t.dict() for t in call1_result.transcript]
            else:
                emotion_score = calculate_emotion_score(result)
                stats = {"sigh": 0, "laugh": 0}
                summary = ""
                transcript = []
            
            tags = generate_tags(result)
            
            end_time = datetime.now()
            duration = int((end_time - datetime.fromisoformat(task_data["start_time"])).total_seconds())
            
            # æ›´æ–°å†…å­˜å­˜å‚¨ï¼ˆå‘åå…¼å®¹ï¼‰
            task_data.update({
                "end_time": end_time.isoformat(),
                "duration": duration,
                "status": "archived",
                "emotion_score": emotion_score,
                "speaker_count": result.speaker_count,
                "tags": tags,
                "updated_at": end_time.isoformat()
            })
            
            # æ›´æ–°æ•°æ®åº“Session
            result_query = await db.execute(select(Session).where(Session.id == uuid.UUID(session_id)))
            db_session = result_query.scalar_one_or_none()
            if db_session:
                db_session.end_time = end_time
                db_session.duration = duration
                db_session.status = "archived"
                db_session.analysis_stage = None  # å®Œæˆæ—¶æ¸…é™¤
                db_session.error_message = None  # æˆåŠŸæ—¶æ¸…é™¤æ—§å¤±è´¥åŸå› 
                db_session.emotion_score = emotion_score
                db_session.speaker_count = result.speaker_count
                db_session.tags = tags
                await db.commit()
                logger.info(f"æ•°æ®åº“Sessionå·²æ›´æ–°: {session_id}")
            
            # ä¿å­˜åˆ†æç»“æœåˆ°æ•°æ®åº“
            analysis_result = AnalysisResult(
                session_id=uuid.UUID(session_id),
                dialogues=[d.dict() for d in result.dialogues],
                risks=result.risks,
                summary=summary,
                mood_score=emotion_score,
                stats=stats,
                transcript=json.dumps(transcript, ensure_ascii=False) if transcript else None,
                call1_result=call1_result.dict() if call1_result else None
            )
            db.add(analysis_result)
            await db.commit()
            logger.info(f"åˆ†æç»“æœå·²ä¿å­˜åˆ°æ•°æ®åº“: {session_id}")
            
            # æ›´æ–°è¿›åº¦ï¼šå£°çº¹åŒ¹é…
            _vq = await db.execute(select(Session).where(Session.id == uuid.UUID(session_id)))
            _vs = _vq.scalar_one_or_none()
            if _vs:
                _vs.analysis_stage = "voiceprint"
                await db.commit()
            
            # åˆ†æåæµç¨‹ï¼šæŒ‰è¯´è¯äººé€‰ä»£è¡¨ç‰‡æ®µ â†’ å£°çº¹è¯†åˆ« â†’ å†™ speaker_mapping
            speaker_mapping = {}
            has_audio = bool(audio_url or audio_path)
            logger.info(f"[å£°çº¹] session_id={session_id} transcript_len={len(transcript) if transcript else 0} has_audio={has_audio} audio_url={bool(audio_url)} audio_path={bool(audio_path)}")
            if not transcript:
                logger.info(f"[å£°çº¹] session_id={session_id} æ—  transcriptï¼Œè·³è¿‡å£°çº¹åŒ¹é…")
            elif not has_audio:
                logger.info(f"[å£°çº¹] session_id={session_id} æ— åŸéŸ³é¢‘ URL/è·¯å¾„ï¼Œè·³è¿‡å£°çº¹åŒ¹é…")
            if transcript and has_audio:
                try:
                    from utils.audio_storage import get_session_audio_local_path
                    def _ts_to_sec(ts):
                        if not ts:
                            return 0.0
                        try:
                            parts = str(ts).split(":")
                            if len(parts) == 2:
                                return int(parts[0]) * 60 + float(parts[1])
                        except Exception:
                            pass
                        return 0.0
                    # ä¸ºæ¯ä¸ª speaker å–ç¬¬ä¸€å¥çš„ (start_sec, end_sec)
                    first_segment = {}
                    for i, t in enumerate(transcript):
                        sp = t.get("speaker") or "æœªçŸ¥"
                        if sp not in first_segment:
                            start_sec = _ts_to_sec(t.get("timestamp"))
                            if i + 1 < len(transcript):
                                end_sec = _ts_to_sec(transcript[i + 1].get("timestamp"))
                            else:
                                end_sec = float(duration) if duration else start_sec + 5.0
                            if end_sec <= start_sec:
                                end_sec = start_sec + 2.0
                            first_segment[sp] = (start_sec, end_sec)
                    local_path, is_temp = get_session_audio_local_path(audio_url, audio_path)
                    logger.info(f"[å£°çº¹] session_id={session_id} æœ¬åœ°éŸ³é¢‘ local_path={bool(local_path)} is_temp={is_temp} speakers={list(first_segment.keys())}")
                    if not local_path:
                        logger.warning(f"[å£°çº¹] session_id={session_id} æ— æ³•è·å–æœ¬åœ°éŸ³é¢‘ï¼ˆä¸‹è½½æˆ–è·¯å¾„å¤±è´¥ï¼‰ï¼Œè·³è¿‡å£°çº¹åŒ¹é…")
                    if local_path:
                        profile_result = await db.execute(
                            select(Profile.id, Profile.relationship_type).where(Profile.user_id == uuid.UUID(user_id))
                        )
                        _rows = profile_result.all()
                        profile_ids = [str(row[0]) for row in _rows]
                        self_profile_id = None
                        for row in _rows:
                            rel = row[1] if len(row) > 1 else None
                            if rel == "è‡ªå·±":
                                self_profile_id = str(row[0])
                                break
                        logger.info(f"[å£°çº¹] session_id={session_id} å½“å‰ç”¨æˆ·æ¡£æ¡ˆæ•° profile_count={len(profile_ids)} self_profile_id={self_profile_id}")
                        if not profile_ids:
                            logger.warning(f"[å£°çº¹] session_id={session_id} å½“å‰ç”¨æˆ·æ— æ¡£æ¡ˆï¼Œè·³è¿‡å£°çº¹åŒ¹é…")
                        # å ä½ï¼šä»… 1 ä¸ªè¯´è¯äººä¸” 1 ä¸ªæ¡£æ¡ˆæ—¶ç›´æ¥æ˜ å°„
                        elif len(first_segment) == 1 and len(profile_ids) == 1:
                            only_sp = next(iter(first_segment.keys()))
                            speaker_mapping[only_sp] = profile_ids[0]
                            logger.info(f"[å£°çº¹] å ä½å•è¯´è¯äººå•æ¡£æ¡ˆ: {only_sp} -> {profile_ids[0]}")
                        else:
                            # å¤šäººï¼šåˆ©ç”¨ is_me æ˜ å°„ã€Œè‡ªå·±ã€ï¼Œå…¶ä½™ä¸ç›²æ˜ å°„ï¼ˆé¿å…æ–°äººè¯¯æ ‡ä¸ºå…¶ä»–æ¡£æ¡ˆï¼‰
                            speaker_with_is_me = None
                            for t in transcript:
                                if t.get("is_me") is True:
                                    speaker_with_is_me = t.get("speaker")
                                    break
                            if self_profile_id and speaker_with_is_me:
                                speaker_mapping[speaker_with_is_me] = self_profile_id
                                logger.info(f"[å£°çº¹] åˆ©ç”¨ is_me æ˜ å°„è‡ªå·±: {speaker_with_is_me} -> {self_profile_id}")
                            # é is_me çš„è¯´è¯äººï¼ˆå¦‚æ–°äººï¼‰ä¸å†åšç›²æ˜ å°„
                        if is_temp and os.path.isfile(local_path):
                            try:
                                os.unlink(local_path)
                            except Exception:
                                pass
                    if speaker_mapping:
                        ar_result = await db.execute(select(AnalysisResult).where(AnalysisResult.session_id == uuid.UUID(session_id)))
                        ar = ar_result.scalar_one_or_none()
                        if ar:
                            ar.speaker_mapping = speaker_mapping
                            await db.commit()
                            logger.info(f"[å£°çº¹] session_id={session_id} speaker_mapping å·²å†™å…¥: {speaker_mapping}")
                        else:
                            logger.warning(f"[å£°çº¹] session_id={session_id} æœªæ‰¾åˆ° AnalysisResultï¼Œæ— æ³•å†™å…¥ speaker_mapping")
                    else:
                        logger.info(f"[å£°çº¹] session_id={session_id} speaker_mapping ä¸ºç©ºï¼Œæœªå†™å…¥")
                except Exception as e:
                    logger.warning(f"[å£°çº¹] session_id={session_id} åˆ†æåå£°çº¹åŒ¹é…å¤±è´¥: {e}", exc_info=True)
            
            # ç¬¬äºŒæ¬¡ Geminiï¼šæ€»ç»“ã€Œè°å’Œè°å¯¹è¯ã€
            conversation_summary = None
            if transcript:
                try:
                    profile_names = {}
                    if speaker_mapping:
                        profile_ids_in_mapping = list(speaker_mapping.values())
                        if profile_ids_in_mapping:
                            profile_res = await db.execute(
                                select(Profile.id, Profile.name, Profile.relationship_type).where(
                                    Profile.user_id == uuid.UUID(user_id),
                                    Profile.id.in_([uuid.UUID(pid) for pid in profile_ids_in_mapping])
                                )
                            )
                            for row in profile_res.all():
                                name = row.name or "æœªçŸ¥"
                                rel = getattr(row, "relationship_type", None) or "æœªçŸ¥"
                                profile_names[str(row.id)] = f"{name}ï¼ˆ{rel}ï¼‰"
                    lines = []
                    for t in transcript:
                        sp = t.get("speaker") or "æœªçŸ¥"
                        name = profile_names.get(speaker_mapping.get(sp, ""), sp)
                        text = (t.get("text") or "").strip()
                        lines.append(f"{name}: {text}")
                    display_text = "\n".join(lines)
                    prompt = f"""æ ¹æ®ä»¥ä¸‹å¯¹è¯ï¼Œæ€»ç»“è¿™æ˜¯è°å’Œè°çš„å¯¹è¯ï¼ˆè§’è‰²å…³ç³»ã€å¯¹è¯ä¸»é¢˜ã€åŒæ–¹ç«‹åœºç­‰ï¼‰ã€‚å¯¹è¯æ ¼å¼ä¸º è¯´è¯äºº: å†…å®¹ã€‚è¯·ç”¨ä¸€ä¸¤æ®µè¯æ¦‚æ‹¬ï¼Œä¸è¦åˆ—ç‚¹ã€‚

å¯¹è¯ï¼š
{display_text}

æ€»ç»“ï¼š"""
                    model = genai.GenerativeModel(GEMINI_FLASH_MODEL)
                    resp = model.generate_content(prompt)
                    if resp and resp.text:
                        conversation_summary = resp.text.strip()
                        ar_res = await db.execute(select(AnalysisResult).where(AnalysisResult.session_id == uuid.UUID(session_id)))
                        ar = ar_res.scalar_one_or_none()
                        if ar:
                            ar.conversation_summary = conversation_summary
                            await db.commit()
                            logger.info(f"conversation_summary å·²å†™å…¥: {session_id}")
                except Exception as e:
                    logger.warning(f"ç¬¬äºŒæ¬¡ Gemini æ€»ç»“å¤±è´¥: {e}", exc_info=True)
            
            # v0.6 è®°å¿†æå–ï¼ˆB é’©å­ï¼‰ï¼šæ¡£æ¡ˆåŒ¹é…å®Œæˆåå†™å…¥ Mem0
            if speaker_mapping and conversation_summary and profile_names:
                logger.info(f"[è®°å¿†] B é’©å­è§¦å‘: session_id={session_id} speaker_mapping={speaker_mapping} profile_names_keys={list(profile_names.keys())}")
                try:
                    from services.memory_service import build_memory_payload, add_memory
                    payload = build_memory_payload(
                        transcript, conversation_summary, speaker_mapping, profile_names
                    )
                    metadata = {
                        "session_id": session_id,
                        "profile_ids": list(speaker_mapping.values()),
                    }
                    logger.info(f"[è®°å¿†] B é’©å­è°ƒç”¨ add_memory: session_id={session_id} payload_len={len(payload)}")
                    # åŒæ­¥ add_memory åœ¨çº¿ç¨‹ä¸­æ‰§è¡Œï¼Œé¿å…é˜»å¡äº‹ä»¶å¾ªç¯
                    ok = await asyncio.to_thread(
                        add_memory,
                        payload,
                        user_id,
                        metadata=metadata,
                        enable_graph=True,
                    )
                    logger.info(f"[è®°å¿†] B é’©å­ add_memory ç»“æœ: session_id={session_id} success={ok}")
                except Exception as mem_err:
                    logger.warning(f"[è®°å¿†] B é’©å­å†™å…¥å¤±è´¥: session_id={session_id} error={mem_err}", exc_info=True)
            else:
                logger.info(f"[è®°å¿†] B é’©å­è·³è¿‡: session_id={session_id} speaker_mapping={bool(speaker_mapping)} conversation_summary={bool(conversation_summary)} profile_names={bool(profile_names)}")
            
            # å­˜å‚¨åˆ†æç»“æœåˆ°å†…å­˜ï¼ˆå‘åå…¼å®¹ï¼‰
            analysis_storage[session_id] = {
                "dialogues": [d.dict() for d in result.dialogues],
                "risks": result.risks,
                "call1": call1_result.dict() if call1_result else None,
                "mood_score": emotion_score,
                "stats": stats,
                "summary": summary,
                "transcript": transcript
            }
            
            logger.info(f"ä»»åŠ¡ {session_id} åˆ†æå®Œæˆ")
            
            # å¼‚æ­¥ç”Ÿæˆç­–ç•¥åˆ†æï¼ˆä¸é˜»å¡ä¸»æµç¨‹ï¼‰
            logger.info(f"å¼€å§‹å¼‚æ­¥ç”Ÿæˆç­–ç•¥åˆ†æ: {session_id}")
            asyncio.create_task(generate_strategies_async(session_id, user_id))
            
        except Exception as e:
            logger.error(f"[åˆ†æ-{session_id}] âŒ åˆ†æéŸ³é¢‘å¤±è´¥: {type(e).__name__}: {str(e)}")
            logger.error(traceback.format_exc())
            
            # æ›´æ–°å†…å­˜å­˜å‚¨
            err_msg = str(e)[:500]
            task_data["status"] = "failed"
            task_data["error_message"] = err_msg
            task_data["updated_at"] = datetime.now().isoformat()

            # æ›´æ–°æ•°æ®åº“çŠ¶æ€
            try:
                result_query = await db.execute(select(Session).where(Session.id == uuid.UUID(session_id)))
                db_session = result_query.scalar_one_or_none()
                if db_session:
                    db_session.status = "failed"
                    db_session.analysis_stage = "failed"
                    db_session.error_message = err_msg
                    await db.commit()
                    logger.info(f"æ•°æ®åº“SessionçŠ¶æ€å·²æ›´æ–°ä¸º failed: {session_id}")
                else:
                    logger.warning(f"æœªæ‰¾åˆ°æ•°æ®åº“Session: {session_id}")
            except Exception as db_error:
                logger.error(f"æ›´æ–°æ•°æ®åº“çŠ¶æ€å¤±è´¥: {db_error}")
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if temp_file_path and os.path.exists(temp_file_path):
                try:
                    os.unlink(temp_file_path)
                    logger.info(f"å·²åˆ é™¤ä¸´æ—¶æ–‡ä»¶: {temp_file_path}")
                except Exception as e:
                    logger.error(f"åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")


@app.get("/api/v1/tasks/sessions")
async def get_task_list(
    page: int = Query(1, ge=1),
    page_size: int = Query(20, ge=1, le=100),
    date: Optional[str] = None,
    status: Optional[str] = None,
    user_id: str = Depends(get_current_user_id),
    db: AsyncSession = Depends(get_db)
):
    """è·å–ä»»åŠ¡åˆ—è¡¨ï¼ˆéœ€è¦JWTè®¤è¯ï¼Œä»…è¿”å›å½“å‰ç”¨æˆ·çš„ä»»åŠ¡ï¼‰"""
    from datetime import datetime
    
    t_start = time.time()
    logger.info(f"[ä»»åŠ¡åˆ—è¡¨] è¿›å…¥ handler user_id={user_id[:8]}... page={page} page_size={page_size}")
    try:
        # ä»æ•°æ®åº“æŸ¥è¯¢å½“å‰ç”¨æˆ·çš„ä»»åŠ¡
        t0 = time.time()
        query = select(Session).where(Session.user_id == uuid.UUID(user_id))
        
        if date:
            target_date = datetime.fromisoformat(date).date()
            query = query.where(
                func.date(Session.start_time) == target_date
            )
        
        if status:
            query = query.where(Session.status == status)
        
        query = query.order_by(Session.created_at.desc())
        
        # é¦–å±æ€§èƒ½ä¼˜åŒ–ï¼šä¸æ‰§è¡Œ countï¼Œåªè¯·æ±‚ page_size+1 æ¡ä»¥åˆ¤æ–­ has_more
        query = query.offset((page - 1) * page_size).limit(page_size + 1)
        result = await db.execute(query)
        sessions = result.scalars().all()
        db_elapsed = time.time() - t0
        if db_elapsed > 2.0:
            logger.warning(f"[ä»»åŠ¡åˆ—è¡¨] Session æŸ¥è¯¢è€—æ—¶ {db_elapsed:.2f}s count={len(sessions)}")
        has_more = len(sessions) > page_size
        if has_more:
            sessions = sessions[:page_size]
        
        session_ids = [str(s.id) for s in sessions]
        summary_map = {}
        cover_map = {}
        
        if session_ids:
            ar_result = await db.execute(select(AnalysisResult).where(AnalysisResult.session_id.in_([uuid.UUID(sid) for sid in session_ids])))
            for ar in ar_result.scalars().all():
                summary_map[str(ar.session_id)] = ar.summary
            sa_result = await db.execute(select(StrategyAnalysis).where(StrategyAnalysis.session_id.in_([uuid.UUID(sid) for sid in session_ids])))
            api_base = os.getenv("API_PUBLIC_URL", "http://47.79.254.213")
            api_base = api_base.rstrip("/")
            for sa in sa_result.scalars().all():
                sid = str(sa.session_id)
                vd = sa.visual_data
                if isinstance(vd, list) and len(vd) > 0:
                    first_v = vd[0] if isinstance(vd[0], dict) else getattr(vd[0], "__dict__", {})
                    img_url = first_v.get("image_url") if isinstance(first_v, dict) else getattr(first_v, "image_url", None)
                    if img_url:
                        # ç»Ÿä¸€èµ°ä»£ç† APIï¼ˆéœ€ JWTï¼‰ï¼Œé¿å… OSS ç§æœ‰ URL ç›´æ¥è®¿é—® 403
                        cover_map[sid] = f"{api_base}/api/v1/images/{sid}/0"
        
        task_items = [
            TaskItem(
                session_id=str(s.id),
                title=s.title or "",
                start_time=s.start_time.isoformat() if s.start_time else "",
                end_time=s.end_time.isoformat() if s.end_time else None,
                duration=s.duration or 0,
                tags=s.tags or [],
                status=s.status or "unknown",
                emotion_score=s.emotion_score,
                speaker_count=s.speaker_count,
                summary=summary_map.get(str(s.id)),
                cover_image_url=cover_map.get(str(s.id))
            )
            for s in sessions
        ]
        
        total_elapsed = time.time() - t_start
        logger.info(f"[ä»»åŠ¡åˆ—è¡¨] å®Œæˆ total={total_elapsed:.2f}s sessions={len(task_items)}")
        return APIResponse(
            code=200,
            message="success",
            data={
                "sessions": [t.dict() for t in task_items],
                "pagination": {
                    "page": page,
                    "page_size": page_size,
                    "has_more": has_more
                }
            },
            timestamp=datetime.now().isoformat()
        )
    except Exception as e:
        logger.error(f"è·å–ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {type(e).__name__}: {e}")
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"è·å–åˆ—è¡¨å¤±è´¥: {str(e)}")


@app.get("/api/v1/tasks/sessions/{session_id}")
async def get_task_detail(
    session_id: str,
    user_id: str = Depends(get_current_user_id),
    db: AsyncSession = Depends(get_db)
):
    """è·å–ä»»åŠ¡è¯¦æƒ…ï¼ˆéœ€è¦JWTè®¤è¯ï¼Œä»…èƒ½è®¿é—®è‡ªå·±çš„ä»»åŠ¡ï¼‰"""
    from datetime import datetime
    
    try:
        # ä»æ•°æ®åº“æŸ¥è¯¢ä»»åŠ¡ï¼Œç¡®ä¿å±äºå½“å‰ç”¨æˆ·
        result = await db.execute(
            select(Session).where(
                Session.id == uuid.UUID(session_id),
                Session.user_id == uuid.UUID(user_id)
            )
        )
        db_session = result.scalar_one_or_none()
        
        if not db_session:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
        
        # æŸ¥è¯¢åˆ†æç»“æœ
        analysis_result_query = await db.execute(
            select(AnalysisResult).where(AnalysisResult.session_id == uuid.UUID(session_id))
        )
        analysis_result = analysis_result_query.scalar_one_or_none()
        
        dialogues = []
        risks = []
        summary = None
        speaker_mapping = None
        speaker_names = None
        conversation_summary = None
        
        if analysis_result:
            dialogues = analysis_result.dialogues if isinstance(analysis_result.dialogues, list) else []
            risks = analysis_result.risks or []
            summary = analysis_result.summary
            speaker_mapping = analysis_result.speaker_mapping if isinstance(analysis_result.speaker_mapping, dict) else None
            conversation_summary = getattr(analysis_result, "conversation_summary", None) or None
            name_to_display = {}  # æ¡£æ¡ˆå/è§’è‰²å -> å±•ç¤ºæ ¼å¼ï¼Œç”¨äºæ›¿æ¢ Gemini ç›´æ¥å†™å‡ºçš„è§’è‰²åï¼ˆå¦‚æ¢è‡´è¿œï¼‰
            speaker_names = None

            # è§£æ transcriptï¼ˆæ¥è‡ª transcript å­—æ®µæˆ– call1_resultï¼‰
            transcript = []
            if getattr(analysis_result, "transcript", None):
                try:
                    transcript = json.loads(analysis_result.transcript) if isinstance(analysis_result.transcript, str) else (analysis_result.transcript or [])
                except Exception:
                    transcript = []
            if not transcript and getattr(analysis_result, "call1_result", None):
                call1 = analysis_result.call1_result
                if isinstance(call1, dict) and "transcript" in call1:
                    transcript = call1.get("transcript") or []

            # ä¼˜å…ˆä½¿ç”¨ transcript + is_me è®¡ç®—æ­£ç¡®çš„ speaker_namesï¼ˆä¿®å¤æ—§ä»»åŠ¡é”™è¯¯æ˜ å°„ï¼‰
            self_profile_id = None
            self_display = None
            profile_rows = await db.execute(
                select(Profile.id, Profile.name, Profile.relationship_type).where(Profile.user_id == uuid.UUID(user_id))
            )
            for row in profile_rows.all():
                rel = getattr(row, "relationship_type", None) or (row[2] if len(row) > 2 else None)
                if rel == "è‡ªå·±":
                    self_profile_id = str(getattr(row, "id", row[0]))
                    name = getattr(row, "name", None) or (row[1] if len(row) > 1 else None) or "æœªçŸ¥"
                    self_display = f"{name}ï¼ˆè‡ªå·±ï¼‰"
                    if name and name.strip():
                        name_to_display[name.strip()] = self_display
                        if "å¿—" in name or "è‡´" in name:
                            alt = name.replace("å¿—", "è‡´") if "å¿—" in name else name.replace("è‡´", "å¿—")
                            if alt != name:
                                name_to_display[alt.strip()] = self_display
                    break

            if transcript and self_profile_id and self_display:
                # ä» transcript æ‰¾ is_me=true çš„ speakerï¼Œä»…æ˜ å°„ã€Œè‡ªå·±ã€ï¼Œå…¶ä½™ä¿æŒ Speaker_X
                speaker_with_is_me = None
                for t in transcript:
                    if t.get("is_me") is True:
                        speaker_with_is_me = t.get("speaker")
                        break
                if speaker_with_is_me:
                    speaker_names = {speaker_with_is_me: self_display}
                    # é is_me çš„è¯´è¯äººä¸æ˜ å°„ï¼Œ_speaker_to_display ä¼šè¿”å›åŸ speaker_valï¼ˆå¦‚ Speaker_0ï¼‰
                    logger.info(f"[ä»»åŠ¡è¯¦æƒ…] session={session_id} ä½¿ç”¨ transcript+is_me è®¡ç®— speaker_names: {speaker_names}ï¼Œæœªæ˜ å°„è€…æ˜¾ç¤ºä¸º Speaker_X")
            elif speaker_mapping and not speaker_names:
                # æ—  transcript/is_me æ—¶å›é€€åˆ° speaker_mappingï¼ˆå…¼å®¹æ—§é€»è¾‘ï¼‰
                profile_ids_in_mapping = list(speaker_mapping.values())
                if profile_ids_in_mapping:
                    try:
                        profile_res = await db.execute(
                            select(Profile.id, Profile.name, Profile.relationship_type).where(
                                Profile.user_id == uuid.UUID(user_id),
                                Profile.id.in_([uuid.UUID(pid) for pid in profile_ids_in_mapping])
                            )
                        )
                        id_to_display = {}
                        for row in profile_res.all():
                            name = row.name or "æœªçŸ¥"
                            rel = getattr(row, "relationship_type", None) or "æœªçŸ¥"
                            display = f"{name}ï¼ˆ{rel}ï¼‰"
                            id_to_display[str(row.id)] = display
                            if name and name.strip():
                                name_to_display[name.strip()] = display
                                if "å¿—" in name or "è‡´" in name:
                                    alt = name.replace("å¿—", "è‡´") if "å¿—" in name else name.replace("è‡´", "å¿—")
                                    if alt != name:
                                        name_to_display[alt.strip()] = display
                        speaker_names = {sp: id_to_display.get(pid, sp) for sp, pid in speaker_mapping.items()}
                    except Exception:
                        speaker_names = None
            
            # è‹¥å·²æœ‰ speaker_namesï¼Œè¿”å›å‰åœ¨ summary / conversation_summary / dialogues ä¸­æŠŠ Speaker_0/Speaker_1 æ›¿æ¢ä¸ºæ¡£æ¡ˆå
            def _replace_speaker_labels(text: Optional[str], names: dict) -> Optional[str]:
                if not text or not names:
                    return text
                for sp in sorted(names.keys(), key=len, reverse=True):
                    text = text.replace(sp, names[sp])
                # Call #1 çº¦å®š Speaker_1 ä¸ºç”¨æˆ·ï¼ŒGemini æ€»ç»“å¸¸å†™ã€Œç”¨æˆ·ã€è€Œé Speaker_1ï¼Œä¸€å¹¶æ›¿æ¢ä¸ºæ¡£æ¡ˆå
                if "Speaker_1" in names:
                    text = text.replace("ç”¨æˆ·", names["Speaker_1"])
                # å…¼å®¹å…¶ä»–å†™æ³•ï¼šè¯´è¯äºº0/1ã€Speaker0/1ï¼ˆæ— ä¸‹åˆ’çº¿ï¼‰
                alias_map = [("è¯´è¯äºº0", "Speaker_0"), ("è¯´è¯äºº1", "Speaker_1"), ("Speaker0", "Speaker_0"), ("Speaker1", "Speaker_1")]
                for alias, canonical in alias_map:
                    if canonical in names and alias in text:
                        text = text.replace(alias, names[canonical])
                return text

            def _replace_profile_names(text: Optional[str], name_map: dict) -> Optional[str]:
                """æ›¿æ¢ Gemini åœ¨æ€»ç»“ä¸­ç›´æ¥å†™å‡ºçš„æ¡£æ¡ˆå/è§’è‰²åï¼ˆå¦‚ æ¢è‡´è¿œï¼‰ä¸º æ¡£æ¡ˆåï¼ˆå…³ç³»ï¼‰"""
                if not text or not name_map:
                    return text
                for name in sorted(name_map.keys(), key=len, reverse=True):
                    # ä»…æ›¿æ¢ä½œä¸ºç‹¬ç«‹è¯å‡ºç°çš„æ¡£æ¡ˆåï¼Œé¿å…è¯¯æ›¿æ¢ï¼ˆå¦‚ã€Œæ¢è‡´è¿œè¯´ã€ä¸­çš„æ¢è‡´è¿œï¼‰
                    text = text.replace(name, name_map[name])
                return text

            def _speaker_to_display(speaker_val: str, names: dict) -> str:
                """å°†è¯´è¯äººæ ‡ç­¾è½¬ä¸ºæ¡£æ¡ˆåå±•ç¤º"""
                if not names or not speaker_val:
                    return speaker_val
                if speaker_val in names:
                    return names[speaker_val]
                alias_map = {"è¯´è¯äºº0": "Speaker_0", "è¯´è¯äºº1": "Speaker_1", "Speaker0": "Speaker_0", "Speaker1": "Speaker_1"}
                canonical = alias_map.get(speaker_val)
                return names.get(canonical, speaker_val) if canonical else speaker_val

            if speaker_names:
                summary = _replace_speaker_labels(summary, speaker_names)
                conversation_summary = _replace_speaker_labels(conversation_summary, speaker_names)
                # é¢å¤–æ›¿æ¢ï¼šGemini å¯èƒ½åœ¨æ€»ç»“ä¸­ç›´æ¥å†™å‡ºè§’è‰²åï¼ˆå¦‚æ¢è‡´è¿œï¼‰ï¼Œéœ€æ›¿æ¢ä¸º æ¡£æ¡ˆåï¼ˆå…³ç³»ï¼‰
                summary = _replace_profile_names(summary, name_to_display)
                conversation_summary = _replace_profile_names(conversation_summary, name_to_display)
                # æ¯æ¡ dialogue çš„ speaker å­—æ®µä¹Ÿæ›¿æ¢ä¸ºæ¡£æ¡ˆåï¼Œä¾¿äºå‰ç«¯ç›´æ¥å±•ç¤º
                if dialogues:
                    new_dialogues = []
                    for d in dialogues:
                        if isinstance(d, dict) and "speaker" in d:
                            d = dict(d)  # æ·±æ‹·è´ä¸€å±‚ï¼Œé¿å…æ”¹åŸå§‹æ•°æ®
                            d["speaker"] = _speaker_to_display(d.get("speaker", ""), speaker_names)
                        new_dialogues.append(d)
                    dialogues = new_dialogues
                logger.info(f"[ä»»åŠ¡è¯¦æƒ…] session={session_id} å·²å¯¹ summary/conversation_summary/dialogues åšæ¡£æ¡ˆåæ›¿æ¢ speaker_names={list(speaker_names.keys())}")
        
        detail = TaskDetailResponse(
            session_id=str(db_session.id),
            title=db_session.title or "",
            start_time=db_session.start_time.isoformat() if db_session.start_time else "",
            end_time=db_session.end_time.isoformat() if db_session.end_time else None,
            duration=db_session.duration or 0,
            tags=db_session.tags or [],
            status=db_session.status or "unknown",
            error_message=getattr(db_session, "error_message", None) or None,
            emotion_score=db_session.emotion_score,
            speaker_count=db_session.speaker_count,
            dialogues=dialogues,
            risks=risks,
            summary=summary,
            speaker_mapping=speaker_mapping,
            speaker_names=speaker_names,
            conversation_summary=conversation_summary,
            created_at=db_session.created_at.isoformat() if db_session.created_at else "",
            updated_at=db_session.updated_at.isoformat() if db_session.updated_at else ""
        )
        
        return APIResponse(
            code=200,
            message="success",
            data=detail.dict(),
            timestamp=datetime.now().isoformat()
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–ä»»åŠ¡è¯¦æƒ…å¤±è´¥: {e}")
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"è·å–è¯¦æƒ…å¤±è´¥: {str(e)}")


@app.get("/api/v1/tasks/sessions/{session_id}/status")
async def get_task_status(
    session_id: str,
    user_id: str = Depends(get_current_user_id),
    db: AsyncSession = Depends(get_db)
):
    """æŸ¥è¯¢ä»»åŠ¡åˆ†æçŠ¶æ€ï¼ˆéœ€è¦JWTè®¤è¯ï¼Œä»…èƒ½è®¿é—®è‡ªå·±çš„ä»»åŠ¡ï¼‰"""
    from datetime import datetime
    
    try:
        # ä»æ•°æ®åº“æŸ¥è¯¢ä»»åŠ¡ï¼Œç¡®ä¿å±äºå½“å‰ç”¨æˆ·
        result = await db.execute(
            select(Session).where(
                Session.id == uuid.UUID(session_id),
                Session.user_id == uuid.UUID(user_id)
            )
        )
        db_session = result.scalar_one_or_none()
        
        if not db_session:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
        
        status_value = db_session.status or "unknown"
        analysis_stage = getattr(db_session, "analysis_stage", None) or ""
        
        # æ ¹æ®é˜¶æ®µä¼°ç®—è¿›åº¦ä¸å‰©ä½™æ—¶é—´
        if status_value == "archived":
            progress_val, eta = 1.0, 0
        elif status_value == "failed":
            progress_val, eta = 0.0, 0
        else:
            stage_map = {"gemini_analysis": (0.5, 45), "voiceprint": (0.9, 10)}
            progress_val, eta = stage_map.get(analysis_stage, (0.3, 60))
        
        payload = {
            "session_id": session_id,
            "status": status_value,
            "progress": progress_val,
            "estimated_time_remaining": eta,
            "analysis_stage": analysis_stage,
            "updated_at": db_session.updated_at.isoformat() if db_session.updated_at else ""
        }
        if status_value == "failed" and getattr(db_session, "error_message", None):
            payload["failure_reason"] = db_session.error_message
        return APIResponse(
            code=200,
            message="success",
            data=payload,
            timestamp=datetime.now().isoformat()
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {e}")
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"è·å–çŠ¶æ€å¤±è´¥: {str(e)}")


async def generate_strategies_async(session_id: str, user_id: str):
    """å¼‚æ­¥ç”Ÿæˆç­–ç•¥åˆ†æï¼ˆåœ¨éŸ³é¢‘åˆ†æå®Œæˆåè‡ªåŠ¨è°ƒç”¨ï¼‰"""
    from datetime import datetime
    from database.connection import AsyncSessionLocal
    
    # åˆ›å»ºæ–°çš„æ•°æ®åº“ä¼šè¯
    async with AsyncSessionLocal() as db:
        try:
            logger.info(f"========== å¼€å§‹å¼‚æ­¥ç”Ÿæˆç­–ç•¥åˆ†æ ==========")
            logger.info(f"session_id: {session_id}, user_id: {user_id}")
            
            # éªŒè¯ä»»åŠ¡å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
            result = await db.execute(
                select(Session).where(
                    Session.id == uuid.UUID(session_id),
                    Session.user_id == uuid.UUID(user_id)
                )
            )
            db_session = result.scalar_one_or_none()
            
            if not db_session:
                logger.error(f"ä»»åŠ¡ä¸å­˜åœ¨: {session_id}")
                return
            
            # ä»æ•°æ®åº“æŸ¥è¯¢åˆ†æç»“æœ
            analysis_result_query = await db.execute(
                select(AnalysisResult).where(AnalysisResult.session_id == uuid.UUID(session_id))
            )
            analysis_result_db = analysis_result_query.scalar_one_or_none()
            
            if not analysis_result_db:
                logger.error(f"åˆ†æç»“æœä¸å­˜åœ¨: {session_id}")
                return
            
            # è·å–transcript
            transcript = []
            if analysis_result_db.transcript:
                try:
                    transcript = json.loads(analysis_result_db.transcript) if isinstance(analysis_result_db.transcript, str) else analysis_result_db.transcript
                except:
                    transcript = []
            
            # å‘åå…¼å®¹ï¼šä»å†…å­˜å­˜å‚¨è·å–ï¼ˆå¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰ï¼‰
            analysis_result = analysis_storage.get(session_id, {})
            if not transcript and analysis_result:
                transcript = analysis_result.get("transcript", [])
            
            if not transcript:
                logger.error(f"å¯¹è¯è½¬å½•æ•°æ®ä¸å­˜åœ¨: {session_id}")
                return
            
            # è°ƒç”¨æ ¸å¿ƒç­–ç•¥ç”Ÿæˆé€»è¾‘
            await _generate_strategies_core(session_id, user_id, transcript, db)
            
        except Exception as e:
            logger.error(f"å¼‚æ­¥ç”Ÿæˆç­–ç•¥åˆ†æå¤±è´¥: {e}")
            logger.error(traceback.format_exc())


_SKILL_ID_TO_NAME = {
    "workplace_jungle": "èŒåœºä¸›æ—",
    "family_relationship": "å®¶åº­å…³ç³»",
    "education_communication": "æ•™è‚²æ²Ÿé€š",
    "brainstorm": "å¤´è„‘é£æš´",
    "emotion_recognition": "æƒ…ç»ªè¯†åˆ«",
}


def _build_legacy_skill_cards(visual_data: list, strategies: list, applied_skills: list) -> list:
    """ä»æ—§æ ¼å¼ visual_data + strategies æ„é€ å…¼å®¹çš„ skill_cards ç»“æ„"""
    if not visual_data and not strategies:
        return []
    skill_id = applied_skills[0]["skill_id"] if applied_skills else "unknown"
    skill_name = applied_skills[0].get("name") or _SKILL_ID_TO_NAME.get(skill_id, skill_id)
    def _to_dict(x):
        if isinstance(x, dict):
            return x
        if hasattr(x, "model_dump"):
            return x.model_dump()
        return x.__dict__ if hasattr(x, "__dict__") else {}
    v_dicts = [_to_dict(v) for v in visual_data]
    s_dicts = [_to_dict(s) for s in strategies]
    return [{
        "skill_id": skill_id,
        "skill_name": skill_name,
        "content_type": "strategy",
        "content": {"visual": v_dicts, "strategies": s_dicts}
    }]


async def _generate_strategies_core(session_id: str, user_id: str, transcript: list, db: AsyncSession):
    """ç­–ç•¥ç”Ÿæˆæ ¸å¿ƒé€»è¾‘ï¼ˆv0.4 æŠ€èƒ½åŒ–æ¶æ„ï¼‰"""
    from datetime import datetime
    import asyncio
    
    try:
        logger.info(f"========== å¼€å§‹ç”Ÿæˆç­–ç•¥åˆ†æï¼ˆv0.4 æŠ€èƒ½åŒ–æ¶æ„ï¼‰ ==========")
        logger.info(f"session_id: {session_id}")
        
        # 2.1 åœºæ™¯è¯†åˆ«ï¼ˆRouter Agentï¼‰
        logger.info("[ç­–ç•¥æµç¨‹] æ­¥éª¤2.1: åœºæ™¯è¯†åˆ«(Gemini classify_scene)...")
        model = genai.GenerativeModel(GEMINI_FLASH_MODEL)
        scene_result = classify_scene(transcript, model)
        primary_scene = scene_result.get("primary_scene", "other")
        scenes = scene_result.get("scenes", [])
        logger.info(f"[ç­–ç•¥æµç¨‹] æ­¥éª¤2.1: å®Œæˆ primary_scene={primary_scene}")
        for scene in scenes:
            logger.info(f"  - {scene.get('category')}: {scene.get('confidence', 0):.2f}")
        
        # 2.2 æŠ€èƒ½åŒ¹é…ï¼ˆè‹¥æ­¤å¤„æŠ¥ PG type 114ï¼Œå¯èƒ½æ˜¯ skills è¡¨ meta_data åˆ—ä¸º jsonï¼‰
        logger.info("[ç­–ç•¥æµç¨‹] æ­¥éª¤2.2: æŠ€èƒ½åŒ¹é…(match_skills/æŸ¥ skills è¡¨)...")
        matched_skills = await match_skills(scene_result, db, transcript=transcript)
        logger.info(f"[ç­–ç•¥æµç¨‹] æ­¥éª¤2.2: å®Œæˆ åŒ¹é…åˆ° {len(matched_skills)} ä¸ªæŠ€èƒ½")
        
        if not matched_skills:
            logger.warning("æœªåŒ¹é…åˆ°ä»»ä½•æŠ€èƒ½ï¼Œä½¿ç”¨é»˜è®¤æŠ€èƒ½")
            # ä½¿ç”¨ workplace_jungle ä½œä¸ºé»˜è®¤æŠ€èƒ½
            default_skill = await get_skill("workplace_jungle", db)
            if default_skill:
                matched_skills = [{
                    "skill_id": "workplace_jungle",
                    "name": default_skill["name"],
                    "category": default_skill["category"],
                    "priority": default_skill["priority"],
                    "confidence": 0.5
                }]
            else:
                raise Exception("æœªåŒ¹é…åˆ°æŠ€èƒ½ä¸”é»˜è®¤æŠ€èƒ½ä¸å­˜åœ¨")
        
        for skill in matched_skills:
            logger.info(f"  âœ… æŠ€èƒ½: {skill['skill_id']} (åç§°: {skill.get('name', 'N/A')}, priority={skill['priority']}, confidence={skill['confidence']:.2f})")
        
        # 2.2b v0.6 è®°å¿†æ£€ç´¢ï¼šä¸ºæŠ€èƒ½æ³¨å…¥ç›¸å…³è®°å¿†
        memory_context = ""
        try:
            logger.info(f"[è®°å¿†] å¼€å§‹æ£€ç´¢: session_id={session_id} user_id={user_id}")
            ar_query = await db.execute(
                select(AnalysisResult).where(AnalysisResult.session_id == uuid.UUID(session_id))
            )
            ar_row = ar_query.scalar_one_or_none()
            if ar_row:
                search_query = getattr(ar_row, "conversation_summary", None) or ar_row.summary or ""
                if not search_query and transcript:
                    search_query = " ".join((t.get("text", "") or "")[:100] for t in transcript[:5])
                logger.info(f"[è®°å¿†] æ£€ç´¢ query æ¥æº: conversation_summary={bool(getattr(ar_row, 'conversation_summary', None))} summary={bool(ar_row.summary)} search_query_len={len(search_query)}")
                if search_query:
                    from services.memory_service import search_memory
                    mem_results = await asyncio.to_thread(
                        search_memory, search_query, user_id, limit=5
                    )
                    if mem_results:
                        memory_context = "\n".join(f"- {m}" for m in mem_results)
                        logger.info(f"[è®°å¿†] æ£€ç´¢æˆåŠŸæ³¨å…¥æŠ€èƒ½: session_id={session_id} å‘½ä¸­={len(mem_results)} æ¡ context_len={len(memory_context)}")
                    else:
                        logger.info(f"[è®°å¿†] æ£€ç´¢æ— å‘½ä¸­: session_id={session_id}")
                else:
                    logger.info(f"[è®°å¿†] æ£€ç´¢è·³è¿‡: search_query ä¸ºç©º session_id={session_id}")
            else:
                logger.info(f"[è®°å¿†] æ£€ç´¢è·³è¿‡: æ—  AnalysisResult session_id={session_id}")
        except Exception as mem_err:
            logger.warning(f"[è®°å¿†] æ£€ç´¢å¤±è´¥: session_id={session_id} error={mem_err}", exc_info=True)
        context = {
            "session_id": session_id,
            "user_id": user_id,
            "memory_context": memory_context or "",
        }
        
        # 2.3 æŠ€èƒ½æ‰§è¡Œï¼štranscript + æŠ€èƒ½ prompt -> Gemini -> ç­–ç•¥ä¸è§†è§‰æè¿°
        logger.info("[ç­–ç•¥æµç¨‹] æ­¥éª¤2.3: æŠ€èƒ½æ‰§è¡Œ(transcript+æŠ€èƒ½prompt->Gemini)...")
        skill_results = []
        
        # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰æŠ€èƒ½
        execution_tasks = []
        for matched_skill in matched_skills:
            skill_id = matched_skill["skill_id"]
            try:
                # è·å–å®Œæ•´æŠ€èƒ½ä¿¡æ¯ï¼ˆåŒ…å« prompt_templateï¼‰
                skill = await get_skill(skill_id, db)
                if not skill:
                    logger.warning(f"æŠ€èƒ½ä¸å­˜åœ¨: {skill_id}")
                    continue
                
                # æ·»åŠ åŒ¹é…ä¿¡æ¯åˆ°æŠ€èƒ½æ•°æ®
                skill["priority"] = matched_skill["priority"]
                skill["confidence"] = matched_skill["confidence"]
                
                # åˆ›å»ºæ‰§è¡Œä»»åŠ¡
                task = execute_skill(skill, transcript, context, model)
                execution_tasks.append((skill_id, task))
            except Exception as e:
                logger.error(f"å‡†å¤‡æ‰§è¡ŒæŠ€èƒ½å¤±è´¥: {skill_id}, é”™è¯¯: {e}")
                skill_results.append({
                    "skill_id": skill_id,
                    "result": None,
                    "execution_time_ms": 0,
                    "success": False,
                    "error_message": str(e),
                    "priority": matched_skill.get("priority", 0),
                    "confidence": matched_skill.get("confidence", 0.5)
                })
        
        # æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        for skill_id, task in execution_tasks:
            try:
                result = await task
                skill_results.append(result)
            except Exception as e:
                logger.error(f"æ‰§è¡ŒæŠ€èƒ½å¤±è´¥: {skill_id}, é”™è¯¯: {e}")
                skill_results.append({
                    "skill_id": skill_id,
                    "result": None,
                    "execution_time_ms": 0,
                    "success": False,
                    "error_message": str(e),
                    "priority": 0,
                    "confidence": 0.5
                })
        
        # è®°å½•æŠ€èƒ½æ‰§è¡Œåˆ°æ•°æ®åº“
        for skill_result in skill_results:
            try:
                skill_execution = SkillExecution(
                    session_id=uuid.UUID(session_id),
                    skill_id=skill_result["skill_id"],
                    scene_category=primary_scene,
                    confidence_score=skill_result.get("confidence", 0.5),
                    execution_time_ms=skill_result.get("execution_time_ms", 0),
                    success=skill_result.get("success", False),
                    error_message=skill_result.get("error_message")
                )
                db.add(skill_execution)
            except Exception as e:
                logger.error(f"è®°å½•æŠ€èƒ½æ‰§è¡Œå¤±è´¥: {skill_result['skill_id']}, é”™è¯¯: {e}")
        
        await db.commit()
        
        # 4. æ„å»º skill_cardsï¼ˆæ¯ä¸ªæŠ€èƒ½ä¸€å¼ å¡ç‰‡ï¼Œä¸å†ç”¨ compose_results åˆå¹¶ï¼‰
        logger.info("[ç­–ç•¥æµç¨‹] æ­¥éª¤2.3a: æ„å»º skill_cards...")
        skill_cards = []
        all_visuals_for_compat = []  # ç”¨äºå…¼å®¹ visual_data
        all_strategies_for_compat = []  # ç”¨äºå…¼å®¹ strategies
        global_image_index = 0
        reference_images = await _get_profile_reference_images(session_id, user_id, db)
        
        for skill_result in skill_results:
            skill_id = skill_result.get("skill_id", "unknown")
            skill_name = skill_result.get("name", skill_id)
            if not skill_result.get("success"):
                continue
            # æƒ…ç»ªæŠ€èƒ½
            if skill_result.get("emotion_insight") is not None:
                emotion_insight = skill_result["emotion_insight"]
                skill_cards.append({
                    "skill_id": skill_id,
                    "skill_name": skill_name,
                    "content_type": "emotion",
                    "content": {
                        "sigh_count": emotion_insight.get("sigh_count", 0),
                        "haha_count": emotion_insight.get("haha_count", 0),
                        "mood_state": emotion_insight.get("mood_state", "å¹³å¸¸å¿ƒ"),
                        "mood_emoji": emotion_insight.get("mood_emoji", "ğŸ˜"),
                        "char_count": emotion_insight.get("char_count", 0),
                    }
                })
                logger.info(f"  âœ… æƒ…ç»ªå¡: {skill_id} mood={emotion_insight.get('mood_state')} sigh={emotion_insight.get('sigh_count')} haha={emotion_insight.get('haha_count')}")
                continue
            # ç­–ç•¥æŠ€èƒ½
            result = skill_result.get("result")
            if result and hasattr(result, "visual") and hasattr(result, "strategies"):
                # ä¸ºç­–ç•¥æŠ€èƒ½çš„ visual ç”Ÿæˆå›¾ç‰‡
                updated_visual_list = []
                for v in result.visual:
                    try:
                        image_result = generate_image_from_prompt(
                            v.image_prompt,
                            user_id,
                            session_id,
                            global_image_index,
                            reference_images=reference_images if reference_images else None,
                        )
                        if image_result:
                            if image_result.startswith('http://') or image_result.startswith('https://'):
                                updated_visual = v.model_copy(update={"image_url": image_result})
                            else:
                                updated_visual = v.model_copy(update={"image_base64": image_result})
                            updated_visual_list.append(updated_visual)
                        else:
                            updated_visual_list.append(v)
                    except Exception as e:
                        logger.error(f"ç”Ÿæˆå›¾ç‰‡å¤±è´¥ {skill_id} idx={global_image_index}: {e}")
                        updated_visual_list.append(v)
                    global_image_index += 1
                card_content = {
                    "visual": [v.dict() for v in updated_visual_list],
                    "strategies": [s.dict() for s in result.strategies]
                }
                skill_cards.append({
                    "skill_id": skill_id,
                    "skill_name": skill_name,
                    "content_type": "strategy",
                    "content": card_content
                })
                all_visuals_for_compat.extend(updated_visual_list)
                all_strategies_for_compat.extend(result.strategies)
                logger.info(f"  âœ… ç­–ç•¥å¡: {skill_id} visual={len(updated_visual_list)} strategies={len(result.strategies)}")
        
        # å…¼å®¹ï¼šä» skill_cards åæ¨ call2_resultï¼ˆé¦–å¼ ç­–ç•¥å¡æˆ–åˆå¹¶ï¼‰
        if all_visuals_for_compat or all_strategies_for_compat:
            all_visuals_for_compat.sort(key=lambda x: x.transcript_index)
            if len(all_visuals_for_compat) > 5:
                all_visuals_for_compat = all_visuals_for_compat[:5]
            call2_result = Call2Response(visual=all_visuals_for_compat, strategies=all_strategies_for_compat)
        else:
            call2_result = Call2Response(visual=[], strategies=[])
        logger.info(f"[ç­–ç•¥æµç¨‹] æ­¥éª¤2.3a: å®Œæˆ skill_cards={len(skill_cards)} å…¼å®¹visual={len(call2_result.visual)} å…¼å®¹strategies={len(call2_result.strategies)}")
        
        # v0.6 è®°å¿†è¡¥å……ï¼ˆC é’©å­ï¼‰ï¼šç­–ç•¥æ–‡æœ¬å†™å…¥ Mem0
        if call2_result.strategies:
            logger.info(f"[è®°å¿†] C é’©å­è§¦å‘: session_id={session_id} ç­–ç•¥æ•°={len(call2_result.strategies)}")
            try:
                from services.memory_service import add_memory
                strategy_text = "\n\n".join(
                    f"[{s.title}] {s.content}" for s in call2_result.strategies
                )
                ar_q = await db.execute(
                    select(AnalysisResult).where(AnalysisResult.session_id == uuid.UUID(session_id))
                )
                ar = ar_q.scalar_one_or_none()
                profile_ids = []
                if ar and isinstance(getattr(ar, "speaker_mapping", None), dict):
                    profile_ids = list(ar.speaker_mapping.values())
                skill_ids = [s["skill_id"] for s in skill_results if s.get("success")]
                metadata = {"session_id": session_id, "profile_ids": profile_ids}
                if skill_ids:
                    metadata["skill_ids"] = skill_ids
                logger.info(f"[è®°å¿†] C é’©å­è°ƒç”¨ add_memory: session_id={session_id} strategy_text_len={len(strategy_text)} metadata={metadata}")
                ok = await asyncio.to_thread(
                    add_memory, strategy_text, user_id, metadata=metadata, enable_graph=True
                )
                logger.info(f"[è®°å¿†] C é’©å­ add_memory ç»“æœ: session_id={session_id} success={ok}")
            except Exception as mem_err:
                logger.warning(f"[è®°å¿†] C é’©å­å†™å…¥å¤±è´¥: session_id={session_id} error={mem_err}", exc_info=True)
        else:
            logger.info(f"[è®°å¿†] C é’©å­è·³è¿‡: session_id={session_id} strategies ä¸ºç©º")
        
        # 6. ä¿å­˜ç­–ç•¥åˆ†æåˆ°æ•°æ®åº“ï¼ˆè‹¥æ­¤å¤„æˆ– commit åæŠ¥ PG type 114ï¼Œè¯´æ˜ strategy_analysis è¡¨åˆ—ä¸º json æœªæ”¹ä¸º jsonbï¼‰
        logger.info("[ç­–ç•¥æµç¨‹] æ­¥éª¤2.4: å†™å…¥ç­–ç•¥åˆ†æåˆ°æ•°æ®åº“(StrategyAnalysis)...")
        
        # æ„å»º applied_skills åˆ—è¡¨
        applied_skills = [
            {
                "skill_id": skill_result["skill_id"],
                "priority": skill_result.get("priority", 0),
                "confidence": skill_result.get("confidence", 0.5)
            }
            for skill_result in skill_results
            if skill_result.get("success", False)
        ]
        
        # è·å–ä¸»è¦åœºæ™¯çš„ç½®ä¿¡åº¦ï¼ˆå­˜å‚¨ä¸º floatï¼Œä¸æ˜¯ JSONBï¼‰
        primary_scene_confidence = None
        for scene in scenes:
            if scene.get("category") == primary_scene:
                primary_scene_confidence = scene.get("confidence", 0.5)
                break
        if primary_scene_confidence is None:
            primary_scene_confidence = 0.5
        
        strategy_analysis = StrategyAnalysis(
            session_id=uuid.UUID(session_id),
            visual_data=[v.dict() for v in call2_result.visual],
            strategies=[s.dict() for s in call2_result.strategies],
            applied_skills=applied_skills,
            scene_category=primary_scene,
            scene_confidence=primary_scene_confidence,
            skill_cards=skill_cards
        )
        
        # å¦‚æœå·²å­˜åœ¨åˆ™æ›´æ–°ï¼Œå¦åˆ™åˆ›å»º
        existing_query = await db.execute(
            select(StrategyAnalysis).where(StrategyAnalysis.session_id == uuid.UUID(session_id))
        )
        existing = existing_query.scalar_one_or_none()
        if existing:
            existing.visual_data = [v.dict() for v in call2_result.visual]
            existing.strategies = [s.dict() for s in call2_result.strategies]
            existing.applied_skills = applied_skills
            existing.scene_category = primary_scene
            existing.scene_confidence = primary_scene_confidence
            existing.skill_cards = skill_cards
            await db.commit()
            logger.info(f"[ç­–ç•¥æµç¨‹] æ­¥éª¤2.4: å·²æ›´æ–°åˆ°æ•°æ®åº“: {session_id}")
        else:
            db.add(strategy_analysis)
            await db.commit()
            logger.info(f"[ç­–ç•¥æµç¨‹] æ­¥éª¤2.4: å·²ä¿å­˜åˆ°æ•°æ®åº“: {session_id}")
        
        # å­˜å‚¨ç­–ç•¥ç»“æœåˆ°å†…å­˜ï¼ˆå‘åå…¼å®¹ï¼‰
        if session_id not in analysis_storage:
            analysis_storage[session_id] = {}
        if "call2" not in analysis_storage[session_id]:
            analysis_storage[session_id]["call2"] = {}
        analysis_storage[session_id]["call2"] = call2_result.dict()
        
        logger.info(f"ç­–ç•¥åˆ†æç”ŸæˆæˆåŠŸï¼ˆv0.4 æŠ€èƒ½åŒ–æ¶æ„ï¼‰")
        logger.info(f"  - åœºæ™¯ç±»åˆ«: {primary_scene} (ç½®ä¿¡åº¦: {primary_scene_confidence:.2f})")
        logger.info(f"  - åº”ç”¨æŠ€èƒ½: {len(applied_skills)} ä¸ª")
        for skill in applied_skills:
            skill_id = skill['skill_id']
            # ä»æŠ€èƒ½ç»“æœä¸­è·å–åç§°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä»æ•°æ®åº“æŸ¥è¯¢
            skill_name = skill.get('name', 'N/A')
            if skill_name == 'N/A':
                try:
                    skill_info = await get_skill(skill_id, db)
                    skill_name = skill_info.get('name', skill_id) if skill_info else skill_id
                except:
                    skill_name = skill_id
            logger.info(f"    âœ… æŠ€èƒ½: {skill_id} (åç§°: {skill_name}, priority={skill['priority']}, confidence={skill['confidence']:.2f})")
        logger.info(f"  - å…³é”®æ—¶åˆ»æ•°é‡: {len(call2_result.visual)}")
        logger.info(f"  - ç­–ç•¥æ•°é‡: {len(call2_result.strategies)}")
        
        return call2_result
        
    except Exception as e:
        logger.error(f"ç”Ÿæˆç­–ç•¥å¤±è´¥: {e}")
        logger.error(traceback.format_exc())
        raise


@app.post("/api/v1/tasks/sessions/{session_id}/classify-scene")
async def classify_scene_endpoint(
    session_id: str,
    user_id: str = Depends(get_current_user_id),
    db: AsyncSession = Depends(get_db)
):
    """åœºæ™¯è¯†åˆ«æ¥å£ï¼ˆä»…è¿›è¡Œåœºæ™¯è¯†åˆ«ï¼Œä¸ç”Ÿæˆç­–ç•¥ï¼‰"""
    from datetime import datetime
    
    try:
        # éªŒè¯ä»»åŠ¡å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
        result = await db.execute(
            select(Session).where(
                Session.id == uuid.UUID(session_id),
                Session.user_id == uuid.UUID(user_id)
            )
        )
        db_session = result.scalar_one_or_none()
        
        if not db_session:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
        
        # ä»æ•°æ®åº“æŸ¥è¯¢åˆ†æç»“æœ
        analysis_result_query = await db.execute(
            select(AnalysisResult).where(AnalysisResult.session_id == uuid.UUID(session_id))
        )
        analysis_result_db = analysis_result_query.scalar_one_or_none()
        
        if not analysis_result_db:
            raise HTTPException(status_code=400, detail="åˆ†æç»“æœä¸å­˜åœ¨ï¼Œè¯·å…ˆå®ŒæˆéŸ³é¢‘åˆ†æ")
        
        # è·å–transcript
        transcript = []
        if analysis_result_db.transcript:
            try:
                transcript = json.loads(analysis_result_db.transcript) if isinstance(analysis_result_db.transcript, str) else analysis_result_db.transcript
            except:
                transcript = []
        
        if not transcript:
            raise HTTPException(status_code=400, detail="å¯¹è¯è½¬å½•æ•°æ®ä¸å­˜åœ¨ï¼Œè¯·å…ˆå®ŒæˆéŸ³é¢‘åˆ†æ")
        
        # åœºæ™¯è¯†åˆ«
        model = genai.GenerativeModel(GEMINI_FLASH_MODEL)
        scene_result = classify_scene(transcript, model)
        
        # æŠ€èƒ½åŒ¹é…ï¼ˆä¼ å…¥ transcript ç”¨äºå‚ä¸è€…å…³é”®è¯è¡¥å……ï¼‰
        matched_skills = await match_skills(scene_result, db, transcript=transcript)
        
        return APIResponse(
            code=200,
            message="success",
            data={
                "scenes": scene_result.get("scenes", []),
                "primary_scene": scene_result.get("primary_scene", "other"),
                "matched_skills": [
                    {
                        "skill_id": skill["skill_id"],
                        "name": skill["name"],
                        "priority": skill["priority"]
                    }
                    for skill in matched_skills
                ]
            },
            timestamp=datetime.now().isoformat()
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"åœºæ™¯è¯†åˆ«å¤±è´¥: {e}")
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"åœºæ™¯è¯†åˆ«å¤±è´¥: {str(e)}")


@app.post("/api/v1/tasks/sessions/{session_id}/strategies")
async def generate_strategies(
    session_id: str,
    force_regenerate: bool = Query(False, description="å¼ºåˆ¶é‡æ–°ç”Ÿæˆï¼ˆç”¨äºæ›´æ–°ä¸ºæœ€æ–°é£æ ¼å¦‚å®«å´éªï¼‰"),
    user_id: str = Depends(get_current_user_id),
    db: AsyncSession = Depends(get_db)
):
    """ç”Ÿæˆç­–ç•¥åˆ†æï¼ˆCall #2ï¼‰- æƒ…å•†æ•™ç»ƒï¼ˆv0.4 æŠ€èƒ½åŒ–æ¶æ„ï¼Œéœ€è¦JWTè®¤è¯ï¼Œä»…èƒ½è®¿é—®è‡ªå·±çš„ä»»åŠ¡ï¼‰ã€‚force_regenerate=true æ—¶åˆ é™¤æ—§æ•°æ®å¹¶é‡æ–°ç”Ÿæˆã€‚"""
    from datetime import datetime
    
    try:
        logger.info(f"[ç­–ç•¥æµç¨‹] session_id={session_id} å¼€å§‹")
        # éªŒè¯ä»»åŠ¡å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
        result = await db.execute(
            select(Session).where(
                Session.id == uuid.UUID(session_id),
                Session.user_id == uuid.UUID(user_id)
            )
        )
        db_session = result.scalar_one_or_none()
        
        if not db_session:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
        
        # æ­¥éª¤0ï¼šä¼˜å…ˆä»æ•°æ®åº“è¯»å–å·²ç”Ÿæˆçš„ç­–ç•¥åˆ†æï¼ˆè‹¥æ­¤å¤„æŠ¥ PG type 114ï¼Œè¯´æ˜ strategy_analysis è¡¨åˆ—ä¸º json æœªæ”¹ä¸º jsonbï¼‰
        logger.info(f"[ç­–ç•¥æµç¨‹] æ­¥éª¤0: è¯»å–å·²æœ‰ç­–ç•¥åˆ†æ(StrategyAnalysis)...")
        strategy_query = await db.execute(
            select(StrategyAnalysis).where(StrategyAnalysis.session_id == uuid.UUID(session_id))
        )
        existing_strategy = strategy_query.scalar_one_or_none()
        logger.info(f"[ç­–ç•¥æµç¨‹] æ­¥éª¤0: å®Œæˆ existing={existing_strategy is not None} force_regenerate={force_regenerate}")
        
        if force_regenerate and existing_strategy:
            from sqlalchemy import delete
            await db.execute(delete(StrategyAnalysis).where(StrategyAnalysis.session_id == uuid.UUID(session_id)))
            await db.commit()
            logger.info(f"[ç­–ç•¥æµç¨‹] å·²åˆ é™¤æ—§ç­–ç•¥åˆ†æï¼Œå°†é‡æ–°ç”Ÿæˆ: {session_id}")
            existing_strategy = None
        
        if existing_strategy:
            logger.info(f"ä»æ•°æ®åº“è¯»å–å·²ç”Ÿæˆçš„ç­–ç•¥åˆ†æ: {session_id}")
            # æ„å»ºè¿”å›æ•°æ®ï¼ˆå…¼å®¹ visual_data/strategies ä¸ºç©ºæˆ–ä»… emotion å¡ï¼‰
            visual_list = []
            for idx, v in enumerate(existing_strategy.visual_data or []):
                vdict = v if isinstance(v, dict) else (v.__dict__ if hasattr(v, '__dict__') else {})
                has_url = bool(vdict.get("image_url"))
                has_b64 = bool(vdict.get("image_base64"))
                b64_len = len(vdict.get("image_base64") or "")
                logger.info(f"[ç­–ç•¥-å›¾ç‰‡] session_id={session_id} visual[{idx}] image_url={has_url} image_base64={bool(has_b64)} b64_len={b64_len}")
                visual_list.append(VisualData(**vdict))
            
            strategies_list = []
            for s in (existing_strategy.strategies or []):
                sdict = s if isinstance(s, dict) else (s.__dict__ if hasattr(s, '__dict__') else {})
                strategies_list.append(StrategyItem(**sdict))
            
            call2_result = Call2Response(
                visual=visual_list,
                strategies=strategies_list
            )
            
            # æ·»åŠ æŠ€èƒ½ä¿¡æ¯
            result_dict = call2_result.dict()
            applied_skills = existing_strategy.applied_skills or []
            scene_category = existing_strategy.scene_category
            scene_confidence = existing_strategy.scene_confidence
            # ä¼˜å…ˆä½¿ç”¨ skill_cardsï¼Œæ— åˆ™ä» visual_data+strategies æ„é€ å…¼å®¹ç»“æ„
            skill_cards_raw = getattr(existing_strategy, "skill_cards", None) or []
            if skill_cards_raw:
                result_dict["skill_cards"] = skill_cards_raw
            else:
                result_dict["skill_cards"] = _build_legacy_skill_cards(
                    existing_strategy.visual_data or [],
                    existing_strategy.strategies or [],
                    applied_skills
                )
            
            logger.info(f"æŠ€èƒ½ä¿¡æ¯: applied_skills={applied_skills}, scene_category={scene_category}, scene_confidence={scene_confidence}")
            # æ—¥å¿—ï¼šè¿”å›ç»™å‰ç«¯çš„ visual ä¸­æ¯ä¸ªçš„ image_url / image_base64 æƒ…å†µ
            for idx, v in enumerate(result_dict.get("visual", [])):
                vd = v if isinstance(v, dict) else (getattr(v, "__dict__", {}) or {})
                url_present = bool(vd.get("image_url"))
                b64_present = bool(vd.get("image_base64"))
                logger.info(f"[ç­–ç•¥è¿”å›] session_id={session_id} visual[{idx}] è¿”å›image_url={url_present} image_base64={b64_present}")
            
            result_dict["applied_skills"] = applied_skills
            result_dict["scene_category"] = scene_category
            result_dict["scene_confidence"] = scene_confidence
            
            return APIResponse(
                code=200,
                message="success",
                data=result_dict,
                timestamp=datetime.now().isoformat()
            )
        
        # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰ï¼Œåˆ™ç”Ÿæˆæ–°çš„ç­–ç•¥åˆ†æ
        logger.info(f"[ç­–ç•¥æµç¨‹] æ•°æ®åº“ä¸­æ²¡æœ‰ç­–ç•¥åˆ†æï¼Œå¼€å§‹ç”Ÿæˆ: {session_id}")
        
        # æ­¥éª¤1ï¼šä»æ•°æ®åº“æŸ¥è¯¢åˆ†æç»“æœå– transcriptï¼ˆè‹¥æ­¤å¤„æŠ¥ PG type 114ï¼Œè¯´æ˜ analysis_results è¡¨åˆ—ä¸º json æœªæ”¹ä¸º jsonbï¼‰
        logger.info(f"[ç­–ç•¥æµç¨‹] æ­¥éª¤1: è¯»å–åˆ†æç»“æœ(AnalysisResult/transcript)...")
        analysis_result_query = await db.execute(
            select(AnalysisResult).where(AnalysisResult.session_id == uuid.UUID(session_id))
        )
        analysis_result_db = analysis_result_query.scalar_one_or_none()
        logger.info(f"[ç­–ç•¥æµç¨‹] æ­¥éª¤1: å®Œæˆ analysis_result_db={analysis_result_db is not None}")
        
        if not analysis_result_db:
            raise HTTPException(status_code=400, detail="åˆ†æç»“æœä¸å­˜åœ¨ï¼Œè¯·å…ˆå®ŒæˆéŸ³é¢‘åˆ†æ")
        
        # è·å–transcript
        transcript = []
        if analysis_result_db.transcript:
            try:
                transcript = json.loads(analysis_result_db.transcript) if isinstance(analysis_result_db.transcript, str) else analysis_result_db.transcript
            except:
                transcript = []
        
        # å‘åå…¼å®¹ï¼šä»å†…å­˜å­˜å‚¨è·å–ï¼ˆå¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰ï¼‰
        analysis_result = analysis_storage.get(session_id, {})
        if not transcript and analysis_result:
            transcript = analysis_result.get("transcript", [])
        
        if not transcript:
            raise HTTPException(status_code=400, detail="å¯¹è¯è½¬å½•æ•°æ®ä¸å­˜åœ¨ï¼Œè¯·å…ˆå®ŒæˆéŸ³é¢‘åˆ†æ")
        
        # æ­¥éª¤2ï¼šæ ¸å¿ƒç”Ÿæˆï¼ˆæ­¥éª¤2.1 åœºæ™¯è¯†åˆ« -> 2.2 æŠ€èƒ½åŒ¹é… -> 2.3 transcript+æŠ€èƒ½ prompt -> Geminiï¼‰
        logger.info(f"[ç­–ç•¥æµç¨‹] æ­¥éª¤2: è°ƒç”¨ _generate_strategies_core(åœºæ™¯è¯†åˆ«->æŠ€èƒ½åŒ¹é…->Geminiç­–ç•¥)...")
        call2_result = await _generate_strategies_core(session_id, user_id, transcript, db)
        logger.info(f"[ç­–ç•¥æµç¨‹] æ­¥éª¤2: _generate_strategies_core è¿”å›æˆåŠŸ")
        
        # æ­¥éª¤3ï¼šä»æ•°æ®åº“è¯»å–åˆšå†™å…¥çš„ç­–ç•¥ä»¥å–æŠ€èƒ½ä¿¡æ¯ï¼ˆè‹¥æ­¤å¤„æŠ¥ PG type 114ï¼Œè¯´æ˜ strategy_analysis è¡¨åˆ—ä¸º json æœªæ”¹ä¸º jsonbï¼‰
        logger.info(f"[ç­–ç•¥æµç¨‹] æ­¥éª¤3: è¯»å–åˆšå†™å…¥çš„ç­–ç•¥åˆ†æ(æŠ€èƒ½ä¿¡æ¯)...")
        strategy_query_after = await db.execute(
            select(StrategyAnalysis).where(StrategyAnalysis.session_id == uuid.UUID(session_id))
        )
        strategy_after = strategy_query_after.scalar_one_or_none()
        
        # æ·»åŠ æŠ€èƒ½ä¿¡æ¯åˆ°è¿”å›æ•°æ®
        result_dict = call2_result.dict()
        if strategy_after:
            applied_skills = strategy_after.applied_skills or []
            scene_category = strategy_after.scene_category
            scene_confidence = strategy_after.scene_confidence
            # ä¼˜å…ˆä½¿ç”¨ skill_cards
            skill_cards_raw = getattr(strategy_after, "skill_cards", None) or []
            if skill_cards_raw:
                result_dict["skill_cards"] = skill_cards_raw
            else:
                result_dict["skill_cards"] = _build_legacy_skill_cards(
                    strategy_after.visual_data or [],
                    strategy_after.strategies or [],
                    applied_skills
                )
            
            logger.info(f"æŠ€èƒ½ä¿¡æ¯: applied_skills={applied_skills}, scene_category={scene_category}, scene_confidence={scene_confidence}")
            
            result_dict["applied_skills"] = applied_skills
            result_dict["scene_category"] = scene_category
            result_dict["scene_confidence"] = scene_confidence
        else:
            logger.warning(f"æœªæ‰¾åˆ°ç­–ç•¥åˆ†ææ•°æ®ï¼Œæ— æ³•è¿”å›æŠ€èƒ½ä¿¡æ¯: {session_id}")
            result_dict["applied_skills"] = []
            result_dict["scene_category"] = None
            result_dict["scene_confidence"] = None
            result_dict["skill_cards"] = []
        
        return APIResponse(
            code=200,
            message="success",
            data=result_dict,
            timestamp=datetime.now().isoformat()
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ç”Ÿæˆç­–ç•¥å¤±è´¥: {e}")
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"ç”Ÿæˆç­–ç•¥å¤±è´¥: {str(e)}")


@app.get("/api/v1/tasks/emotion-trend")
async def get_emotion_trend(
    user_id: str = Depends(get_current_user_id),
    db: AsyncSession = Depends(get_db),
    limit: int = Query(30, ge=1, le=100)
):
    """
    è·å–å¿ƒæƒ…è¶‹åŠ¿ï¼šä»å„ session çš„ skill_cards ä¸­æå– content_type=emotion çš„æ•°æ®ï¼ŒæŒ‰æ—¶é—´æ’åºã€‚
    """
    try:
        sa_result = await db.execute(
            select(StrategyAnalysis, Session.created_at)
            .join(Session, StrategyAnalysis.session_id == Session.id)
            .where(Session.user_id == uuid.UUID(user_id))
            .order_by(Session.created_at.desc())
            .limit(limit * 3)
        )
        rows = sa_result.all()
        points = []
        for sa, created_at in rows:
            skill_cards = getattr(sa, "skill_cards", None) or []
            for card in skill_cards:
                if isinstance(card, dict) and card.get("content_type") == "emotion":
                    content = card.get("content") or {}
                    points.append({
                        "session_id": str(sa.session_id),
                        "created_at": created_at.isoformat() if created_at else None,
                        "mood_state": content.get("mood_state", "å¹³å¸¸å¿ƒ"),
                        "mood_emoji": content.get("mood_emoji", "ğŸ˜"),
                        "sigh_count": content.get("sigh_count", 0),
                        "haha_count": content.get("haha_count", 0),
                        "char_count": content.get("char_count", 0),
                    })
                    break
            if len(points) >= limit:
                break
        return APIResponse(
            code=200,
            message="success",
            data={"points": points[:limit]},
            timestamp=datetime.now().isoformat()
        )
    except Exception as e:
        logger.error(f"è·å–å¿ƒæƒ…è¶‹åŠ¿å¤±è´¥: {e}")
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"è·å–å¿ƒæƒ…è¶‹åŠ¿å¤±è´¥: {str(e)}")


@app.get("/api/v1/images/{session_id}/{image_index}")
async def get_image(
    session_id: str,
    image_index: int,
    user_id: str = Depends(get_current_user_id),
    db: AsyncSession = Depends(get_db)
):
    """
    è·å–å›¾ç‰‡ï¼ˆé€šè¿‡åç«¯ API è®¿é—®ï¼Œæ”¯æŒç§æœ‰ OSS bucketï¼Œéœ€è¦JWTè®¤è¯ï¼‰
    
    æ³¨æ„ï¼šç”±äº OSS bucket è®¾ç½®ä¸ºç§æœ‰ï¼Œä¸èƒ½ç›´æ¥é€šè¿‡ OSS URL è®¿é—®å›¾ç‰‡ã€‚
    å¿…é¡»é€šè¿‡æ­¤ API æ¥å£è®¿é—®ï¼Œåç«¯ä¼šä» OSS è·å–å›¾ç‰‡å¹¶è¿”å›ã€‚
    ä»…èƒ½è®¿é—®å±äºå½“å‰ç”¨æˆ·çš„å›¾ç‰‡ã€‚
    
    Args:
        session_id: ä¼šè¯ ID
        image_index: å›¾ç‰‡ç´¢å¼•
        
    Returns:
        å›¾ç‰‡æ•°æ®ï¼ˆPNG æ ¼å¼ï¼‰
    """
    try:
        # æ¡£æ¡ˆç…§ç‰‡ï¼šsession_id ä¸º profile_{uuid}ï¼Œæ— éœ€æŸ¥ Session è¡¨
        # ç­–ç•¥å›¾ç‰‡ï¼šsession_id ä¸ºä»»åŠ¡ UUIDï¼Œéœ€éªŒè¯å½’å±
        if session_id.startswith("profile_"):
            # æ¡£æ¡ˆç…§ç‰‡è·¯å¾„ images/{user_id}/profile_xxx/0.pngï¼Œä»…æ ¡éªŒ user_id å½’å±
            pass
        else:
            # ç­–ç•¥å›¾ç‰‡ï¼šéªŒè¯ä»»åŠ¡å±äºå½“å‰ç”¨æˆ·
            result = await db.execute(
                select(Session).where(
                    Session.id == uuid.UUID(session_id),
                    Session.user_id == uuid.UUID(user_id)
                )
            )
            db_session = result.scalar_one_or_none()
            if not db_session:
                raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
        
        # å¦‚æœ OSS æœªå¯ç”¨ï¼Œè¿”å›é”™è¯¯
        if not USE_OSS or oss_bucket is None:
            logger.warning("OSS æœªå¯ç”¨ï¼Œæ— æ³•æä¾›å›¾ç‰‡è®¿é—®")
            raise HTTPException(status_code=503, detail="Image service unavailable")
        
        # æ„å»º OSS æ–‡ä»¶è·¯å¾„: images/{user_id}/{session_id}/{image_index}.png
        oss_key = f"images/{user_id}/{session_id}/{image_index}.png"
        
        logger.info(f"è·å–å›¾ç‰‡: {oss_key}")
        
        try:
            # ä» OSS è·å–å›¾ç‰‡
            start_time = time.time()
            image_object = oss_bucket.get_object(oss_key)
            image_data = image_object.read()
            fetch_time = time.time() - start_time
            
            logger.info(f"âœ… å›¾ç‰‡è·å–æˆåŠŸï¼Œå¤§å°: {len(image_data)} å­—èŠ‚ï¼Œè€—æ—¶: {fetch_time:.2f} ç§’")
            
            media_type = "image/png"
            if len(image_data) >= 2 and image_data[0:2] == b"\xff\xd8":
                media_type = "image/jpeg"
            elif len(image_data) >= 4 and image_data[0:4] == b"\x89PNG":
                media_type = "image/png"
            
            return Response(
                content=image_data,
                media_type=media_type,
                headers={
                    "Cache-Control": "public, max-age=3600",  # ç¼“å­˜ 1 å°æ—¶
                    "Content-Disposition": f'inline; filename="image_{image_index}.png"'
                }
            )
            
        except Exception as e:
            error_msg = str(e)
            if "NoSuchKey" in error_msg or "404" in error_msg:
                logger.warning(f"å›¾ç‰‡ä¸å­˜åœ¨: {oss_key}")
                raise HTTPException(status_code=404, detail="Image not found")
            else:
                logger.error(f"âŒ ä» OSS è·å–å›¾ç‰‡å¤±è´¥: {e}")
                logger.error(traceback.format_exc())
                raise HTTPException(status_code=500, detail="Failed to fetch image")
                
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ è·å–å›¾ç‰‡æ—¶å‡ºé”™: {e}")
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail="Internal server error")


def cleanup_old_images(days: int = 7):
    """
    æ¸…ç†è¿‡æœŸçš„å›¾ç‰‡æ–‡ä»¶
    
    Args:
        days: ä¿ç•™å¤©æ•°ï¼Œé»˜è®¤ 7 å¤©
    """
    if not USE_OSS or oss_bucket is None:
        logger.warning("OSS æœªå¯ç”¨ï¼Œæ— æ³•æ¸…ç†å›¾ç‰‡")
        return
    
    try:
        from datetime import datetime, timedelta
        cutoff_date = datetime.now() - timedelta(days=days)
        
        logger.info(f"å¼€å§‹æ¸…ç† {days} å¤©å‰çš„å›¾ç‰‡æ–‡ä»¶...")
        
        # åˆ—å‡ºæ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
        prefix = "images/"
        deleted_count = 0
        error_count = 0
        
        for obj in oss2.ObjectIterator(oss_bucket, prefix=prefix):
            # æ£€æŸ¥æ–‡ä»¶ä¿®æ”¹æ—¶é—´
            if obj.last_modified < cutoff_date:
                try:
                    oss_bucket.delete_object(obj.key)
                    deleted_count += 1
                    logger.debug(f"åˆ é™¤æ–‡ä»¶: {obj.key}")
                except Exception as e:
                    error_count += 1
                    logger.error(f"åˆ é™¤æ–‡ä»¶å¤±è´¥ {obj.key}: {e}")
        
        logger.info(f"âœ… æ¸…ç†å®Œæˆ: åˆ é™¤ {deleted_count} ä¸ªæ–‡ä»¶ï¼Œå¤±è´¥ {error_count} ä¸ª")
        
    except Exception as e:
        logger.error(f"âŒ æ¸…ç†å›¾ç‰‡æ–‡ä»¶å¤±è´¥: {e}")
        logger.error(traceback.format_exc())


@app.get("/api/v1/admin/cleanup-images")
async def cleanup_images_endpoint(days: int = Query(7, ge=1, le=30)):
    """
    æ¸…ç†è¿‡æœŸå›¾ç‰‡çš„ç®¡ç†æ¥å£
    
    Args:
        days: ä¿ç•™å¤©æ•°ï¼Œé»˜è®¤ 7 å¤©
    """
    try:
        cleanup_old_images(days)
        return {"message": f"æ¸…ç†å®Œæˆï¼Œä¿ç•™æœ€è¿‘ {days} å¤©çš„å›¾ç‰‡", "status": "success"}
    except Exception as e:
        logger.error(f"æ¸…ç†å›¾ç‰‡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ¸…ç†å¤±è´¥: {str(e)}")


@app.get("/test-gemini")
async def test_gemini():
    """æµ‹è¯• Gemini 3 Flash API è¿æ¥"""
    try:
        print("æµ‹è¯• Gemini 3 Flash API è¿æ¥...")
        model_name = GEMINI_FLASH_MODEL
        print(f"ä½¿ç”¨æ¨¡å‹: {model_name}")
        model = genai.GenerativeModel(model_name)
        response = model.generate_content("è¯·å›å¤'è¿æ¥æˆåŠŸ'")
        return {
            "status": "success",
            "message": "Gemini 3 Flash API è¿æ¥æ­£å¸¸",
            "model": model_name,
            "response": response.text
        }
    except Exception as e:
        error_msg = str(e)
        print(f"Gemini 3 Flash è¿æ¥å¤±è´¥: {error_msg}")
        return {
            "status": "error",
            "message": "Gemini 3 Flash API è¿æ¥å¤±è´¥",
            "error": error_msg
        }


if __name__ == "__main__":
    import uvicorn
    # ä¸ Nginx proxy_pass ä¸€è‡´ï¼šæœåŠ¡å™¨ä¸Š Nginx ä»£ç† 80 -> 8000ï¼Œæ­¤å¤„å¿…é¡»ç›‘å¬ 8000
    port = int(os.getenv("UVICORN_PORT", "8000"))
    uvicorn.run(app, host="0.0.0.0", port=port)

