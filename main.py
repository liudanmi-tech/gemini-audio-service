"""
FastAPI éŸ³é¢‘åˆ†æå¾®æœåŠ¡
é€šè¿‡ Google Gemini API åˆ†æä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶
"""

import os
import json
import time
import tempfile
import traceback
import logging
import uuid
import asyncio
from io import BytesIO
from typing import List, Optional, Any, Tuple
from pathlib import Path
from datetime import datetime

import google.generativeai as genai
from google import genai as genai_new  # æ–°çš„ SDK ç”¨äºå›¾ç‰‡ç”Ÿæˆ
from google.genai import types as genai_types
from fastapi import FastAPI, UploadFile, File, HTTPException, Query, Depends
from fastapi.responses import JSONResponse, Response
from pydantic import BaseModel
from dotenv import load_dotenv
import base64

# é…ç½®æ—¥å¿—
# ä½¿ç”¨ç”¨æˆ·ç›®å½•ä¸‹çš„æ—¥å¿—æ–‡ä»¶ï¼Œé¿å…æƒé™é—®é¢˜
log_file_path = os.path.expanduser('~/gemini-audio-service.log')
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler(log_file_path)
    ]
)
logger = logging.getLogger(__name__)

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# åˆå§‹åŒ– FastAPI åº”ç”¨
app = FastAPI(title="éŸ³é¢‘åˆ†ææœåŠ¡", description="é€šè¿‡ Gemini API åˆ†æéŸ³é¢‘æ–‡ä»¶")

# æ³¨å†Œè®¤è¯è·¯ç”±
from api.auth import router as auth_router
app.include_router(auth_router)

# æ³¨å†ŒæŠ€èƒ½ç®¡ç†è·¯ç”±
from api.skills import router as skills_router
app.include_router(skills_router)

# å¯¼å…¥æ•°æ®åº“ç›¸å…³
from database.connection import get_db, init_db, close_db
from database.models import User, Session, AnalysisResult, StrategyAnalysis, Skill, SkillExecution
from auth.jwt_handler import get_current_user_id, get_current_user
from sqlalchemy import select, func
from sqlalchemy.ext.asyncio import AsyncSession

# å¯¼å…¥æŠ€èƒ½æ¨¡å—
from skills.router import classify_scene, match_skills
from skills.registry import get_skill, initialize_skills
from skills.executor import execute_skill
from skills.composer import compose_results

# é…ç½® Gemini API
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
PROXY_URL = os.getenv("PROXY_URL", "http://47.79.254.213/secret-channel")
USE_PROXY = os.getenv("USE_PROXY", "true").lower() == "true"

if not GEMINI_API_KEY:
    raise ValueError("è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® GEMINI_API_KEY")

# é…ç½® Gemini å®¢æˆ·ç«¯ï¼Œä½¿ç”¨åå‘ä»£ç†æœåŠ¡å™¨
logger.info(f"API Key: {GEMINI_API_KEY[:10]}... (å·²éšè—)")
if USE_PROXY and PROXY_URL:
    logger.info(f"åå‘ä»£ç†æ¨¡å¼: å¯ç”¨ï¼Œä»£ç†æœåŠ¡å™¨: {PROXY_URL}")
    
    # å¯¹äºåå‘ä»£ç†ï¼Œéœ€è¦ä¿®æ”¹ API çš„ base URL
    # google-generativeai SDK ä½¿ç”¨ googleapiclient å’Œ httplib2
    try:
        from urllib.parse import urlparse, urljoin
        import googleapiclient.http
        import httplib2
        
        parsed = urlparse(PROXY_URL)
        logger.info(f"ä»£ç†æœåŠ¡å™¨ä¸»æœº: {parsed.hostname}, ç«¯å£: {parsed.port or 80}")
        
        # ä¿å­˜åŸå§‹çš„ execute æ–¹æ³•
        original_execute = googleapiclient.http.HttpRequest.execute
        
        def patched_execute(self, http=None, num_retries=0):
            """ä¿®æ”¹è¯·æ±‚ URLï¼Œå°† Google API çš„ URL æ›¿æ¢ä¸ºä»£ç†æœåŠ¡å™¨ URL"""
            if http is None:
                http = self.http
            
            # è·å–åŸå§‹ URI
            original_uri = self.uri
            
            # å¦‚æœ URI åŒ…å« generativelanguage.googleapis.comï¼Œæ›¿æ¢ä¸ºä»£ç†æœåŠ¡å™¨
            if 'generativelanguage.googleapis.com' in original_uri:
                # æå–è·¯å¾„éƒ¨åˆ†
                from urllib.parse import urlparse, urlunparse
                parsed_uri = urlparse(original_uri)
                
                # æ„å»ºæ–°çš„ URLï¼šä½¿ç”¨ä»£ç†æœåŠ¡å™¨ + /secret-channel + åŸå§‹è·¯å¾„
                # ä¾‹å¦‚ï¼šhttps://generativelanguage.googleapis.com/v1beta/... 
                # -> http://47.79.254.213/secret-channel/v1beta/...
                new_path = f"/secret-channel{parsed_uri.path}"
                
                new_uri = urlunparse((
                    parsed.scheme,  # http
                    f"{parsed.hostname}:{parsed.port or 80}",  # ä»£ç†æœåŠ¡å™¨åœ°å€
                    new_path,  # æ·»åŠ  /secret-channel å‰ç¼€
                    parsed_uri.params,
                    parsed_uri.query,
                    parsed_uri.fragment
                ))
                
                logger.info(f"ä¿®æ”¹è¯·æ±‚ URL: {original_uri} -> {new_uri}")
                self.uri = new_uri
            
            # è°ƒç”¨åŸå§‹æ–¹æ³•
            return original_execute(self, http, num_retries)
        
        # æ›¿æ¢ execute æ–¹æ³•
        googleapiclient.http.HttpRequest.execute = patched_execute
        logger.info("å·² patch googleapiclient.http.HttpRequest.execute ä»¥ä½¿ç”¨åå‘ä»£ç†")
        
    except Exception as e:
        logger.warning(f"é…ç½®åå‘ä»£ç†æ—¶å‡ºé”™: {e}")
        logger.error(traceback.format_exc())
        logger.info("å°†å°è¯•ä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®")
else:
    logger.info("ä»£ç†æ¨¡å¼: ç¦ç”¨ï¼Œç›´æ¥è¿æ¥ Gemini API")

# é…ç½® Gemini API
try:
    # å¦‚æœä½¿ç”¨åå‘ä»£ç†ï¼Œå°è¯•é€šè¿‡ client_options è®¾ç½®
    config_params = {
        'api_key': GEMINI_API_KEY,
        'transport': 'rest'
    }
    
    # å°è¯•è®¾ç½® client_optionsï¼ˆå¦‚æœ SDK æ”¯æŒï¼‰
    if USE_PROXY and PROXY_URL:
        try:
            # æŸäº›ç‰ˆæœ¬å¯èƒ½æ”¯æŒ client_options
            config_params['client_options'] = {
                'api_endpoint': PROXY_URL
            }
            logger.info(f"å°è¯•é€šè¿‡ client_options è®¾ç½® API endpoint: {PROXY_URL}")
        except TypeError:
            logger.info("SDK ä¸æ”¯æŒ client_optionsï¼Œå°†ä½¿ç”¨å…¶ä»–æ–¹æ³•")
    
    genai.configure(**config_params)
    logger.info("Gemini API é…ç½®å®Œæˆï¼ˆä½¿ç”¨ REST ä¼ è¾“æ¨¡å¼ï¼‰")
    
except Exception as e:
    logger.error(f"é…ç½® Gemini API æ—¶å‡ºé”™: {e}")
    raise

# é…ç½®é˜¿é‡Œäº‘ OSS
OSS_ACCESS_KEY_ID = os.getenv("OSS_ACCESS_KEY_ID")
OSS_ACCESS_KEY_SECRET = os.getenv("OSS_ACCESS_KEY_SECRET")
OSS_ENDPOINT = os.getenv("OSS_ENDPOINT")
OSS_BUCKET_NAME = os.getenv("OSS_BUCKET_NAME")
OSS_CDN_DOMAIN = os.getenv("OSS_CDN_DOMAIN")  # å¯é€‰ï¼Œå¦‚æœä½¿ç”¨ CDN
USE_OSS = os.getenv("USE_OSS", "true").lower() == "true"  # æ˜¯å¦å¯ç”¨ OSS

# åˆå§‹åŒ– OSS å®¢æˆ·ç«¯
oss_bucket = None
if USE_OSS:
    if not all([OSS_ACCESS_KEY_ID, OSS_ACCESS_KEY_SECRET, OSS_ENDPOINT, OSS_BUCKET_NAME]):
        logger.warning("âš ï¸ OSS é…ç½®ä¸å®Œæ•´ï¼Œå°†ç¦ç”¨ OSS åŠŸèƒ½")
        logger.warning("éœ€è¦é…ç½®: OSS_ACCESS_KEY_ID, OSS_ACCESS_KEY_SECRET, OSS_ENDPOINT, OSS_BUCKET_NAME")
        USE_OSS = False
    else:
        try:
            import oss2
            auth = oss2.Auth(OSS_ACCESS_KEY_ID, OSS_ACCESS_KEY_SECRET)
            oss_bucket = oss2.Bucket(auth, OSS_ENDPOINT, OSS_BUCKET_NAME)
            logger.info(f"âœ… OSS é…ç½®æˆåŠŸ")
            logger.info(f"OSS Endpoint: {OSS_ENDPOINT}")
            logger.info(f"OSS Bucket: {OSS_BUCKET_NAME}")
            if OSS_CDN_DOMAIN:
                logger.info(f"OSS CDN Domain: {OSS_CDN_DOMAIN}")
        except ImportError:
            logger.error("âŒ æœªå®‰è£… oss2 åº“ï¼Œè¯·è¿è¡Œ: pip install oss2")
            USE_OSS = False
        except Exception as e:
            logger.error(f"âŒ OSS åˆå§‹åŒ–å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            USE_OSS = False
else:
    logger.info("OSS åŠŸèƒ½å·²ç¦ç”¨ï¼ˆUSE_OSS=falseï¼‰")

# å®šä¹‰è¿”å›æ•°æ®æ¨¡å‹
class DialogueItem(BaseModel):
    """å•ä¸ªå¯¹è¯é¡¹çš„æ•°æ®æ¨¡å‹"""
    speaker: str  # è¯´è¯äººæ ‡è¯†ï¼ˆå¦‚ï¼šè¯´è¯äºº1ã€è¯´è¯äººAç­‰ï¼‰
    content: str  # è¯´è¯å†…å®¹
    tone: str  # è¯´è¯è¯­æ°”ï¼ˆå¦‚ï¼šå¹³é™ã€æ„¤æ€’ã€è½»æ¾ã€ç„¦è™‘ç­‰ï¼‰
    timestamp: Optional[str] = None  # æ—¶é—´æˆ³ï¼ˆæ ¼å¼ï¼š"MM:SS"ï¼‰
    is_me: Optional[bool] = False  # æ˜¯å¦æ˜¯æˆ‘è¯´çš„ï¼ˆSpeaker_1ä¸ºtrueï¼‰

class AudioAnalysisResponse(BaseModel):
    """éŸ³é¢‘åˆ†æç»“æœçš„æ•°æ®æ¨¡å‹"""
    speaker_count: int  # è¯´è¯äººæ•°
    dialogues: List[DialogueItem]  # æ‰€æœ‰å¯¹è¯åˆ—è¡¨ï¼ŒæŒ‰æ—¶é—´é¡ºåº
    risks: List[str]  # é£é™©ç‚¹åˆ—è¡¨

# Call #1 æ•°æ®æ¨¡å‹ï¼ˆæ–°çš„åˆ†ææ ¼å¼ï¼‰
class TranscriptItem(BaseModel):
    """è½¬å½•é¡¹æ•°æ®æ¨¡å‹"""
    speaker: str  # è¯´è¯äººæ ‡è¯†
    text: str  # å¯¹è¯å†…å®¹
    timestamp: Optional[str] = None  # æ—¶é—´æˆ³ï¼ˆæ ¼å¼ï¼š"MM:SS"ï¼‰
    is_me: bool  # æ˜¯å¦æ˜¯æˆ‘è¯´çš„

class Call1Response(BaseModel):
    """Call #1 åˆ†æå“åº”"""
    mood_score: int  # æƒ…ç»ªåˆ†æ•° (0-100)
    stats: dict  # ç»Ÿè®¡ä¿¡æ¯ï¼ŒåŒ…å« sigh å’Œ laugh
    summary: str  # å¯¹è¯æ€»ç»“
    transcript: List[TranscriptItem]  # è½¬å½•åˆ—è¡¨

# Call #2 æ•°æ®æ¨¡å‹ï¼ˆç­–ç•¥åˆ†æï¼‰
class StrategyItem(BaseModel):
    """ç­–ç•¥é¡¹æ•°æ®æ¨¡å‹"""
    id: str  # ç­–ç•¥ID
    label: str  # ç­–ç•¥æ ‡ç­¾
    emoji: str  # è¡¨æƒ…ç¬¦å·
    title: str  # ç­–ç•¥æ ‡é¢˜
    content: str  # ç­–ç•¥å†…å®¹ï¼ˆMarkdownæ ¼å¼ï¼‰

class VisualData(BaseModel):
    """è§†è§‰æ•°æ®æ¨¡å‹"""
    transcript_index: int  # å…³è”çš„ transcript ç´¢å¼•
    speaker: str  # è¯´è¯äººæ ‡è¯†
    image_prompt: str  # ç«æŸ´äººå›¾ç‰‡æè¿°è¯ï¼ˆè¯¦ç»†ç‰ˆï¼‰
    emotion: str  # è¯´è¯äººæƒ…ç»ª
    subtext: str  # æ½œå°è¯
    context: str  # å½“æ—¶çš„æƒ…æ™¯æˆ–å¿ƒç†çŠ¶æ€
    my_inner: str  # æˆ‘çš„å†…å¿ƒOS
    other_inner: str  # å¯¹æ–¹çš„å†…å¿ƒOS
    image_url: Optional[str] = None  # å›¾ç‰‡ URLï¼ˆä¼˜å…ˆä½¿ç”¨ï¼‰
    image_base64: Optional[str] = None  # Base64 ç¼–ç çš„å›¾ç‰‡æ•°æ®ï¼ˆå‘åå…¼å®¹ï¼ŒOSS å¤±è´¥æ—¶ä½¿ç”¨ï¼‰

class Call2Response(BaseModel):
    """Call #2 ç­–ç•¥åˆ†æå“åº”"""
    visual: List[VisualData]  # è§†è§‰æ•°æ®æ•°ç»„ï¼ˆå…³é”®æ—¶åˆ»ï¼‰
    strategies: List[StrategyItem]  # ç­–ç•¥åˆ—è¡¨


def wait_for_file_active(file: Any, max_wait_time=300) -> Any:
    """
    ç­‰å¾…æ–‡ä»¶çŠ¶æ€å˜ä¸º ACTIVE
    
    Args:
        file: Gemini æ–‡ä»¶å¯¹è±¡
        max_wait_time: æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ 5 åˆ†é’Ÿ
        
    Returns:
        çŠ¶æ€ä¸º ACTIVE çš„æ–‡ä»¶å¯¹è±¡
    """
    start_time = time.time()
    print(f"ç­‰å¾…æ–‡ä»¶å¤„ç†ï¼Œå½“å‰çŠ¶æ€: {file.state}")
    
    while file.state.name == "PROCESSING":
        elapsed = time.time() - start_time
        if elapsed > max_wait_time:
            raise Exception(f"æ–‡ä»¶å¤„ç†è¶…æ—¶ï¼ˆè¶…è¿‡ {max_wait_time} ç§’ï¼‰ï¼Œå½“å‰çŠ¶æ€: {file.state}")
        
        time.sleep(2)
        try:
            file = genai.get_file(file.name)
            print(f"æ–‡ä»¶çŠ¶æ€: {file.state} (å·²ç­‰å¾… {int(elapsed)} ç§’)")
        except Exception as e:
            print(f"è·å–æ–‡ä»¶çŠ¶æ€æ—¶å‡ºé”™: {e}")
            time.sleep(2)
            continue
    
    if file.state.name != "ACTIVE":
        raise Exception(f"æ–‡ä»¶å¤„ç†å¤±è´¥ï¼ŒçŠ¶æ€: {file.state}")
    
    return file


def upload_image_to_oss(image_bytes: bytes, user_id: str, session_id: str, image_index: int) -> Optional[str]:
    """
    ä¸Šä¼ å›¾ç‰‡åˆ°é˜¿é‡Œäº‘ OSS
    
    Args:
        image_bytes: å›¾ç‰‡çš„å­—èŠ‚æ•°æ®
        user_id: ç”¨æˆ· ID
        session_id: ä¼šè¯ ID
        image_index: å›¾ç‰‡ç´¢å¼•
        
    Returns:
        OSS URLï¼Œå¦‚æœå¤±è´¥è¿”å› None
    """
    if not USE_OSS or oss_bucket is None:
        logger.warning("OSS æœªå¯ç”¨æˆ–æœªåˆå§‹åŒ–ï¼Œæ— æ³•ä¸Šä¼ å›¾ç‰‡")
        return None
    
    try:
        # æ„å»º OSS æ–‡ä»¶è·¯å¾„: images/{user_id}/{session_id}/{image_index}.png
        oss_key = f"images/{user_id}/{session_id}/{image_index}.png"
        
        logger.info(f"ä¸Šä¼ å›¾ç‰‡åˆ° OSS: {oss_key}")
        logger.info(f"å›¾ç‰‡å¤§å°: {len(image_bytes)} å­—èŠ‚")
        
        # ä¸Šä¼ å›¾ç‰‡åˆ° OSS
        start_time = time.time()
        oss_bucket.put_object(oss_key, image_bytes, headers={'Content-Type': 'image/png'})
        upload_time = time.time() - start_time
        
        logger.info(f"âœ… å›¾ç‰‡ä¸Šä¼ æˆåŠŸï¼Œè€—æ—¶: {upload_time:.2f} ç§’")
        
        # æ„å»ºå›¾ç‰‡ URL
        if OSS_CDN_DOMAIN:
            # ä½¿ç”¨ CDN åŸŸå
            image_url = f"https://{OSS_CDN_DOMAIN}/{oss_key}"
        else:
            # ä½¿ç”¨ OSS ç›´æ¥è®¿é—® URL
            # æ ¼å¼: https://{bucket}.{endpoint}/{key}
            if OSS_ENDPOINT.startswith('http://'):
                endpoint = OSS_ENDPOINT.replace('http://', 'https://')
            elif OSS_ENDPOINT.startswith('https://'):
                endpoint = OSS_ENDPOINT
            else:
                endpoint = f"https://{OSS_BUCKET_NAME}.{OSS_ENDPOINT}"
            image_url = f"{endpoint}/{oss_key}"
        
        logger.info(f"âœ… å›¾ç‰‡ URL: {image_url}")
        return image_url
        
    except Exception as e:
        logger.error(f"âŒ ä¸Šä¼ å›¾ç‰‡åˆ° OSS å¤±è´¥: {e}")
        logger.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
        logger.error(f"å®Œæ•´é”™è¯¯å †æ ˆ:")
        logger.error(traceback.format_exc())
        return None


def generate_image_from_prompt(image_prompt: str, user_id: str, session_id: str, image_index: int, max_retries: int = 3) -> Optional[str]:
    """
    ä½¿ç”¨ Gemini Nano Banana ç”Ÿæˆå›¾ç‰‡å¹¶ä¸Šä¼ åˆ° OSS
    
    Args:
        image_prompt: å›¾ç‰‡ç”Ÿæˆæç¤ºè¯
        user_id: ç”¨æˆ· IDï¼ˆç”¨äº OSS æ–‡ä»¶è·¯å¾„ï¼‰
        session_id: ä¼šè¯ IDï¼ˆç”¨äº OSS æ–‡ä»¶è·¯å¾„ï¼‰
        image_index: å›¾ç‰‡ç´¢å¼•ï¼ˆç”¨äº OSS æ–‡ä»¶è·¯å¾„ï¼‰
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤ 3 æ¬¡ï¼‰
        
    Returns:
        å›¾ç‰‡ URLï¼ˆå¦‚æœ OSS å¯ç”¨ï¼‰æˆ– Base64 ç¼–ç çš„å›¾ç‰‡æ•°æ®ï¼ˆå¦‚æœ OSS æœªå¯ç”¨æˆ–å¤±è´¥ï¼‰ï¼Œå¦‚æœå¤±è´¥è¿”å› None
    """
    from google.genai.errors import ClientError
    
    client = genai_new.Client(api_key=GEMINI_API_KEY)
    
    # é…ç½®å›¾ç‰‡ç”Ÿæˆå‚æ•°
    config = genai_types.GenerateContentConfig(
        image_config=genai_types.ImageConfig(
            aspect_ratio="4:3"  # 1184x864ï¼Œæ¥è¿‘ 1024x768
        )
    )
    
    for attempt in range(max_retries):
        try:
            if attempt > 0:
                logger.info(f"========== é‡è¯•ç”Ÿæˆå›¾ç‰‡ (ç¬¬ {attempt + 1}/{max_retries} æ¬¡) ==========")
            else:
                logger.info(f"========== å¼€å§‹ç”Ÿæˆå›¾ç‰‡ ==========")
            
            logger.info(f"æç¤ºè¯é•¿åº¦: {len(image_prompt)} å­—ç¬¦")
            logger.debug(f"æç¤ºè¯å†…å®¹: {image_prompt[:200]}...")
            logger.info(f"è°ƒç”¨æ¨¡å‹: gemini-2.5-flash-image")
            logger.info(f"å®½é«˜æ¯”: 4:3 (1184x864)")
            
            start_time = time.time()
            response = client.models.generate_content(
                model="gemini-2.5-flash-image",
                contents=[image_prompt],
                config=config
            )
            generate_time = time.time() - start_time
            
            logger.info(f"âœ… å›¾ç‰‡ç”ŸæˆæˆåŠŸï¼Œè€—æ—¶: {generate_time:.2f} ç§’")
            
            # æå–å›¾ç‰‡æ•°æ®
            image_bytes = None
            for part in response.parts:
                if part.inline_data is not None:
                    # å›¾ç‰‡æ•°æ®å·²ç»æ˜¯ bytes
                    image_bytes = part.inline_data.data
                    logger.info(f"âœ… å›¾ç‰‡æ•°æ®æå–æˆåŠŸï¼Œå¤§å°: {len(image_bytes)} å­—èŠ‚")
                    break
            
            if image_bytes is None:
                logger.warning("âš ï¸ å“åº”ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ•°æ®")
                return None
            
            # å°è¯•ä¸Šä¼ åˆ° OSS
            if USE_OSS and oss_bucket is not None:
                logger.info(f"å°è¯•ä¸Šä¼ å›¾ç‰‡åˆ° OSS...")
                image_url = upload_image_to_oss(image_bytes, user_id, session_id, image_index)
                if image_url:
                    logger.info(f"âœ… å›¾ç‰‡å·²ä¸Šä¼ åˆ° OSSï¼ŒURL: {image_url}")
                    return image_url
                else:
                    logger.warning("âš ï¸ OSS ä¸Šä¼ å¤±è´¥ï¼Œé™çº§åˆ° Base64")
            
            # å¦‚æœ OSS æœªå¯ç”¨æˆ–ä¸Šä¼ å¤±è´¥ï¼Œé™çº§åˆ° Base64
            logger.info("ä½¿ç”¨ Base64 ç¼–ç è¿”å›å›¾ç‰‡")
            image_base64 = base64.b64encode(image_bytes).decode('utf-8')
            logger.info(f"âœ… å›¾ç‰‡ Base64 ç¼–ç å®Œæˆï¼Œå¤§å°: {len(image_base64)} å­—ç¬¦")
            return image_base64
            
        except ClientError as e:
            error_code = getattr(e, 'status_code', None)
            error_message = str(e)
            
            # å¤„ç† 429 é…é¢è¶…é™é”™è¯¯
            if error_code == 429 or '429' in error_message or 'RESOURCE_EXHAUSTED' in error_message:
                # å°è¯•ä»é”™è¯¯ä¿¡æ¯ä¸­æå–é‡è¯•å»¶è¿Ÿ
                retry_delay = 15  # é»˜è®¤å»¶è¿Ÿ 15 ç§’
                if 'retry in' in error_message.lower() or 'retryDelay' in error_message:
                    import re
                    delay_match = re.search(r'retry in ([\d.]+)s', error_message, re.IGNORECASE)
                    if delay_match:
                        retry_delay = max(15, int(float(delay_match.group(1))) + 2)  # è‡³å°‘ç­‰å¾… 15 ç§’ï¼Œå¤šåŠ  2 ç§’ç¼“å†²
                
                logger.warning(f"âš ï¸ é…é¢è¶…é™ (429)ï¼Œç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
                logger.warning(f"é”™è¯¯è¯¦æƒ…: {error_message[:500]}")
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯å…è´¹å±‚é…é¢ä¸º 0 çš„é—®é¢˜
                if 'limit: 0' in error_message or 'free_tier' in error_message.lower():
                    logger.error("âŒ æ£€æµ‹åˆ°å…è´¹å±‚é…é¢é™åˆ¶ (limit: 0)")
                    logger.error("ğŸ’¡ å»ºè®®æ£€æŸ¥:")
                    logger.error("   1. ç¡®è®¤ API Key æ˜¯å¦å…³è”åˆ°ä»˜è´¹é¡¹ç›®")
                    logger.error("   2. åœ¨ Google Cloud Console æ£€æŸ¥é…é¢è®¾ç½®")
                    logger.error("   3. ç¡®è®¤å·²å¯ç”¨å›¾ç‰‡ç”Ÿæˆ API çš„ä»˜è´¹é…é¢")
                    logger.error("   4. å¯èƒ½éœ€è¦ç­‰å¾…å‡ åˆ†é’Ÿè®©é…é¢åˆ·æ–°")
                
                if attempt < max_retries - 1:
                    logger.info(f"ç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
                    time.sleep(retry_delay)
                    continue
                else:
                    logger.error(f"âŒ é‡è¯• {max_retries} æ¬¡åä»ç„¶å¤±è´¥ï¼Œæ”¾å¼ƒç”Ÿæˆå›¾ç‰‡")
                    logger.error(f"æœ€ç»ˆé”™è¯¯: {error_message[:500]}")
                    return None
            else:
                # å…¶ä»–ç±»å‹çš„ ClientError
                logger.error(f"âŒ ç”Ÿæˆå›¾ç‰‡å¤±è´¥ (ClientError): {error_code} - {error_message[:500]}")
                if attempt < max_retries - 1:
                    wait_time = (attempt + 1) * 5  # æŒ‡æ•°é€€é¿ï¼š5ç§’ã€10ç§’ã€15ç§’
                    logger.info(f"ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                    continue
                else:
                    logger.error(traceback.format_exc())
                    return None
                    
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆå›¾ç‰‡å¤±è´¥: {e}")
            logger.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
            if attempt < max_retries - 1:
                wait_time = (attempt + 1) * 5  # æŒ‡æ•°é€€é¿
                logger.info(f"ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                time.sleep(wait_time)
                continue
            else:
                logger.error(f"å®Œæ•´é”™è¯¯å †æ ˆ:")
                logger.error(traceback.format_exc())
                return None
    
    return None


def parse_gemini_response(response_text: str) -> dict:
    """
    è§£æ Gemini è¿”å›çš„æ–‡æœ¬ï¼Œæå– JSON æ•°æ®
    
    Args:
        response_text: Gemini è¿”å›çš„æ–‡æœ¬
        
    Returns:
        è§£æåçš„å­—å…¸æ•°æ®
    """
    # å°è¯•æå– JSON éƒ¨åˆ†ï¼ˆå¯èƒ½åŒ…å«åœ¨ markdown ä»£ç å—ä¸­ï¼‰
    text = response_text.strip()
    
    # å¦‚æœåŒ…å« ```json æˆ– ``` æ ‡è®°ï¼Œæå–å…¶ä¸­çš„å†…å®¹
    if "```json" in text:
        start = text.find("```json") + 7
        end = text.find("```", start)
        if end != -1:
            text = text[start:end].strip()
    elif "```" in text:
        start = text.find("```") + 3
        end = text.find("```", start)
        if end != -1:
            text = text[start:end].strip()
    
    # è§£æ JSON
    try:
        data = json.loads(text)
        return data
    except json.JSONDecodeError as e:
        # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•ä¿®å¤å¸¸è§çš„ JSON é—®é¢˜
        print(f"JSON è§£æé”™è¯¯: {e}")
        print(f"åŸå§‹æ–‡æœ¬: {text}")
        raise HTTPException(status_code=500, detail=f"æ— æ³•è§£æ Gemini è¿”å›çš„ JSON: {str(e)}")


async def analyze_audio_from_path(temp_file_path: str, file_filename: str) -> Tuple[AudioAnalysisResponse, Optional[Call1Response]]:
    """
    ä»æ–‡ä»¶è·¯å¾„åˆ†æéŸ³é¢‘æ–‡ä»¶ï¼ˆå†…éƒ¨å‡½æ•°ï¼‰
    
    Args:
        temp_file_path: ä¸´æ—¶æ–‡ä»¶è·¯å¾„
        file_filename: æ–‡ä»¶å
        
    Returns:
        å…ƒç»„ï¼š(AudioAnalysisResponse, Optional[Call1Response])
        - AudioAnalysisResponse: å…¼å®¹æ—§ç‰ˆæœ¬çš„åˆ†æç»“æœ
        - Call1Response: æ–°çš„Call1æ ¼å¼æ•°æ®ï¼ˆå¦‚æœè§£ææˆåŠŸï¼‰
    """
    uploaded_file = None
    
    try:
        logger.info(f"========== æ–‡ä»¶ä¸Šä¼ å¤„ç†å¼€å§‹ ==========")
        logger.info(f"æ–‡ä»¶å·²ä¿å­˜åˆ°ä¸´æ—¶è·¯å¾„: {temp_file_path}")
        
        # ä¸Šä¼ æ–‡ä»¶åˆ° Geminiï¼ˆæ·»åŠ è¶…æ—¶å’Œé‡è¯•æœºåˆ¶ï¼‰
        file_size = os.path.getsize(temp_file_path)
        file_size_mb = file_size / 1024 / 1024
        logger.info(f"========== å¼€å§‹ä¸Šä¼ æ–‡ä»¶åˆ° Gemini ==========")
        logger.info(f"æ–‡ä»¶å: {file_filename}")
        logger.info(f"æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚ ({file_size_mb:.2f} MB)")
        logger.info(f"æ–‡ä»¶è·¯å¾„: {temp_file_path}")
        
        max_retries = 3
        retry_count = 0
        uploaded_file = None
        
        while retry_count < max_retries:
            try:
                logger.info(f"å°è¯•ä¸Šä¼ ï¼ˆç¬¬ {retry_count + 1}/{max_retries} æ¬¡ï¼‰...")
                logger.debug(f"è°ƒç”¨ genai.upload_file()")
                logger.debug(f"å‚æ•°: path={temp_file_path}, display_name={file_filename}")
                
                start_upload = time.time()
                uploaded_file = genai.upload_file(
                    path=temp_file_path,
                    display_name=file_filename
                )
                upload_time = time.time() - start_upload
                
                logger.info(f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼")
                logger.info(f"ä¸Šä¼ çš„æ–‡ä»¶å: {uploaded_file.name}")
                logger.info(f"æ–‡ä»¶çŠ¶æ€: {uploaded_file.state}")
                logger.info(f"ä¸Šä¼ è€—æ—¶: {upload_time:.2f} ç§’")
                break
            except Exception as e:
                retry_count += 1
                error_msg = str(e)
                error_type = type(e).__name__
                logger.error(f"âŒ ä¸Šä¼ å¤±è´¥ï¼ˆç¬¬ {retry_count}/{max_retries} æ¬¡ï¼‰")
                logger.error(f"é”™è¯¯ç±»å‹: {error_type}")
                logger.error(f"é”™è¯¯ä¿¡æ¯: {error_msg}")
                logger.error(f"å®Œæ•´é”™è¯¯å †æ ˆ:")
                logger.error(traceback.format_exc())
                
                if retry_count >= max_retries:
                    logger.error(f"å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œæ”¾å¼ƒä¸Šä¼ ")
                    raise Exception(f"ä¸Šä¼ æ–‡ä»¶å¤±è´¥ï¼ˆå·²é‡è¯• {max_retries} æ¬¡ï¼‰: {error_msg}")
                
                logger.info(f"ç­‰å¾… 5 ç§’åé‡è¯•...")
                time.sleep(5)
        
        # ç­‰å¾…æ–‡ä»¶å¤„ç†å®Œæˆï¼ˆæœ€å¤šç­‰å¾… 10 åˆ†é’Ÿï¼‰
        logger.info(f"========== ç­‰å¾…æ–‡ä»¶å¤„ç†å®Œæˆ ==========")
        logger.info(f"å½“å‰æ–‡ä»¶çŠ¶æ€: {uploaded_file.state}")
        uploaded_file = wait_for_file_active(uploaded_file, max_wait_time=600)
        logger.info(f"âœ… æ–‡ä»¶å¤„ç†å®Œæˆï¼ŒçŠ¶æ€: ACTIVE")
        
        # é…ç½®æ¨¡å‹å’Œæç¤ºè¯
        # ä½¿ç”¨ Gemini 3 Flash æ¨¡å‹ï¼ˆæ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼šhttps://ai.google.dev/gemini-api/docs/gemini-3ï¼‰
        # gemini-3-flash-preview: å…è´¹å±‚æœ‰é…é¢ï¼Œé€Ÿåº¦å¿«ï¼Œé€‚åˆéŸ³é¢‘åˆ†æ
        model_name = 'gemini-3-flash-preview'
        logger.info(f"========== é…ç½®æ¨¡å‹ ==========")
        logger.info(f"ä½¿ç”¨æ¨¡å‹: {model_name}")
        model = genai.GenerativeModel(model_name)
        logger.info(f"æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
        
        # ä½¿ç”¨æ–°çš„æç¤ºè¯ï¼ˆCall #1 - Observerï¼‰
        prompt = """è§’è‰²: ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è¯­éŸ³åˆ†æä¸è¡Œä¸ºè§‚å¯Ÿä¸“å®¶ã€‚

ä»»åŠ¡: è¯·æ·±å…¥è§£æä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶ï¼Œå¹¶è¾“å‡ºä¸¥æ ¼æ ¼å¼åŒ–çš„ JSON æ•°æ®ã€‚

å‚æ•°å®šä¹‰:

1. **mood_score**: (Integer, 0-100) æ ¹æ®è¯­è°ƒæ³¢åŠ¨ã€è¯­é€Ÿå˜åŒ–åŠè¯­ä¹‰å†²çªç¨‹åº¦å¯¹å¯¹è¯æ°›å›´è¿›è¡Œå»ºæ¨¡è¯„åˆ†ã€‚åˆ†æ•°è¶Šé«˜è¡¨ç¤ºæ°›å›´è¶Šè½»æ¾æ„‰å¿«ã€‚

2. **sigh_count**: (Integer) è¯†åˆ«å¹¶ç»Ÿè®¡ Speaker_1 (ç”¨æˆ·) åœ¨éŸ³é¢‘ä¸­äº§ç”Ÿçš„é•¿å‘¼æ°”æˆ–å¹æ°”æ¬¡æ•°ï¼ˆé€šå¸¸ä»£è¡¨å‹åŠ›ã€ç–²æƒ«æˆ–æ— å¥ˆï¼‰ã€‚

3. **laugh_count**: (Integer) è¯†åˆ«å¹¶ç»Ÿè®¡å…¨åœºå‡ºç°çš„æ‰€æœ‰ç±»å‹ç¬‘å£°ï¼ˆåŒ…æ‹¬æ„‰å¿«çš„ã€å°´å°¬çš„æˆ–å˜²è®½çš„ç¬‘ï¼‰ã€‚

4. **summary**: (String) å¯¹å¯¹è¯å†…å®¹ã€æ ¸å¿ƒçŸ›ç›¾åŠæƒ…ç»ªè½¬æŠ˜ç‚¹è¿›è¡Œç²¾ç‚¼æ€»ç»“ï¼ˆ100-200å­—ï¼‰ã€‚

5. **transcript**: (Array) æŒ‰æ—¶é—´é¡ºåºåŒ…å«æ‰€æœ‰å¯¹è¯ï¼Œæ¯ä¸ªå¯¹è¯åŒ…å«ï¼š
   - speaker: è¯´è¯äººæ ‡è¯†ï¼ˆå¦‚ï¼šSpeaker_0, Speaker_1ï¼Œå…¶ä¸­Speaker_1ä¸ºç”¨æˆ·ï¼‰
   - text: å¯¹è¯å†…å®¹ï¼ˆå®Œæ•´åŸè¯ï¼‰
   - timestamp: æ—¶é—´æˆ³ï¼ˆæ ¼å¼ï¼š"MM:SS"ï¼Œå¦‚"00:01"ï¼‰
   - is_me: (Boolean) æ˜¯å¦ä¸ºç”¨æˆ·è¯´çš„ï¼ˆSpeaker_1ä¸ºtrueï¼Œå…¶ä»–ä¸ºfalseï¼‰

6. **risks**: (Array) å…³é”®é£é™©ç‚¹åˆ—è¡¨

è¯·åŠ¡å¿…ä»¥çº¯ JSON æ ¼å¼è¿”å›ï¼Œä¸è¦åŒ…å« Markdown æ ‡è®°ã€‚

è¿”å›æ ¼å¼å¿…é¡»ä¸¥æ ¼éµå¾ªä»¥ä¸‹ç»“æ„ï¼š
{
  "mood_score": 75,
  "sigh_count": 2,
  "laugh_count": 5,
  "summary": "å¯¹è¯æ°”æ°›æ•´ä½“ç¼“å’Œï¼Œä½†åœ¨å‘¨æœ«åŠ ç­çš„æˆªæ­¢æ—¥æœŸé—®é¢˜ä¸Šå­˜åœ¨æ˜æ˜¾çš„éšå½¢æ‹‰é”¯ï¼Œç”¨æˆ·è¯•å›¾é˜²å¾¡ä¸ªäººæ—¶é—´ã€‚",
  "transcript": [
    {
      "speaker": "Speaker_0",
      "text": "å…·ä½“è¯´è¯å†…å®¹",
      "timestamp": "00:01",
      "is_me": false
    },
    {
      "speaker": "Speaker_1",
      "text": "å…·ä½“è¯´è¯å†…å®¹",
      "timestamp": "00:05",
      "is_me": true
    }
  ],
  "risks": ["é£é™©ç‚¹1", "é£é™©ç‚¹2", ...]
}

æ³¨æ„ï¼štranscript æ•°ç»„å¿…é¡»åŒ…å«æ‰€æœ‰å¯¹è¯ï¼ŒæŒ‰æ—¶é—´é¡ºåºæ’åˆ—ï¼Œä¸è¦é—æ¼ä»»ä½•å¯¹è¯ã€‚"""
        
        # è°ƒç”¨æ¨¡å‹è¿›è¡Œåˆ†æï¼ˆæ·»åŠ é‡è¯•æœºåˆ¶ï¼‰
        logger.info(f"========== å¼€å§‹è°ƒç”¨ Gemini æ¨¡å‹åˆ†æéŸ³é¢‘ ==========")
        logger.info(f"æ¨¡å‹: {model_name}")
        logger.info(f"æç¤ºè¯é•¿åº¦: {len(prompt)} å­—ç¬¦")
        max_retries = 3
        retry_count = 0
        response = None
        
        while retry_count < max_retries:
            try:
                logger.info(f"è°ƒç”¨æ¨¡å‹ï¼ˆç¬¬ {retry_count + 1}/{max_retries} æ¬¡ï¼‰...")
                logger.debug(f"è°ƒç”¨ model.generate_content()")
                start_generate = time.time()
                response = model.generate_content([
                    uploaded_file,
                    prompt
                ])
                generate_time = time.time() - start_generate
                logger.info(f"âœ… æ¨¡å‹è°ƒç”¨æˆåŠŸï¼Œè€—æ—¶: {generate_time:.2f} ç§’")
                break
            except Exception as e:
                retry_count += 1
                error_msg = str(e)
                error_type = type(e).__name__
                logger.error(f"âŒ è°ƒç”¨æ¨¡å‹å¤±è´¥ï¼ˆç¬¬ {retry_count}/{max_retries} æ¬¡ï¼‰")
                logger.error(f"é”™è¯¯ç±»å‹: {error_type}")
                logger.error(f"é”™è¯¯ä¿¡æ¯: {error_msg}")
                logger.error(f"å®Œæ•´é”™è¯¯å †æ ˆ:")
                logger.error(traceback.format_exc())
                if retry_count >= max_retries:
                    raise Exception(f"è°ƒç”¨æ¨¡å‹å¤±è´¥ï¼ˆé‡è¯• {max_retries} æ¬¡ï¼‰: {error_msg}")
                logger.info(f"ç­‰å¾… 5 ç§’åé‡è¯•...")
                time.sleep(5)
        
        logger.info(f"Gemini å“åº”é•¿åº¦: {len(response.text)} å­—ç¬¦")
        logger.debug(f"Gemini å“åº”å†…å®¹: {response.text[:500]}...")  # åªè®°å½•å‰500å­—ç¬¦
        
        # è§£æå“åº”
        analysis_data = parse_gemini_response(response.text)
        
        # å°è¯•è§£ææ–°çš„Call1æ ¼å¼ï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨æ—§æ ¼å¼
        call1_result = None
        try:
            # è§£æè½¬å½•åˆ—è¡¨
            transcript_list = []
            if "transcript" in analysis_data:
                for item in analysis_data["transcript"]:
                    transcript_list.append(TranscriptItem(
                        speaker=item.get("speaker", "æœªçŸ¥"),
                        text=item.get("text", ""),
                        timestamp=item.get("timestamp"),
                        is_me=item.get("is_me", False)
                    ))
            
            # æ„å»ºCall1Response
            call1_result = Call1Response(
                mood_score=analysis_data.get("mood_score", 70),
                stats={
                    "sigh": analysis_data.get("sigh_count", 0),
                    "laugh": analysis_data.get("laugh_count", 0)
                },
                summary=analysis_data.get("summary", ""),
                transcript=transcript_list
            )
            
            # è½¬æ¢ä¸ºæ—§æ ¼å¼ä»¥ä¿æŒå…¼å®¹æ€§
            dialogues_list = []
            for item in transcript_list:
                dialogues_list.append(DialogueItem(
                    speaker=item.speaker,
                    content=item.text,
                    tone="æœªçŸ¥",  # æ–°æ ¼å¼ä¸åŒ…å«toneï¼Œä¿ç•™é»˜è®¤å€¼
                    timestamp=item.timestamp,
                    is_me=item.is_me
                ))
            
            speaker_count = len(set(item.speaker for item in transcript_list)) if transcript_list else 0
            
        except Exception as e:
            logger.warning(f"è§£ææ–°æ ¼å¼å¤±è´¥ï¼Œä½¿ç”¨æ—§æ ¼å¼: {e}")
            # å…¼å®¹æ—§æ ¼å¼
            dialogues_list = []
            if "dialogues" in analysis_data:
                for dialogue in analysis_data["dialogues"]:
                    dialogues_list.append(DialogueItem(
                        speaker=dialogue.get("speaker", "æœªçŸ¥"),
                        content=dialogue.get("content", ""),
                        tone=dialogue.get("tone", "æœªçŸ¥"),
                        timestamp=dialogue.get("timestamp"),
                        is_me=dialogue.get("is_me", False)
                    ))
            speaker_count = analysis_data.get("speaker_count", 0)
        
        # éªŒè¯å¹¶æ„å»ºè¿”å›æ•°æ®
        result = AudioAnalysisResponse(
            speaker_count=speaker_count,
            dialogues=dialogues_list,
            risks=analysis_data.get("risks", [])
        )
        
        # è¿”å›ç»“æœå’ŒCall1æ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        return result, call1_result
        
    except Exception as e:
        error_msg = str(e)
        error_type = type(e).__name__
        logger.error(f"========== å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ ==========")
        logger.error(f"é”™è¯¯ç±»å‹: {error_type}")
        logger.error(f"é”™è¯¯ä¿¡æ¯: {error_msg}")
        logger.error(f"å®Œæ•´é”™è¯¯å †æ ˆ:")
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"éŸ³é¢‘åˆ†æå¤±è´¥: {error_msg}")
    
    finally:
        # åˆ é™¤ Gemini ä¸Šçš„æ–‡ä»¶
        if uploaded_file:
            try:
                genai.delete_file(uploaded_file.name)
                logger.info(f"å·²åˆ é™¤ Gemini æ–‡ä»¶: {uploaded_file.name}")
            except Exception as e:
                logger.error(f"åˆ é™¤ Gemini æ–‡ä»¶å¤±è´¥: {e}")


@app.post("/analyze-audio", response_model=AudioAnalysisResponse)
async def analyze_audio(file: UploadFile = File(...)):
    """
    åˆ†æä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶
    
    Args:
        file: ä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶ï¼ˆmp3/wav/m4aï¼‰
        
    Returns:
        ç»“æ„åŒ–çš„éŸ³é¢‘åˆ†æç»“æœ
    """
    # éªŒè¯æ–‡ä»¶ç±»å‹
    allowed_extensions = {'.mp3', '.wav', '.m4a'}
    file_ext = Path(file.filename).suffix.lower() if file.filename else '.m4a'
    
    if file_ext not in allowed_extensions:
        raise HTTPException(
            status_code=400,
            detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ã€‚ä»…æ”¯æŒ: {', '.join(allowed_extensions)}"
        )
    
    # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ä¿å­˜ä¸Šä¼ çš„éŸ³é¢‘
    temp_file_path = None
    
    try:
        # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
        with tempfile.NamedTemporaryFile(delete=False, suffix=file_ext) as temp_file:
            temp_file_path = temp_file.name
            content = await file.read()
            temp_file.write(content)
        
        # è°ƒç”¨å†…éƒ¨å‡½æ•°åˆ†æï¼ˆåªè¿”å›æ—§æ ¼å¼ä»¥ä¿æŒAPIå…¼å®¹æ€§ï¼‰
        result, _ = await analyze_audio_from_path(temp_file_path, file.filename or "audio.m4a")
        return result
        
    except Exception as e:
        error_msg = str(e)
        error_type = type(e).__name__
        logger.error(f"========== å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ ==========")
        logger.error(f"é”™è¯¯ç±»å‹: {error_type}")
        logger.error(f"é”™è¯¯ä¿¡æ¯: {error_msg}")
        logger.error(f"å®Œæ•´é”™è¯¯å †æ ˆ:")
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"éŸ³é¢‘åˆ†æå¤±è´¥: {error_msg}")
    
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if temp_file_path and os.path.exists(temp_file_path):
            try:
                os.unlink(temp_file_path)
                print(f"å·²åˆ é™¤ä¸´æ—¶æ–‡ä»¶: {temp_file_path}")
            except Exception as e:
                print(f"åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")


@app.get("/")
async def root():
    """æ ¹è·¯å¾„ï¼Œè¿”å›æœåŠ¡ä¿¡æ¯"""
    return {
        "service": "éŸ³é¢‘åˆ†ææœåŠ¡",
        "version": "1.0.0",
        "endpoint": "/analyze-audio"
    }


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    return {"message": "éŸ³é¢‘åˆ†ææœåŠ¡æ­£åœ¨è¿è¡Œ", "status": "ok"}


# ==================== ä»»åŠ¡ç®¡ç† API ====================

# å†…å­˜å­˜å‚¨ï¼ˆä¸´æ—¶ï¼Œåç»­æ”¹ä¸ºæ•°æ®åº“ï¼‰
tasks_storage: dict = {}
analysis_storage: dict = {}


class TaskItem(BaseModel):
    """ä»»åŠ¡é¡¹æ•°æ®æ¨¡å‹"""
    session_id: str
    title: str
    start_time: str
    end_time: Optional[str] = None
    duration: int
    tags: List[str] = []
    status: str
    emotion_score: Optional[int] = None
    speaker_count: Optional[int] = None


class TaskListResponse(BaseModel):
    """ä»»åŠ¡åˆ—è¡¨å“åº”"""
    sessions: List[TaskItem]
    pagination: dict


class TaskDetailResponse(BaseModel):
    """ä»»åŠ¡è¯¦æƒ…å“åº”"""
    session_id: str
    title: str
    start_time: str
    end_time: Optional[str] = None
    duration: int
    tags: List[str] = []
    status: str
    emotion_score: Optional[int] = None
    speaker_count: Optional[int] = None
    dialogues: List[dict] = []
    risks: List[str] = []
    summary: Optional[str] = None  # æ–°å¢ï¼šå¯¹è¯æ€»ç»“
    created_at: str
    updated_at: str


class UploadResponse(BaseModel):
    """ä¸Šä¼ å“åº”"""
    session_id: str
    audio_id: str
    title: str
    status: str
    estimated_duration: Optional[int] = None
    created_at: str


class APIResponse(BaseModel):
    """é€šç”¨ API å“åº”"""
    code: int
    message: str
    data: Optional[dict] = None
    timestamp: Optional[str] = None


def calculate_emotion_score(result: AudioAnalysisResponse) -> int:
    """è®¡ç®—æƒ…ç»ªåˆ†æ•°"""
    score = 70  # åŸºç¡€åˆ†æ•°
    
    for dialogue in result.dialogues:
        tone = dialogue.tone.lower()
        if tone in ["æ„¤æ€’", "ç„¦è™‘", "ç´§å¼ ", "angry", "anxious", "tense"]:
            score -= 20
        elif tone in ["è½»æ¾", "å¹³é™", "relaxed", "calm"]:
            score += 5
    
    score -= len(result.risks) * 10
    return max(0, min(100, score))


def generate_tags(result: AudioAnalysisResponse) -> List[str]:
    """ç”Ÿæˆæ ‡ç­¾"""
    tags = []
    
    for risk in result.risks:
        if "PUA" in risk or "pua" in risk.lower():
            tags.append("#PUAé¢„è­¦")
        if "é¢„ç®—" in risk or "budget" in risk.lower():
            tags.append("#é¢„ç®—")
        if "äº‰è®®" in risk or "dispute" in risk.lower():
            tags.append("#äº‰è®®")
    
    tones = [d.tone for d in result.dialogues]
    if any("æ„¤æ€’" in t or "angry" in t.lower() for t in tones):
        tags.append("#æ€¥èº")
    if any("ç”»é¥¼" in t or "promise" in t.lower() for t in tones):
        tags.append("#ç”»é¥¼")
    
    return tags if tags else ["#æ­£å¸¸"]


@app.post("/api/v1/audio/upload", response_model=APIResponse)
async def upload_audio_api(
    file: UploadFile = File(...),
    title: Optional[str] = None,
    user_id: str = Depends(get_current_user_id),
    db: AsyncSession = Depends(get_db)
):
    """ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶å¹¶å¼€å§‹åˆ†æï¼ˆéœ€è¦JWTè®¤è¯ï¼‰"""
    import asyncio
    from datetime import datetime
    
    logger.info("========== æ”¶åˆ°éŸ³é¢‘ä¸Šä¼ è¯·æ±‚ ==========")
    logger.info(f"æ–‡ä»¶å: {file.filename}")
    logger.info(f"Content-Type: {file.content_type}")
    logger.info(f"Title: {title}")
    logger.info(f"User ID: {user_id}")
    
    try:
        session_id = str(uuid.uuid4())
        logger.info(f"ç”Ÿæˆ session_id: {session_id}")
        
        if not title:
            formatter = datetime.now().strftime("%H:%M")
            title = f"å½•éŸ³ {formatter}"
        
        start_time = datetime.now()
        
        # åˆ›å»ºæ•°æ®åº“Sessionè®°å½•
        db_session = Session(
            id=uuid.UUID(session_id),
            user_id=uuid.UUID(user_id),
            title=title,
            start_time=start_time,
            duration=0,
            status="analyzing",
            tags=[]
        )
        db.add(db_session)
        await db.commit()
        await db.refresh(db_session)
        logger.info(f"æ•°æ®åº“Sessionå·²åˆ›å»º: {session_id}")
        
        # ä¿ç•™å†…å­˜å­˜å‚¨ç”¨äºå‘åå…¼å®¹ï¼ˆå¯é€‰ï¼‰
        task_data = {
            "session_id": session_id,
            "user_id": user_id,
            "title": title,
            "start_time": start_time.isoformat(),
            "end_time": None,
            "duration": 0,
            "tags": [],
            "status": "analyzing",
            "emotion_score": None,
            "speaker_count": None,
            "created_at": start_time.isoformat(),
            "updated_at": start_time.isoformat()
        }
        tasks_storage[session_id] = task_data
        logger.info(f"ä»»åŠ¡æ•°æ®å·²å­˜å‚¨: {session_id}")
        
        # è¯»å–æ–‡ä»¶å†…å®¹å¹¶ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶ï¼ˆå¿…é¡»åœ¨å¼‚æ­¥ä»»åŠ¡ä¹‹å‰è¯»å–ï¼Œå› ä¸º UploadFile åªèƒ½è¯»å–ä¸€æ¬¡ï¼‰
        logger.info("å¼€å§‹è¯»å–æ–‡ä»¶å†…å®¹...")
        file_content = await file.read()
        file_size = len(file_content)
        logger.info(f"æ–‡ä»¶å†…å®¹è¯»å–å®Œæˆï¼Œå¤§å°: {file_size} å­—èŠ‚ ({file_size / 1024 / 1024:.2f} MB)")
        
        file_filename = file.filename or "audio.m4a"
        file_ext = Path(file_filename).suffix.lower() if file_filename else '.m4a'
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ä¿å­˜æ–‡ä»¶å†…å®¹
        import tempfile
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=file_ext)
        temp_file.write(file_content)
        temp_file.close()
        temp_file_path = temp_file.name
        logger.info(f"ä¸´æ—¶æ–‡ä»¶å·²åˆ›å»º: {temp_file_path}")
        logger.info(f"æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚ ({file_size / 1024 / 1024:.2f} MB)")
        
        # å¼‚æ­¥åˆ†æï¼ˆä¼ é€’ä¸´æ—¶æ–‡ä»¶è·¯å¾„å’Œæ–‡ä»¶åï¼Œç¡®ä¿æ‰€æœ‰å‚æ•°éƒ½æ­£ç¡®ä¼ é€’ï¼‰
        # æ³¨æ„ï¼šä¸ä¼ é€’dbä¼šè¯ï¼Œåœ¨å¼‚æ­¥ä»»åŠ¡ä¸­åˆ›å»ºæ–°çš„ä¼šè¯
        logger.info(f"åˆ›å»ºå¼‚æ­¥åˆ†æä»»åŠ¡: session_id={session_id}, file_path={temp_file_path}, filename={file_filename}")
        asyncio.create_task(analyze_audio_async(session_id, temp_file_path, file_filename, task_data, user_id))
        
        # æ„å»ºå“åº”æ•°æ®
        response_data = {
            "session_id": session_id,
            "user_id": user_id,
            "audio_id": session_id,
            "title": title,
            "status": "analyzing",
            "estimated_duration": 300,
            "created_at": start_time.isoformat()
        }
        
        api_response = APIResponse(
            code=200,
            message="ä¸Šä¼ æˆåŠŸ",
            data=response_data,
            timestamp=datetime.now().isoformat()
        )
        
        logger.info("========== å‡†å¤‡è¿”å›å“åº” ==========")
        logger.info(f"å“åº”ç : {api_response.code}")
        logger.info(f"å“åº”æ¶ˆæ¯: {api_response.message}")
        logger.info(f"å“åº”æ•°æ®: {response_data}")
        logger.info(f"å“åº”å¯¹è±¡: {api_response}")
        logger.info(f"å“åº”å­—å…¸: {api_response.dict()}")
        
        # ä½¿ç”¨ JSONResponse ç¡®ä¿æ­£ç¡®åºåˆ—åŒ–
        return JSONResponse(
            content=api_response.dict(),
            status_code=200,
            headers={"Content-Type": "application/json"}
        )
    except Exception as e:
        logger.error(f"========== ä¸Šä¼ éŸ³é¢‘å¤±è´¥ ==========")
        logger.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
        logger.error(f"é”™è¯¯ä¿¡æ¯: {str(e)}")
        logger.error(f"å®Œæ•´é”™è¯¯å †æ ˆ:")
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"ä¸Šä¼ å¤±è´¥: {str(e)}")


async def analyze_audio_async(session_id: str, temp_file_path: str, file_filename: str, task_data: dict, user_id: str):
    """å¼‚æ­¥åˆ†æéŸ³é¢‘æ–‡ä»¶ï¼ˆä¿å­˜åˆ°æ•°æ®åº“ï¼‰"""
    from datetime import datetime
    from database.connection import AsyncSessionLocal
    
    # åˆ›å»ºæ–°çš„æ•°æ®åº“ä¼šè¯ï¼ˆå› ä¸ºåŸä¼šè¯å¯èƒ½å·²å…³é—­ï¼‰
    async with AsyncSessionLocal() as db:
        try:
            logger.info(f"========== å¼€å§‹å¼‚æ­¥åˆ†æéŸ³é¢‘ ==========")
            logger.info(f"session_id: {session_id}")
            logger.info(f"user_id: {user_id}")
            logger.info(f"temp_file_path: {temp_file_path}")
            logger.info(f"file_filename: {file_filename}")
            logger.info(f"task_data keys: {list(task_data.keys()) if task_data else 'None'}")
            
            # éªŒè¯å‚æ•°
            if not task_data:
                raise ValueError("task_data å‚æ•°ä¸èƒ½ä¸ºç©º")
            if not session_id:
                raise ValueError("session_id å‚æ•°ä¸èƒ½ä¸ºç©º")
            if not temp_file_path:
                raise ValueError("temp_file_path å‚æ•°ä¸èƒ½ä¸ºç©º")
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(temp_file_path):
                raise FileNotFoundError(f"ä¸´æ—¶æ–‡ä»¶ä¸å­˜åœ¨: {temp_file_path}")
            
            # è®°å½•æ–‡ä»¶å¤§å°ï¼ˆä¸é™åˆ¶ï¼‰
            file_size = os.path.getsize(temp_file_path)
            logger.info(f"æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚ ({file_size / 1024 / 1024:.2f} MB)")
            
            # ç›´æ¥ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶è·¯å¾„è°ƒç”¨ analyze_audio_from_path
            result, call1_result = await analyze_audio_from_path(temp_file_path, file_filename or "audio.m4a")
            
            # ä½¿ç”¨Call1ç»“æœæˆ–æ—§ç»“æœ
            if call1_result:
                emotion_score = call1_result.mood_score
                stats = call1_result.stats
                summary = call1_result.summary
                transcript = [t.dict() for t in call1_result.transcript]
            else:
                emotion_score = calculate_emotion_score(result)
                stats = {"sigh": 0, "laugh": 0}
                summary = ""
                transcript = []
            
            tags = generate_tags(result)
            
            end_time = datetime.now()
            duration = int((end_time - datetime.fromisoformat(task_data["start_time"])).total_seconds())
            
            # æ›´æ–°å†…å­˜å­˜å‚¨ï¼ˆå‘åå…¼å®¹ï¼‰
            task_data.update({
                "end_time": end_time.isoformat(),
                "duration": duration,
                "status": "archived",
                "emotion_score": emotion_score,
                "speaker_count": result.speaker_count,
                "tags": tags,
                "updated_at": end_time.isoformat()
            })
            
            # æ›´æ–°æ•°æ®åº“Session
            result_query = await db.execute(select(Session).where(Session.id == uuid.UUID(session_id)))
            db_session = result_query.scalar_one_or_none()
            if db_session:
                db_session.end_time = end_time
                db_session.duration = duration
                db_session.status = "archived"
                db_session.emotion_score = emotion_score
                db_session.speaker_count = result.speaker_count
                db_session.tags = tags
                await db.commit()
                logger.info(f"æ•°æ®åº“Sessionå·²æ›´æ–°: {session_id}")
            
            # ä¿å­˜åˆ†æç»“æœåˆ°æ•°æ®åº“
            analysis_result = AnalysisResult(
                session_id=uuid.UUID(session_id),
                dialogues=[d.dict() for d in result.dialogues],
                risks=result.risks,
                summary=summary,
                mood_score=emotion_score,
                stats=stats,
                transcript=json.dumps(transcript, ensure_ascii=False) if transcript else None,
                call1_result=call1_result.dict() if call1_result else None
            )
            db.add(analysis_result)
            await db.commit()
            logger.info(f"åˆ†æç»“æœå·²ä¿å­˜åˆ°æ•°æ®åº“: {session_id}")
            
            # å­˜å‚¨åˆ†æç»“æœåˆ°å†…å­˜ï¼ˆå‘åå…¼å®¹ï¼‰
            analysis_storage[session_id] = {
                "dialogues": [d.dict() for d in result.dialogues],
                "risks": result.risks,
                "call1": call1_result.dict() if call1_result else None,
                "mood_score": emotion_score,
                "stats": stats,
                "summary": summary,
                "transcript": transcript
            }
            
            logger.info(f"ä»»åŠ¡ {session_id} åˆ†æå®Œæˆ")
            
            # å¼‚æ­¥ç”Ÿæˆç­–ç•¥åˆ†æï¼ˆä¸é˜»å¡ä¸»æµç¨‹ï¼‰
            logger.info(f"å¼€å§‹å¼‚æ­¥ç”Ÿæˆç­–ç•¥åˆ†æ: {session_id}")
            asyncio.create_task(generate_strategies_async(session_id, user_id))
            
        except Exception as e:
            logger.error(f"========== åˆ†æéŸ³é¢‘å¤±è´¥ ==========")
            logger.error(f"session_id: {session_id}")
            logger.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
            logger.error(f"é”™è¯¯ä¿¡æ¯: {str(e)}")
            logger.error(traceback.format_exc())
            
            # æ›´æ–°å†…å­˜å­˜å‚¨
            task_data["status"] = "failed"
            task_data["updated_at"] = datetime.now().isoformat()
            
            # æ›´æ–°æ•°æ®åº“çŠ¶æ€
            try:
                result_query = await db.execute(select(Session).where(Session.id == uuid.UUID(session_id)))
                db_session = result_query.scalar_one_or_none()
                if db_session:
                    db_session.status = "failed"
                    await db.commit()
                    logger.info(f"æ•°æ®åº“SessionçŠ¶æ€å·²æ›´æ–°ä¸º failed: {session_id}")
                else:
                    logger.warning(f"æœªæ‰¾åˆ°æ•°æ®åº“Session: {session_id}")
            except Exception as db_error:
                logger.error(f"æ›´æ–°æ•°æ®åº“çŠ¶æ€å¤±è´¥: {db_error}")
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if temp_file_path and os.path.exists(temp_file_path):
                try:
                    os.unlink(temp_file_path)
                    logger.info(f"å·²åˆ é™¤ä¸´æ—¶æ–‡ä»¶: {temp_file_path}")
                except Exception as e:
                    logger.error(f"åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")


@app.get("/api/v1/tasks/sessions")
async def get_task_list(
    page: int = Query(1, ge=1),
    page_size: int = Query(20, ge=1, le=100),
    date: Optional[str] = None,
    status: Optional[str] = None,
    user_id: str = Depends(get_current_user_id),
    db: AsyncSession = Depends(get_db)
):
    """è·å–ä»»åŠ¡åˆ—è¡¨ï¼ˆéœ€è¦JWTè®¤è¯ï¼Œä»…è¿”å›å½“å‰ç”¨æˆ·çš„ä»»åŠ¡ï¼‰"""
    from datetime import datetime
    
    try:
        # ä»æ•°æ®åº“æŸ¥è¯¢å½“å‰ç”¨æˆ·çš„ä»»åŠ¡
        query = select(Session).where(Session.user_id == uuid.UUID(user_id))
        
        if date:
            target_date = datetime.fromisoformat(date).date()
            query = query.where(
                func.date(Session.start_time) == target_date
            )
        
        if status:
            query = query.where(Session.status == status)
        
        query = query.order_by(Session.created_at.desc())
        
        # è·å–æ€»æ•°
        count_result = await db.execute(select(func.count()).select_from(query.subquery()))
        total = count_result.scalar() or 0
        
        # åˆ†é¡µæŸ¥è¯¢
        query = query.offset((page - 1) * page_size).limit(page_size)
        result = await db.execute(query)
        sessions = result.scalars().all()
        
        task_items = [
            TaskItem(
                session_id=str(s.id),
                title=s.title or "",
                start_time=s.start_time.isoformat() if s.start_time else "",
                end_time=s.end_time.isoformat() if s.end_time else None,
                duration=s.duration or 0,
                tags=s.tags or [],
                status=s.status or "unknown",
                emotion_score=s.emotion_score,
                speaker_count=s.speaker_count
            )
            for s in sessions
        ]
        
        return APIResponse(
            code=200,
            message="success",
            data={
                "sessions": [t.dict() for t in task_items],
                "pagination": {
                    "page": page,
                    "page_size": page_size,
                    "total": total,
                    "total_pages": (total + page_size - 1) // page_size
                }
            },
            timestamp=datetime.now().isoformat()
        )
    except Exception as e:
        logger.error(f"è·å–ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {e}")
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"è·å–åˆ—è¡¨å¤±è´¥: {str(e)}")


@app.get("/api/v1/tasks/sessions/{session_id}")
async def get_task_detail(
    session_id: str,
    user_id: str = Depends(get_current_user_id),
    db: AsyncSession = Depends(get_db)
):
    """è·å–ä»»åŠ¡è¯¦æƒ…ï¼ˆéœ€è¦JWTè®¤è¯ï¼Œä»…èƒ½è®¿é—®è‡ªå·±çš„ä»»åŠ¡ï¼‰"""
    from datetime import datetime
    
    try:
        # ä»æ•°æ®åº“æŸ¥è¯¢ä»»åŠ¡ï¼Œç¡®ä¿å±äºå½“å‰ç”¨æˆ·
        result = await db.execute(
            select(Session).where(
                Session.id == uuid.UUID(session_id),
                Session.user_id == uuid.UUID(user_id)
            )
        )
        db_session = result.scalar_one_or_none()
        
        if not db_session:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
        
        # æŸ¥è¯¢åˆ†æç»“æœ
        analysis_result_query = await db.execute(
            select(AnalysisResult).where(AnalysisResult.session_id == uuid.UUID(session_id))
        )
        analysis_result = analysis_result_query.scalar_one_or_none()
        
        dialogues = []
        risks = []
        summary = None
        
        if analysis_result:
            dialogues = analysis_result.dialogues if isinstance(analysis_result.dialogues, list) else []
            risks = analysis_result.risks or []
            summary = analysis_result.summary
        
        detail = TaskDetailResponse(
            session_id=str(db_session.id),
            title=db_session.title or "",
            start_time=db_session.start_time.isoformat() if db_session.start_time else "",
            end_time=db_session.end_time.isoformat() if db_session.end_time else None,
            duration=db_session.duration or 0,
            tags=db_session.tags or [],
            status=db_session.status or "unknown",
            emotion_score=db_session.emotion_score,
            speaker_count=db_session.speaker_count,
            dialogues=dialogues,
            risks=risks,
            summary=summary,
            created_at=db_session.created_at.isoformat() if db_session.created_at else "",
            updated_at=db_session.updated_at.isoformat() if db_session.updated_at else ""
        )
        
        return APIResponse(
            code=200,
            message="success",
            data=detail.dict(),
            timestamp=datetime.now().isoformat()
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–ä»»åŠ¡è¯¦æƒ…å¤±è´¥: {e}")
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"è·å–è¯¦æƒ…å¤±è´¥: {str(e)}")


@app.get("/api/v1/tasks/sessions/{session_id}/status")
async def get_task_status(
    session_id: str,
    user_id: str = Depends(get_current_user_id),
    db: AsyncSession = Depends(get_db)
):
    """æŸ¥è¯¢ä»»åŠ¡åˆ†æçŠ¶æ€ï¼ˆéœ€è¦JWTè®¤è¯ï¼Œä»…èƒ½è®¿é—®è‡ªå·±çš„ä»»åŠ¡ï¼‰"""
    from datetime import datetime
    
    try:
        # ä»æ•°æ®åº“æŸ¥è¯¢ä»»åŠ¡ï¼Œç¡®ä¿å±äºå½“å‰ç”¨æˆ·
        result = await db.execute(
            select(Session).where(
                Session.id == uuid.UUID(session_id),
                Session.user_id == uuid.UUID(user_id)
            )
        )
        db_session = result.scalar_one_or_none()
        
        if not db_session:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
        
        status_value = db_session.status or "unknown"
        
        return APIResponse(
            code=200,
            message="success",
            data={
                "session_id": session_id,
                "status": status_value,
                "progress": 1.0 if status_value == "archived" else 0.5,
                "estimated_time_remaining": 0 if status_value == "archived" else 30,
                "updated_at": db_session.updated_at.isoformat() if db_session.updated_at else ""
            },
            timestamp=datetime.now().isoformat()
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {e}")
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"è·å–çŠ¶æ€å¤±è´¥: {str(e)}")


async def generate_strategies_async(session_id: str, user_id: str):
    """å¼‚æ­¥ç”Ÿæˆç­–ç•¥åˆ†æï¼ˆåœ¨éŸ³é¢‘åˆ†æå®Œæˆåè‡ªåŠ¨è°ƒç”¨ï¼‰"""
    from datetime import datetime
    from database.connection import AsyncSessionLocal
    
    # åˆ›å»ºæ–°çš„æ•°æ®åº“ä¼šè¯
    async with AsyncSessionLocal() as db:
        try:
            logger.info(f"========== å¼€å§‹å¼‚æ­¥ç”Ÿæˆç­–ç•¥åˆ†æ ==========")
            logger.info(f"session_id: {session_id}, user_id: {user_id}")
            
            # éªŒè¯ä»»åŠ¡å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
            result = await db.execute(
                select(Session).where(
                    Session.id == uuid.UUID(session_id),
                    Session.user_id == uuid.UUID(user_id)
                )
            )
            db_session = result.scalar_one_or_none()
            
            if not db_session:
                logger.error(f"ä»»åŠ¡ä¸å­˜åœ¨: {session_id}")
                return
            
            # ä»æ•°æ®åº“æŸ¥è¯¢åˆ†æç»“æœ
            analysis_result_query = await db.execute(
                select(AnalysisResult).where(AnalysisResult.session_id == uuid.UUID(session_id))
            )
            analysis_result_db = analysis_result_query.scalar_one_or_none()
            
            if not analysis_result_db:
                logger.error(f"åˆ†æç»“æœä¸å­˜åœ¨: {session_id}")
                return
            
            # è·å–transcript
            transcript = []
            if analysis_result_db.transcript:
                try:
                    transcript = json.loads(analysis_result_db.transcript) if isinstance(analysis_result_db.transcript, str) else analysis_result_db.transcript
                except:
                    transcript = []
            
            # å‘åå…¼å®¹ï¼šä»å†…å­˜å­˜å‚¨è·å–ï¼ˆå¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰ï¼‰
            analysis_result = analysis_storage.get(session_id, {})
            if not transcript and analysis_result:
                transcript = analysis_result.get("transcript", [])
            
            if not transcript:
                logger.error(f"å¯¹è¯è½¬å½•æ•°æ®ä¸å­˜åœ¨: {session_id}")
                return
            
            # è°ƒç”¨æ ¸å¿ƒç­–ç•¥ç”Ÿæˆé€»è¾‘
            await _generate_strategies_core(session_id, user_id, transcript, db)
            
        except Exception as e:
            logger.error(f"å¼‚æ­¥ç”Ÿæˆç­–ç•¥åˆ†æå¤±è´¥: {e}")
            logger.error(traceback.format_exc())


async def _generate_strategies_core(session_id: str, user_id: str, transcript: list, db: AsyncSession):
    """ç­–ç•¥ç”Ÿæˆæ ¸å¿ƒé€»è¾‘ï¼ˆv0.4 æŠ€èƒ½åŒ–æ¶æ„ï¼‰"""
    from datetime import datetime
    import asyncio
    
    try:
        logger.info(f"========== å¼€å§‹ç”Ÿæˆç­–ç•¥åˆ†æï¼ˆv0.4 æŠ€èƒ½åŒ–æ¶æ„ï¼‰ ==========")
        logger.info(f"session_id: {session_id}")
        
        # 1. åœºæ™¯è¯†åˆ«ï¼ˆRouter Agentï¼‰
        logger.info("========== æ­¥éª¤ 1: åœºæ™¯è¯†åˆ« ==========")
        model = genai.GenerativeModel('gemini-3-flash-preview')
        scene_result = classify_scene(transcript, model)
        primary_scene = scene_result.get("primary_scene", "other")
        scenes = scene_result.get("scenes", [])
        
        logger.info(f"åœºæ™¯è¯†åˆ«å®Œæˆ: primary_scene={primary_scene}")
        for scene in scenes:
            logger.info(f"  - {scene.get('category')}: {scene.get('confidence', 0):.2f}")
        
        # 2. æŠ€èƒ½åŒ¹é…
        logger.info("========== æ­¥éª¤ 2: æŠ€èƒ½åŒ¹é… ==========")
        matched_skills = await match_skills(scene_result, db)
        
        if not matched_skills:
            logger.warning("æœªåŒ¹é…åˆ°ä»»ä½•æŠ€èƒ½ï¼Œä½¿ç”¨é»˜è®¤æŠ€èƒ½")
            # ä½¿ç”¨ workplace_jungle ä½œä¸ºé»˜è®¤æŠ€èƒ½
            default_skill = await get_skill("workplace_jungle", db)
            if default_skill:
                matched_skills = [{
                    "skill_id": "workplace_jungle",
                    "name": default_skill["name"],
                    "category": default_skill["category"],
                    "priority": default_skill["priority"],
                    "confidence": 0.5
                }]
            else:
                raise Exception("æœªåŒ¹é…åˆ°æŠ€èƒ½ä¸”é»˜è®¤æŠ€èƒ½ä¸å­˜åœ¨")
        
        logger.info(f"åŒ¹é…åˆ° {len(matched_skills)} ä¸ªæŠ€èƒ½")
        for skill in matched_skills:
            logger.info(f"  âœ… æŠ€èƒ½: {skill['skill_id']} (åç§°: {skill.get('name', 'N/A')}, priority={skill['priority']}, confidence={skill['confidence']:.2f})")
        
        # 3. æŠ€èƒ½æ‰§è¡Œï¼ˆå¹¶è¡Œæ‰§è¡Œæ‰€æœ‰åŒ¹é…çš„æŠ€èƒ½ï¼‰
        logger.info("========== æ­¥éª¤ 3: æŠ€èƒ½æ‰§è¡Œ ==========")
        skill_results = []
        context = {
            "session_id": session_id,
            "user_id": user_id
        }
        
        # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰æŠ€èƒ½
        execution_tasks = []
        for matched_skill in matched_skills:
            skill_id = matched_skill["skill_id"]
            try:
                # è·å–å®Œæ•´æŠ€èƒ½ä¿¡æ¯ï¼ˆåŒ…å« prompt_templateï¼‰
                skill = await get_skill(skill_id, db)
                if not skill:
                    logger.warning(f"æŠ€èƒ½ä¸å­˜åœ¨: {skill_id}")
                    continue
                
                # æ·»åŠ åŒ¹é…ä¿¡æ¯åˆ°æŠ€èƒ½æ•°æ®
                skill["priority"] = matched_skill["priority"]
                skill["confidence"] = matched_skill["confidence"]
                
                # åˆ›å»ºæ‰§è¡Œä»»åŠ¡
                task = execute_skill(skill, transcript, context, model)
                execution_tasks.append((skill_id, task))
            except Exception as e:
                logger.error(f"å‡†å¤‡æ‰§è¡ŒæŠ€èƒ½å¤±è´¥: {skill_id}, é”™è¯¯: {e}")
                skill_results.append({
                    "skill_id": skill_id,
                    "result": None,
                    "execution_time_ms": 0,
                    "success": False,
                    "error_message": str(e),
                    "priority": matched_skill.get("priority", 0),
                    "confidence": matched_skill.get("confidence", 0.5)
                })
        
        # æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        for skill_id, task in execution_tasks:
            try:
                result = await task
                skill_results.append(result)
            except Exception as e:
                logger.error(f"æ‰§è¡ŒæŠ€èƒ½å¤±è´¥: {skill_id}, é”™è¯¯: {e}")
                skill_results.append({
                    "skill_id": skill_id,
                    "result": None,
                    "execution_time_ms": 0,
                    "success": False,
                    "error_message": str(e),
                    "priority": 0,
                    "confidence": 0.5
                })
        
        # è®°å½•æŠ€èƒ½æ‰§è¡Œåˆ°æ•°æ®åº“
        for skill_result in skill_results:
            try:
                skill_execution = SkillExecution(
                    session_id=uuid.UUID(session_id),
                    skill_id=skill_result["skill_id"],
                    scene_category=primary_scene,
                    confidence_score=skill_result.get("confidence", 0.5),
                    execution_time_ms=skill_result.get("execution_time_ms", 0),
                    success=skill_result.get("success", False),
                    error_message=skill_result.get("error_message")
                )
                db.add(skill_execution)
            except Exception as e:
                logger.error(f"è®°å½•æŠ€èƒ½æ‰§è¡Œå¤±è´¥: {skill_result['skill_id']}, é”™è¯¯: {e}")
        
        await db.commit()
        
        # 4. ç»“æœèåˆï¼ˆå¦‚æœå¤šæŠ€èƒ½ï¼‰
        logger.info("========== æ­¥éª¤ 4: ç»“æœèåˆ ==========")
        if len(skill_results) == 1 and skill_results[0].get("success"):
            # å•ä¸ªæŠ€èƒ½ï¼Œç›´æ¥ä½¿ç”¨ç»“æœ
            call2_result = skill_results[0]["result"]
        else:
            # å¤šæŠ€èƒ½ï¼Œéœ€è¦èåˆ
            call2_result = compose_results(skill_results)
        
        # 5. ä¸ºæ¯ä¸ªå…³é”®æ—¶åˆ»ç”Ÿæˆå›¾ç‰‡
        logger.info(f"========== æ­¥éª¤ 5: ç”Ÿæˆå›¾ç‰‡ ==========")
        logger.info(f"å¼€å§‹ä¸º {len(call2_result.visual)} ä¸ªå…³é”®æ—¶åˆ»ç”Ÿæˆå›¾ç‰‡")
        updated_visual_list = []
        for idx, visual_data in enumerate(call2_result.visual):
            try:
                logger.info(f"ç”Ÿæˆå›¾ç‰‡ {idx+1}/{len(call2_result.visual)}: transcript_index={visual_data.transcript_index}, speaker={visual_data.speaker}")
                image_result = generate_image_from_prompt(visual_data.image_prompt, user_id, session_id, idx)
                if image_result:
                    # åˆ¤æ–­è¿”å›çš„æ˜¯ URL è¿˜æ˜¯ Base64
                    if image_result.startswith('http://') or image_result.startswith('https://'):
                        # æ˜¯ URLï¼Œæ›´æ–° image_url å­—æ®µ
                        updated_visual = visual_data.model_copy(update={"image_url": image_result})
                        logger.info(f"âœ… å›¾ç‰‡ {idx+1} ç”ŸæˆæˆåŠŸï¼ŒURL: {image_result}")
                    else:
                        # æ˜¯ Base64ï¼Œæ›´æ–° image_base64 å­—æ®µï¼ˆå‘åå…¼å®¹ï¼‰
                        updated_visual = visual_data.model_copy(update={"image_base64": image_result})
                        logger.info(f"âœ… å›¾ç‰‡ {idx+1} ç”ŸæˆæˆåŠŸï¼ŒBase64 å¤§å°: {len(image_result)} å­—ç¬¦")
                    updated_visual_list.append(updated_visual)
                else:
                    # å³ä½¿ç”Ÿæˆå¤±è´¥ï¼Œä¹Ÿä¿ç•™ visual_data
                    updated_visual_list.append(visual_data)
                    logger.warning(f"âš ï¸ å›¾ç‰‡ {idx+1} ç”Ÿæˆå¤±è´¥ï¼Œä¿ç•™ visual_data")
            except Exception as e:
                logger.error(f"âŒ ç”Ÿæˆå›¾ç‰‡ {idx+1} æ—¶å‡ºé”™: {e}")
                logger.error(traceback.format_exc())
                # å³ä½¿å‡ºé”™ï¼Œä¹Ÿä¿ç•™ visual_data
                updated_visual_list.append(visual_data)
        
        call2_result.visual = updated_visual_list
        logger.info(f"========== å›¾ç‰‡ç”Ÿæˆå®Œæˆ ==========")
        
        # 6. ä¿å­˜ç­–ç•¥åˆ†æåˆ°æ•°æ®åº“
        logger.info("========== æ­¥éª¤ 6: ä¿å­˜åˆ°æ•°æ®åº“ ==========")
        
        # æ„å»º applied_skills åˆ—è¡¨
        applied_skills = [
            {
                "skill_id": skill_result["skill_id"],
                "priority": skill_result.get("priority", 0),
                "confidence": skill_result.get("confidence", 0.5)
            }
            for skill_result in skill_results
            if skill_result.get("success", False)
        ]
        
        # è·å–ä¸»è¦åœºæ™¯çš„ç½®ä¿¡åº¦ï¼ˆå­˜å‚¨ä¸º floatï¼Œä¸æ˜¯ JSONBï¼‰
        primary_scene_confidence = None
        for scene in scenes:
            if scene.get("category") == primary_scene:
                primary_scene_confidence = scene.get("confidence", 0.5)
                break
        if primary_scene_confidence is None:
            primary_scene_confidence = 0.5
        
        strategy_analysis = StrategyAnalysis(
            session_id=uuid.UUID(session_id),
            visual_data=[v.dict() for v in call2_result.visual],
            strategies=[s.dict() for s in call2_result.strategies],
            applied_skills=applied_skills,
            scene_category=primary_scene,
            scene_confidence=primary_scene_confidence
        )
        
        # å¦‚æœå·²å­˜åœ¨åˆ™æ›´æ–°ï¼Œå¦åˆ™åˆ›å»º
        existing_query = await db.execute(
            select(StrategyAnalysis).where(StrategyAnalysis.session_id == uuid.UUID(session_id))
        )
        existing = existing_query.scalar_one_or_none()
        if existing:
            existing.visual_data = [v.dict() for v in call2_result.visual]
            existing.strategies = [s.dict() for s in call2_result.strategies]
            existing.applied_skills = applied_skills
            existing.scene_category = primary_scene
            existing.scene_confidence = primary_scene_confidence
            await db.commit()
            logger.info(f"ç­–ç•¥åˆ†æå·²æ›´æ–°åˆ°æ•°æ®åº“: {session_id}")
        else:
            db.add(strategy_analysis)
            await db.commit()
            logger.info(f"ç­–ç•¥åˆ†æå·²ä¿å­˜åˆ°æ•°æ®åº“: {session_id}")
        
        # å­˜å‚¨ç­–ç•¥ç»“æœåˆ°å†…å­˜ï¼ˆå‘åå…¼å®¹ï¼‰
        if session_id not in analysis_storage:
            analysis_storage[session_id] = {}
        if "call2" not in analysis_storage[session_id]:
            analysis_storage[session_id]["call2"] = {}
        analysis_storage[session_id]["call2"] = call2_result.dict()
        
        logger.info(f"ç­–ç•¥åˆ†æç”ŸæˆæˆåŠŸï¼ˆv0.4 æŠ€èƒ½åŒ–æ¶æ„ï¼‰")
        logger.info(f"  - åœºæ™¯ç±»åˆ«: {primary_scene} (ç½®ä¿¡åº¦: {primary_scene_confidence:.2f})")
        logger.info(f"  - åº”ç”¨æŠ€èƒ½: {len(applied_skills)} ä¸ª")
        for skill in applied_skills:
            logger.info(f"    - {skill['skill_id']}: priority={skill['priority']}, confidence={skill['confidence']:.2f}")
        logger.info(f"  - å…³é”®æ—¶åˆ»æ•°é‡: {len(call2_result.visual)}")
        logger.info(f"  - ç­–ç•¥æ•°é‡: {len(call2_result.strategies)}")
        
        return call2_result
        
    except Exception as e:
        logger.error(f"ç”Ÿæˆç­–ç•¥å¤±è´¥: {e}")
        logger.error(traceback.format_exc())
        raise


@app.post("/api/v1/tasks/sessions/{session_id}/classify-scene")
async def classify_scene_endpoint(
    session_id: str,
    user_id: str = Depends(get_current_user_id),
    db: AsyncSession = Depends(get_db)
):
    """åœºæ™¯è¯†åˆ«æ¥å£ï¼ˆä»…è¿›è¡Œåœºæ™¯è¯†åˆ«ï¼Œä¸ç”Ÿæˆç­–ç•¥ï¼‰"""
    from datetime import datetime
    
    try:
        # éªŒè¯ä»»åŠ¡å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
        result = await db.execute(
            select(Session).where(
                Session.id == uuid.UUID(session_id),
                Session.user_id == uuid.UUID(user_id)
            )
        )
        db_session = result.scalar_one_or_none()
        
        if not db_session:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
        
        # ä»æ•°æ®åº“æŸ¥è¯¢åˆ†æç»“æœ
        analysis_result_query = await db.execute(
            select(AnalysisResult).where(AnalysisResult.session_id == uuid.UUID(session_id))
        )
        analysis_result_db = analysis_result_query.scalar_one_or_none()
        
        if not analysis_result_db:
            raise HTTPException(status_code=400, detail="åˆ†æç»“æœä¸å­˜åœ¨ï¼Œè¯·å…ˆå®ŒæˆéŸ³é¢‘åˆ†æ")
        
        # è·å–transcript
        transcript = []
        if analysis_result_db.transcript:
            try:
                transcript = json.loads(analysis_result_db.transcript) if isinstance(analysis_result_db.transcript, str) else analysis_result_db.transcript
            except:
                transcript = []
        
        if not transcript:
            raise HTTPException(status_code=400, detail="å¯¹è¯è½¬å½•æ•°æ®ä¸å­˜åœ¨ï¼Œè¯·å…ˆå®ŒæˆéŸ³é¢‘åˆ†æ")
        
        # åœºæ™¯è¯†åˆ«
        model = genai.GenerativeModel('gemini-3-flash-preview')
        scene_result = classify_scene(transcript, model)
        
        # æŠ€èƒ½åŒ¹é…
        matched_skills = await match_skills(scene_result, db)
        
        return APIResponse(
            code=200,
            message="success",
            data={
                "scenes": scene_result.get("scenes", []),
                "primary_scene": scene_result.get("primary_scene", "other"),
                "matched_skills": [
                    {
                        "skill_id": skill["skill_id"],
                        "name": skill["name"],
                        "priority": skill["priority"]
                    }
                    for skill in matched_skills
                ]
            },
            timestamp=datetime.now().isoformat()
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"åœºæ™¯è¯†åˆ«å¤±è´¥: {e}")
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"åœºæ™¯è¯†åˆ«å¤±è´¥: {str(e)}")


@app.post("/api/v1/tasks/sessions/{session_id}/strategies")
async def generate_strategies(
    session_id: str,
    user_id: str = Depends(get_current_user_id),
    db: AsyncSession = Depends(get_db)
):
    """ç”Ÿæˆç­–ç•¥åˆ†æï¼ˆCall #2ï¼‰- æƒ…å•†æ•™ç»ƒï¼ˆv0.4 æŠ€èƒ½åŒ–æ¶æ„ï¼Œéœ€è¦JWTè®¤è¯ï¼Œä»…èƒ½è®¿é—®è‡ªå·±çš„ä»»åŠ¡ï¼‰"""
    from datetime import datetime
    
    try:
        # éªŒè¯ä»»åŠ¡å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
        result = await db.execute(
            select(Session).where(
                Session.id == uuid.UUID(session_id),
                Session.user_id == uuid.UUID(user_id)
            )
        )
        db_session = result.scalar_one_or_none()
        
        if not db_session:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
        
        # ä¼˜å…ˆä»æ•°æ®åº“è¯»å–å·²ç”Ÿæˆçš„ç­–ç•¥åˆ†æ
        strategy_query = await db.execute(
            select(StrategyAnalysis).where(StrategyAnalysis.session_id == uuid.UUID(session_id))
        )
        existing_strategy = strategy_query.scalar_one_or_none()
        
        if existing_strategy and existing_strategy.visual_data and existing_strategy.strategies:
            logger.info(f"ä»æ•°æ®åº“è¯»å–å·²ç”Ÿæˆçš„ç­–ç•¥åˆ†æ: {session_id}")
            # æ„å»ºè¿”å›æ•°æ®
            visual_list = []
            for v in existing_strategy.visual_data:
                visual_list.append(VisualData(**v))
            
            strategies_list = []
            for s in existing_strategy.strategies:
                strategies_list.append(StrategyItem(**s))
            
            call2_result = Call2Response(
                visual=visual_list,
                strategies=strategies_list
            )
            
            # æ·»åŠ æŠ€èƒ½ä¿¡æ¯
            result_dict = call2_result.dict()
            applied_skills = existing_strategy.applied_skills or []
            scene_category = existing_strategy.scene_category
            scene_confidence = existing_strategy.scene_confidence
            
            logger.info(f"æŠ€èƒ½ä¿¡æ¯: applied_skills={applied_skills}, scene_category={scene_category}, scene_confidence={scene_confidence}")
            
            result_dict["applied_skills"] = applied_skills
            result_dict["scene_category"] = scene_category
            result_dict["scene_confidence"] = scene_confidence
            
            return APIResponse(
                code=200,
                message="success",
                data=result_dict,
                timestamp=datetime.now().isoformat()
            )
        
        # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰ï¼Œåˆ™ç”Ÿæˆæ–°çš„ç­–ç•¥åˆ†æ
        logger.info(f"æ•°æ®åº“ä¸­æ²¡æœ‰ç­–ç•¥åˆ†æï¼Œå¼€å§‹ç”Ÿæˆ: {session_id}")
        
        # ä»æ•°æ®åº“æŸ¥è¯¢åˆ†æç»“æœ
        analysis_result_query = await db.execute(
            select(AnalysisResult).where(AnalysisResult.session_id == uuid.UUID(session_id))
        )
        analysis_result_db = analysis_result_query.scalar_one_or_none()
        
        if not analysis_result_db:
            raise HTTPException(status_code=400, detail="åˆ†æç»“æœä¸å­˜åœ¨ï¼Œè¯·å…ˆå®ŒæˆéŸ³é¢‘åˆ†æ")
        
        # è·å–transcript
        transcript = []
        if analysis_result_db.transcript:
            try:
                transcript = json.loads(analysis_result_db.transcript) if isinstance(analysis_result_db.transcript, str) else analysis_result_db.transcript
            except:
                transcript = []
        
        # å‘åå…¼å®¹ï¼šä»å†…å­˜å­˜å‚¨è·å–ï¼ˆå¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰ï¼‰
        analysis_result = analysis_storage.get(session_id, {})
        if not transcript and analysis_result:
            transcript = analysis_result.get("transcript", [])
        
        if not transcript:
            raise HTTPException(status_code=400, detail="å¯¹è¯è½¬å½•æ•°æ®ä¸å­˜åœ¨ï¼Œè¯·å…ˆå®ŒæˆéŸ³é¢‘åˆ†æ")
        
        # è°ƒç”¨æ ¸å¿ƒç­–ç•¥ç”Ÿæˆé€»è¾‘
        call2_result = await _generate_strategies_core(session_id, user_id, transcript, db)
        
        # ä»æ•°æ®åº“è¯»å–æŠ€èƒ½ä¿¡æ¯
        strategy_query_after = await db.execute(
            select(StrategyAnalysis).where(StrategyAnalysis.session_id == uuid.UUID(session_id))
        )
        strategy_after = strategy_query_after.scalar_one_or_none()
        
        # æ·»åŠ æŠ€èƒ½ä¿¡æ¯åˆ°è¿”å›æ•°æ®
        result_dict = call2_result.dict()
        if strategy_after:
            applied_skills = strategy_after.applied_skills or []
            scene_category = strategy_after.scene_category
            scene_confidence = strategy_after.scene_confidence
            
            logger.info(f"æŠ€èƒ½ä¿¡æ¯: applied_skills={applied_skills}, scene_category={scene_category}, scene_confidence={scene_confidence}")
            
            result_dict["applied_skills"] = applied_skills
            result_dict["scene_category"] = scene_category
            result_dict["scene_confidence"] = scene_confidence
        else:
            logger.warning(f"æœªæ‰¾åˆ°ç­–ç•¥åˆ†ææ•°æ®ï¼Œæ— æ³•è¿”å›æŠ€èƒ½ä¿¡æ¯: {session_id}")
            result_dict["applied_skills"] = []
            result_dict["scene_category"] = None
            result_dict["scene_confidence"] = None
        
        return APIResponse(
            code=200,
            message="success",
            data=result_dict,
            timestamp=datetime.now().isoformat()
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ç”Ÿæˆç­–ç•¥å¤±è´¥: {e}")
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"ç”Ÿæˆç­–ç•¥å¤±è´¥: {str(e)}")


@app.get("/api/v1/images/{session_id}/{image_index}")
async def get_image(
    session_id: str,
    image_index: int,
    user_id: str = Depends(get_current_user_id),
    db: AsyncSession = Depends(get_db)
):
    """
    è·å–å›¾ç‰‡ï¼ˆé€šè¿‡åç«¯ API è®¿é—®ï¼Œæ”¯æŒç§æœ‰ OSS bucketï¼Œéœ€è¦JWTè®¤è¯ï¼‰
    
    æ³¨æ„ï¼šç”±äº OSS bucket è®¾ç½®ä¸ºç§æœ‰ï¼Œä¸èƒ½ç›´æ¥é€šè¿‡ OSS URL è®¿é—®å›¾ç‰‡ã€‚
    å¿…é¡»é€šè¿‡æ­¤ API æ¥å£è®¿é—®ï¼Œåç«¯ä¼šä» OSS è·å–å›¾ç‰‡å¹¶è¿”å›ã€‚
    ä»…èƒ½è®¿é—®å±äºå½“å‰ç”¨æˆ·çš„å›¾ç‰‡ã€‚
    
    Args:
        session_id: ä¼šè¯ ID
        image_index: å›¾ç‰‡ç´¢å¼•
        
    Returns:
        å›¾ç‰‡æ•°æ®ï¼ˆPNG æ ¼å¼ï¼‰
    """
    try:
        # éªŒè¯ä»»åŠ¡å±äºå½“å‰ç”¨æˆ·
        result = await db.execute(
            select(Session).where(
                Session.id == uuid.UUID(session_id),
                Session.user_id == uuid.UUID(user_id)
            )
        )
        db_session = result.scalar_one_or_none()
        
        if not db_session:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
        
        # å¦‚æœ OSS æœªå¯ç”¨ï¼Œè¿”å›é”™è¯¯
        if not USE_OSS or oss_bucket is None:
            logger.warning("OSS æœªå¯ç”¨ï¼Œæ— æ³•æä¾›å›¾ç‰‡è®¿é—®")
            raise HTTPException(status_code=503, detail="Image service unavailable")
        
        # æ„å»º OSS æ–‡ä»¶è·¯å¾„: images/{user_id}/{session_id}/{image_index}.png
        oss_key = f"images/{user_id}/{session_id}/{image_index}.png"
        
        logger.info(f"è·å–å›¾ç‰‡: {oss_key}")
        
        try:
            # ä» OSS è·å–å›¾ç‰‡
            start_time = time.time()
            image_object = oss_bucket.get_object(oss_key)
            image_data = image_object.read()
            fetch_time = time.time() - start_time
            
            logger.info(f"âœ… å›¾ç‰‡è·å–æˆåŠŸï¼Œå¤§å°: {len(image_data)} å­—èŠ‚ï¼Œè€—æ—¶: {fetch_time:.2f} ç§’")
            
            # è¿”å›å›¾ç‰‡æ•°æ®ï¼Œè®¾ç½®ç¼“å­˜å¤´
            return Response(
                content=image_data,
                media_type="image/png",
                headers={
                    "Cache-Control": "public, max-age=3600",  # ç¼“å­˜ 1 å°æ—¶
                    "Content-Disposition": f'inline; filename="image_{image_index}.png"'
                }
            )
            
        except Exception as e:
            error_msg = str(e)
            if "NoSuchKey" in error_msg or "404" in error_msg:
                logger.warning(f"å›¾ç‰‡ä¸å­˜åœ¨: {oss_key}")
                raise HTTPException(status_code=404, detail="Image not found")
            else:
                logger.error(f"âŒ ä» OSS è·å–å›¾ç‰‡å¤±è´¥: {e}")
                logger.error(traceback.format_exc())
                raise HTTPException(status_code=500, detail="Failed to fetch image")
                
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ è·å–å›¾ç‰‡æ—¶å‡ºé”™: {e}")
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail="Internal server error")


def cleanup_old_images(days: int = 7):
    """
    æ¸…ç†è¿‡æœŸçš„å›¾ç‰‡æ–‡ä»¶
    
    Args:
        days: ä¿ç•™å¤©æ•°ï¼Œé»˜è®¤ 7 å¤©
    """
    if not USE_OSS or oss_bucket is None:
        logger.warning("OSS æœªå¯ç”¨ï¼Œæ— æ³•æ¸…ç†å›¾ç‰‡")
        return
    
    try:
        from datetime import datetime, timedelta
        cutoff_date = datetime.now() - timedelta(days=days)
        
        logger.info(f"å¼€å§‹æ¸…ç† {days} å¤©å‰çš„å›¾ç‰‡æ–‡ä»¶...")
        
        # åˆ—å‡ºæ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
        prefix = "images/"
        deleted_count = 0
        error_count = 0
        
        for obj in oss2.ObjectIterator(oss_bucket, prefix=prefix):
            # æ£€æŸ¥æ–‡ä»¶ä¿®æ”¹æ—¶é—´
            if obj.last_modified < cutoff_date:
                try:
                    oss_bucket.delete_object(obj.key)
                    deleted_count += 1
                    logger.debug(f"åˆ é™¤æ–‡ä»¶: {obj.key}")
                except Exception as e:
                    error_count += 1
                    logger.error(f"åˆ é™¤æ–‡ä»¶å¤±è´¥ {obj.key}: {e}")
        
        logger.info(f"âœ… æ¸…ç†å®Œæˆ: åˆ é™¤ {deleted_count} ä¸ªæ–‡ä»¶ï¼Œå¤±è´¥ {error_count} ä¸ª")
        
    except Exception as e:
        logger.error(f"âŒ æ¸…ç†å›¾ç‰‡æ–‡ä»¶å¤±è´¥: {e}")
        logger.error(traceback.format_exc())


@app.get("/api/v1/admin/cleanup-images")
async def cleanup_images_endpoint(days: int = Query(7, ge=1, le=30)):
    """
    æ¸…ç†è¿‡æœŸå›¾ç‰‡çš„ç®¡ç†æ¥å£
    
    Args:
        days: ä¿ç•™å¤©æ•°ï¼Œé»˜è®¤ 7 å¤©
    """
    try:
        cleanup_old_images(days)
        return {"message": f"æ¸…ç†å®Œæˆï¼Œä¿ç•™æœ€è¿‘ {days} å¤©çš„å›¾ç‰‡", "status": "success"}
    except Exception as e:
        logger.error(f"æ¸…ç†å›¾ç‰‡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ¸…ç†å¤±è´¥: {str(e)}")


@app.get("/test-gemini")
async def test_gemini():
    """æµ‹è¯• Gemini 3 Flash API è¿æ¥"""
    try:
        print("æµ‹è¯• Gemini 3 Flash API è¿æ¥...")
        # ä½¿ç”¨ Gemini 3 Flashï¼ˆæ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼Œå…è´¹å±‚æœ‰é…é¢ï¼‰
        model_name = 'gemini-3-flash-preview'
        print(f"ä½¿ç”¨æ¨¡å‹: {model_name}")
        model = genai.GenerativeModel(model_name)
        response = model.generate_content("è¯·å›å¤'è¿æ¥æˆåŠŸ'")
        return {
            "status": "success",
            "message": "Gemini 3 Flash API è¿æ¥æ­£å¸¸",
            "model": model_name,
            "response": response.text
        }
    except Exception as e:
        error_msg = str(e)
        print(f"Gemini 3 Flash è¿æ¥å¤±è´¥: {error_msg}")
        return {
            "status": "error",
            "message": "Gemini 3 Flash API è¿æ¥å¤±è´¥",
            "error": error_msg
        }


@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–æ•°æ®åº“å’ŒæŠ€èƒ½"""
    try:
        logger.info("æ­£åœ¨åˆå§‹åŒ–æ•°æ®åº“...")
        await init_db()
        logger.info("âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
        
        # åˆå§‹åŒ–æŠ€èƒ½ï¼ˆv0.4 æŠ€èƒ½åŒ–æ¶æ„ï¼‰
        try:
            logger.info("æ­£åœ¨åˆå§‹åŒ–æŠ€èƒ½...")
            from database.connection import async_session_maker
            async with async_session_maker() as db:
                try:
                    registered_skills = await initialize_skills(db)
                    logger.info(f"âœ… æŠ€èƒ½åˆå§‹åŒ–å®Œæˆï¼Œå…±æ³¨å†Œ {len(registered_skills)} ä¸ªæŠ€èƒ½")
                    for skill in registered_skills:
                        logger.info(f"  - {skill['skill_id']}: {skill['name']}")
                except Exception as e:
                    logger.error(f"âŒ æŠ€èƒ½åˆå§‹åŒ–å¤±è´¥: {e}")
                    logger.error(traceback.format_exc())
                    await db.rollback()
        except Exception as e:
            logger.error(f"âŒ æŠ€èƒ½åˆå§‹åŒ–å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            # ä¸é˜»æ­¢åº”ç”¨å¯åŠ¨ï¼Œå…è®¸åœ¨æ²¡æœ‰æŠ€èƒ½çš„æƒ…å†µä¸‹è¿è¡Œï¼ˆå‘åå…¼å®¹ï¼‰
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
        logger.error(traceback.format_exc())
        # ä¸é˜»æ­¢åº”ç”¨å¯åŠ¨ï¼Œå…è®¸åœ¨æ²¡æœ‰æ•°æ®åº“çš„æƒ…å†µä¸‹è¿è¡Œï¼ˆå‘åå…¼å®¹ï¼‰


@app.on_event("shutdown")
async def shutdown_event():
    """åº”ç”¨å…³é—­æ—¶æ¸…ç†æ•°æ®åº“è¿æ¥"""
    try:
        await close_db()
        logger.info("âœ… æ•°æ®åº“è¿æ¥å·²å…³é—­")
    except Exception as e:
        logger.error(f"å…³é—­æ•°æ®åº“è¿æ¥æ—¶å‡ºé”™: {e}")


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8001)

