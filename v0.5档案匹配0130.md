# v0.5 档案匹配技术方案（2025-01-30）

本文档描述当前「录音分析 → 说话人与档案匹配 → 任务详情展示档案名」的完整技术方案，包括数据模型、流程、接口与扩展点。

---

## 1. 目标与范围

- **目标**：在完成录音分析后，将转录中的说话人标识（如 `Speaker_0`、`Speaker_1`）与当前用户的**档案**关联，在任务详情、总结、对话列表中展示为「档案名（关系）」而非原始标签。
- **范围**：服务端分析流水线中的声纹/占位匹配、`speaker_mapping` 写入、任务详情接口中的 `speaker_names` 与总结替换；档案管理 API 与数据库模型；不包含客户端 UI 实现细节。

---

## 2. 数据模型

### 2.1 档案（Profile）

- **表**：`profiles`（[database/models.py](database/models.py)）
- **主要字段**：
  - `id`（UUID）、`user_id`（所属用户）
  - `name`、`relationship_type`（关系：自己、死党、领导等）
  - `photo_url`、`notes`
  - 声纹相关（可选）：`audio_session_id`、`audio_segment_id`、`audio_start_time`、`audio_end_time`、`audio_url`（档案对应音频片段，用于后续声纹注册）

### 2.2 会话与分析结果

- **sessions**：`audio_url`（原音频 OSS URL）、`audio_path`（原音频本地路径），供声纹流程获取本地音频。
- **analysis_results**：
  - `speaker_mapping`（JSONB）：`{ "Speaker_0": "profile_id_uuid", "Speaker_1": "profile_id_uuid" }`，说话人标签到档案 ID 的映射。
  - `conversation_summary`（Text）：第二次 Gemini 生成的「谁和谁对话」总结；写入时若已有 `speaker_mapping`，会先用档案名（关系）替换 transcript 中的说话人再生成总结。

### 2.3 任务详情响应中的档案相关字段

- **TaskDetailResponse**（[main.py](main.py) 约 1009–1027 行）：
  - `speaker_mapping`：原始映射 `Speaker_* -> profile_id`，可选。
  - `speaker_names`：展示用映射 `Speaker_* -> "档案名（关系）"`，如 `"张三（自己）"`，由服务端根据 `speaker_mapping` 查 Profile 后填充。
  - `summary`、`conversation_summary`：返回前若存在 `speaker_names`，会将其中的 `Speaker_0`/`Speaker_1` 以及「用户」（Call #1 约定 Speaker_1 为用户）替换为对应档案名，便于前端直接展示。

---

## 3. 档案分析涉及的接口与表

### 3.1 涉及的接口

| 方法 | 路径 | 说明 |
|------|------|------|
| POST | `/api/v1/audio/upload` | 上传录音并触发分析；分析完成后台执行档案匹配（读 transcript、sessions 原音频、profiles），写入 `analysis_results.speaker_mapping` 与 `conversation_summary`。 |
| GET | `/api/v1/tasks/sessions/{session_id}` | 任务详情；读 `analysis_results.speaker_mapping`、`conversation_summary`，查 `profiles` 得到 `speaker_names`，并替换 summary/conversation_summary 中的说话人标签后返回。 |
| GET | `/api/v1/profiles` | 获取当前用户档案列表；档案匹配流程中通过内部查库获取 `profile_ids`（不直接调该接口），前端展示档案列表、创建/编辑档案时使用。 |
| POST | `/api/v1/profiles` | 创建档案；提供档案数据源，匹配时按 `user_id` 查到的档案即来自本表。 |
| PUT | `/api/v1/profiles/{profile_id}` | 更新档案；更新后任务详情中的 `speaker_names` 会随档案 name/relationship 变化。 |
| DELETE | `/api/v1/profiles/{profile_id}` | 删除档案；删除后该 profile_id 不再参与匹配，已有 `speaker_mapping` 中若含此 id，详情展示时可能显示为原始 Speaker_* 或需兼容。 |
| POST | `/api/v1/profiles/upload-photo` | 上传档案照片；与声纹/匹配无直接关系，用于档案头像展示。 |

说明：档案匹配逻辑在「上传 → 分析」的异步流程内部执行，无单独 HTTP 接口；匹配时依赖 `sessions`、`analysis_results`、`profiles` 的读与 `analysis_results` 的写。

### 3.2 涉及的表

| 表名 | 与档案分析相关的字段 / 用途 |
|------|-----------------------------|
| `profiles` | `id`、`user_id`、`name`、`relationship_type`；匹配时按 `user_id` 取当前用户档案 ID 列表；任务详情时按 `speaker_mapping` 中的 profile_id 查 `name`、`relationship_type` 拼成 `speaker_names`。 |
| `sessions` | `id`、`user_id`、`audio_url`、`audio_path`、`duration`；分析后流程用 `audio_url`/`audio_path` 获取本地音频以剪切片段或做单说话人占位，`duration` 用于缺省结束时间。 |
| `analysis_results` | `session_id`、`transcript`、`speaker_mapping`、`conversation_summary`；Call #1 写入 `transcript` 等；档案匹配流程读 transcript 取说话人首句时间、写 `speaker_mapping`、第二次 Gemini 后写 `conversation_summary`；任务详情接口读本表得到 `speaker_mapping`、`conversation_summary` 及 summary 等。 |
| `users` | `id`；档案归属与鉴权，`profiles.user_id`、`sessions.user_id` 均指向本表，匹配仅针对当前用户下的 profiles。 |

---

## 4. 档案管理 API

- **路由**：[api/profiles.py](api/profiles.py)，前缀 `/api/v1/profiles`，需 JWT。
- **能力**：
  - `GET /api/v1/profiles`：获取当前用户档案列表（含短期内存缓存 TTL 60s，创建/更新/删除时按 user_id 失效）。
  - `POST /api/v1/profiles`：创建档案（body 含 name、relationship、photo_url、notes、audio_session_id、audio_segment_id、audio_start_time、audio_end_time、audio_url 等）。
  - `PUT /api/v1/profiles/{profile_id}`：更新档案。
  - `DELETE /api/v1/profiles/{profile_id}`：删除档案。
  - `POST /api/v1/profiles/upload-photo`：上传档案照片到 OSS，返回 URL。

---

## 5. 分析后档案匹配流程（声纹 / 占位）

在 `analyze_audio_async` 中，Call #1 分析完成并写入 `analysis_results`（含 transcript）后，执行以下步骤（[main.py](main.py) 约 1309–1395 行）。

### 5.1 前置条件

- 存在 `transcript`（每条含 `speaker`、`timestamp`、`text` 等）。
- 存在原音频：`audio_url` 或 `audio_path`（用于按时间剪切片段或占位逻辑）。

### 5.2 为每个说话人选取「第一句」时间区间

- 遍历 transcript，按 `speaker` 去重，为每个说话人记录**第一次出现**的起止时间：
  - 开始：该条 `timestamp` 转为秒。
  - 结束：下一条的 `timestamp` 转为秒；若无下条则用会话 `duration` 或 `start_sec + 5.0`。
- 得到 `first_segment: { "Speaker_0": (start_sec, end_sec), "Speaker_1": (...) }`。

### 5.3 获取本地音频路径

- 调用 [utils/audio_storage.py](utils/audio_storage.py) 中 `get_session_audio_local_path(audio_url, audio_path)`：
  - 若有 `audio_path` 且文件存在，直接返回 `(audio_path, False)`。
  - 若仅有 `audio_url`：本 bucket 私有读时用 OSS SDK 下载到临时文件；否则用 urllib。返回 `(local_path, is_temp)`，`is_temp=True` 时调用方需在用完后删除。

### 5.4 获取当前用户档案 ID 列表

- `profile_ids = [str(r) for r in profile_result.scalars().all()]`，来自 `Profile.id` 且 `user_id = 当前用户`。
- 若无档案，跳过声纹匹配，不写入 `speaker_mapping`。

### 5.5 匹配策略（当前实现）

1. **占位：单说话人 + 单档案**  
   - 若 `len(first_segment)==1` 且 `len(profile_ids)==1`：直接 `speaker_mapping[only_sp] = profile_ids[0]`，不依赖剪切与声纹服务，避免 ffmpeg/剪切失败导致无映射。

2. **多说话人或多档案**  
   - 对 `first_segment` 中每个说话人：
     - 调用 `cut_audio_segment(local_path, start_sec, end_sec)`（[utils/audio_storage.py](utils/audio_storage.py)，基于 pydub）得到该句对应音频片段字节。
     - 将片段写入临时文件，调用 [services/voiceprint_service.py](services/voiceprint_service.py) 中 `identify_speaker(tmp_path, user_id, profile_ids, speaker_label=sp)`。
     - 若返回 `(matched_id, conf)` 且 `conf > 0.5`，则 `speaker_mapping[sp] = str(matched_id)`。
   - 临时文件与（若为 is_temp）下载的本地音频在流程结束后删除。

### 5.6 声纹服务（当前为占位）

- **register_voiceprint(profile_id, audio_url, audio_path)**：为档案注册声纹。占位：不调用阿里云，仅返回 `mock_vp_{profile_id}`。
- **identify_speaker(segment_audio_path, user_id, profile_ids, speaker_label)**：将一段音频与若干档案「匹配」。占位：不调用阿里云；按 `speaker_label`（如 Speaker_0/Speaker_1）轮询到不同 profile（Speaker_0→第 1 个档案，Speaker_1→第 2 个…），无标签则退回第 1 个；返回 `(matched_profile_id, 0.8)`。后续可接入阿里云 Speaker Verification 等 1:N 识别。

### 5.7 写入 speaker_mapping 与 conversation_summary

- 若有非空 `speaker_mapping`：查当前任务对应的 `AnalysisResult`，设置 `ar.speaker_mapping = speaker_mapping`，提交事务。
- **第二次 Gemini**：用 transcript + 当前 `speaker_mapping` 解析出档案名（关系），将每条转为「档案名: 内容」再拼成文本，调用 Gemini 生成「谁和谁对话」总结，写入 `analysis_results.conversation_summary`。

---

## 6. 任务详情接口中的档案展示

- **接口**：`GET /api/v1/tasks/sessions/{session_id}`（[main.py](main.py) 约 1558–1672 行）。
- **逻辑**：
  1. 从 `analysis_results` 读取 `speaker_mapping`、`conversation_summary`。
  2. 若存在 `speaker_mapping`：根据其 values（profile_id）查询 `Profile` 的 `name`、`relationship_type`，构建 `id_to_display[profile_id] = "档案名（关系）"`，再得到 `speaker_names = { sp: id_to_display[pid] for sp, pid in speaker_mapping.items() }`。
  3. 若存在 `speaker_names`：对 `summary`、`conversation_summary` 做替换：将 `Speaker_0`/`Speaker_1` 及「用户」替换为对应档案名（`_replace_speaker_labels`）。
  4. 响应中返回 `speaker_mapping`、`speaker_names`、以及已替换后的 `summary`、`conversation_summary`、`dialogues` 等，前端可直接展示档案名与总结。

---

## 7. 依赖与配置

- **数据库**：`analysis_results.speaker_mapping`、`conversation_summary` 及 `sessions.audio_url`/`audio_path` 需已迁移（见 [database/migrations/run_add_session_audio_and_speaker_mapping.py](database/migrations/run_add_session_audio_and_speaker_mapping.py)、[add_session_audio_and_speaker_mapping.sql](database/migrations/add_session_audio_and_speaker_mapping.sql)）。
- **音频**：多说话人声纹路径依赖 `cut_audio_segment`（pydub）；单说话人单档案占位不依赖剪切与 ffmpeg。
- **OSS**：私有 bucket 下原音频需通过 OSS SDK 在服务端下载后使用（[utils/audio_storage.py](utils/audio_storage.py) 中 `get_session_audio_local_path`）。

---

## 8. 诊断与扩展

- **诊断某任务匹配结果**：运行 `python3 check_speaker_mapping.py <session_id>`（或环境变量 `SPEAKER_CHECK_SESSION_ID`），可查看该任务的 `audio_url`/`audio_path`、`speaker_mapping`、`conversation_summary` 及说话人→档案名（[check_speaker_mapping.py](check_speaker_mapping.py)）。
- **扩展声纹**：在 [services/voiceprint_service.py](services/voiceprint_service.py) 中实现真实 `register_voiceprint`（档案音频→声纹库）与 `identify_speaker`（片段 1:N 识别），当前占位逻辑可保留为 fallback 或测试用。

---

## 9. 流程概览

```
录音上传 → Call #1 分析 → 写入 transcript / analysis_results
    → 取每说话人第一句时间 → 获取本地音频 → 取当前用户 profile_ids
    → [占位] 单说话人+单档案 → 直接 speaker_mapping
    → [否则] 按人剪切片段 → identify_speaker → 写入 speaker_mapping
    → 第二次 Gemini：用档案名生成 conversation_summary
    → 任务详情接口：speaker_mapping → speaker_names，替换 summary/conversation_summary 中的 Speaker_* / 用户
    → 前端展示档案名与总结
```

以上为 v0.5 档案匹配方案的完整技术描述，可作为实现与排查的统一参考。
